{
  "updatedAt": "2026-02-07T10:32:05.556Z",
  "createdAt": "2026-01-30T12:15:52.953Z",
  "id": "FZxkpldDbgV8AD_cg7IWG",
  "name": "V10.1 orchestrator copy",
  "description": null,
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "92217bb8-ffc8-459a-8331-3f553812c3d0",
        "responseMode": "responseNode",
        "options": {
          "rawBody": false
        }
      },
      "id": "f744daf0-5a48-444c-800a-b1b3cc4ae510",
      "name": "Webhook V8",
      "type": "n8n-nodes-base.webhook",
      "position": [
        16768,
        22288
      ],
      "typeVersion": 2.1,
      "webhookId": "92217bb8-ffc8-459a-8331-3f553812c3d0"
    },
    {
      "parameters": {
        "public": true,
        "initialMessages": "\ud83e\udde0 Bienvenue! Je suis l'assistant RAG SOTA 2026 **V8.0 CoT**.\n\n\u2728 Nouveaut\u00e9s:\n- Chain-of-Thought reasoning\n- Adaptive retrieval\n- Meilleure planification\n\nPosez-moi vos questions!",
        "options": {
          "responseMode": "responseNode"
        }
      },
      "id": "ad2972dd-a8f8-4368-8546-aeb5f5449ca8",
      "name": "Chat Trigger V8",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "typeVersion": 1.1,
      "position": [
        16768,
        22080
      ],
      "webhookId": "95045bc0-7635-45e7-9cbb-5e96b93b32af"
    },
    {
      "parameters": {
        "jsCode": "// INPUT MERGER V8 - Unifie Webhook et Chat Trigger\nconst inputItem = $input.first().json;\nconst startTime = Date.now();\n\nlet source = 'unknown';\nlet body = {};\nlet rawQuery = '';\n\nif (inputItem.headers !== undefined && inputItem.body !== undefined) {\n  source = 'webhook';\n  body = inputItem.body || {};\n  rawQuery = body.query || '';\n} else if (inputItem.chatInput !== undefined || inputItem.sessionId !== undefined) {\n  source = 'chat';\n  rawQuery = inputItem.chatInput || inputItem.message || '';\n  body = {\n    query: rawQuery,\n    conversation_id: inputItem.sessionId || 'chat-' + Date.now(),\n    tenant_id: 'chat-user',\n    user_groups: ['chat-user'],\n    roles: ['viewer']\n  };\n} else if (inputItem.query) {\n  source = 'direct';\n  body = inputItem;\n  rawQuery = inputItem.query;\n} else {\n  throw new Error('INPUT_ERROR: No valid input detected');\n}\n\nif (!rawQuery || rawQuery.trim().length === 0) {\n  throw new Error('VALIDATION_ERROR: query is required');\n}\n\nreturn [{\n  json: {\n    source: source,\n    body: body,\n    query: rawQuery.trim(),\n    session_id: body.conversation_id || inputItem.sessionId,\n    is_chat: source === 'chat',\n    is_webhook: source === 'webhook' || source === 'direct',\n    _perf: { start_time: startTime }\n  }\n}];"
      },
      "id": "935fb493-3928-400b-b87a-53a312b97015",
      "name": "Input Merger V8",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        16960,
        22192
      ]
    },
    {
      "parameters": {
        "jsCode": "// INIT V8 - Security Gate + Pre-Classification + CoT Prep + Query Hash\nconst body = $node[\"Input Merger V8\"].json.body || {};\nconst inputMerger = $node[\"Input Merger V8\"].json;\nconst startTime = Date.now();\n\n// Crypto pour hash\nconst crypto = require('crypto');\n\n// Extraction query\nlet rawQuery = body.query || inputMerger.query || '';\nconst query = rawQuery.trim();\n\n// G\u00e9n\u00e9rer query_hash pour cache\nconst queryHash = crypto.createHash('sha256')\n  .update(query.toLowerCase().trim())\n  .digest('hex').substring(0, 16);\n\n// Trace ID\nconst traceId = body.conversation_id || inputMerger.conversation_id || \n  `trace-${Date.now()}-${Math.random().toString(36).substring(7)}`;\n\n// Security checks\nconst isSuspicious = /(<script|javascript:|onerror=|eval\\()/i.test(query);\nconst isEmpty = query.length < 2;\n\nreturn {\n  trace_id: traceId,\n  query: query,\n  query_hash: queryHash,\n  conversation_id: body.conversation_id || traceId,\n  session_id: body.session_id || body.conversation_id || traceId,\n  tenant_id: body.tenant_id || 'default',\n  user_groups: body.user_groups || ['default'],\n  metadata: body.metadata || {},\n  is_suspicious: isSuspicious,\n  is_empty: isEmpty,\n  timestamp: startTime,\n  source: inputMerger.source || 'unknown'\n};\n"
      },
      "id": "3e534116-e58f-4aff-802c-66b4c5db2b2e",
      "name": "Init V8 Security & Analysis",
      "type": "n8n-nodes-base.code",
      "position": [
        17152,
        22192
      ],
      "typeVersion": 2
    },
    {
      "parameters": {
        "operation": "get",
        "key": "={{ 'conv:' + $node['Init V8 Security & Analysis'].json.conversation_id }}",
        "options": {}
      },
      "id": "a9f97e14-db82-4bd7-b0db-51b6eca8f667",
      "name": "Redis: Fetch Conversation",
      "type": "n8n-nodes-base.redis",
      "position": [
        17296,
        22384
      ],
      "typeVersion": 1,
      "credentials": {
        "redis": {
          "id": "O2KEPiv7VzgDG5ZX",
          "name": "Redis Upstash"
        }
      },
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT \n  COALESCE(entities_json, '{}'::jsonb) as entities_json,\n  COALESCE(last_intent, 'UNKNOWN') as last_intent,\n  COALESCE(updated_at, NOW()) as updated_at\nFROM conversation_context \nWHERE conversation_id = $1 AND tenant_id = $2\nLIMIT 1",
        "options": {
          "queryReplacement": "=={{ [$json.conversation_id, $json.user_context.tenant_id] }}"
        }
      },
      "id": "da7327db-154d-4cea-9020-96650b124966",
      "name": "Postgres L2/L3 Memory",
      "type": "n8n-nodes-base.postgres",
      "position": [
        17344,
        21904
      ],
      "typeVersion": 2.4,
      "credentials": {
        "postgres": {
          "id": "zEr7jPswZNv6lWKu",
          "name": "Supabase PostgreSQL"
        }
      },
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "workflowId": {
          "__rl": true,
          "value": "qtBs2Wbi_raU2o_dqfdDC",
          "mode": "id",
          "cachedResultUrl": "/workflow/qtBs2Wbi_raU2o_dqfdDC"
        },
        "workflowInputs": {
          "value": {
            "query": "={{ $node['\u2699\ufe0f Execution Engine V10'].json.current_task?.query || $node['\u2699\ufe0f Execution Engine V10'].json.task_query || $node['Init V8 Security & Analysis'].json.query }}",
            "trace_id": "={{ $node['Init V8 Security & Analysis'].json.trace_id }}",
            "user_context": "={{ JSON.stringify({ tenant_id: $node['Init V8 Security & Analysis'].json.tenant_id || 'default', groups: $node['Init V8 Security & Analysis'].json.user_groups || ['default'] }) }}",
            "topK": 20
          },
          "matchingColumns": [],
          "schema": [
            {
              "id": "query",
              "displayName": "query",
              "type": "string"
            },
            {
              "id": "trace_id",
              "displayName": "trace_id",
              "type": "string"
            },
            {
              "id": "user_context",
              "displayName": "user_context",
              "type": "string"
            },
            {
              "id": "topK",
              "displayName": "topK",
              "type": "number"
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": true,
          "mappingMode": "defineBelow"
        },
        "options": {
          "waitForSubWorkflow": true
        }
      },
      "id": "72c191ac-677e-4f9c-a64f-1cc328680e31",
      "name": "Invoke WF5: Standard",
      "type": "n8n-nodes-base.executeWorkflow",
      "position": [
        21840,
        22224
      ],
      "typeVersion": 1.2,
      "alwaysOutputData": false,
      "continueOnFail": true,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "workflowId": {
          "__rl": true,
          "value": "95x2BBAbJlLWZtWEJn6rb",
          "mode": "id",
          "cachedResultUrl": "/workflow/95x2BBAbJlLWZtWEJn6rb"
        },
        "workflowInputs": {
          "value": {
            "query": "={{ $node['\u2699\ufe0f Execution Engine V10'].json.current_task?.query || $node['\u2699\ufe0f Execution Engine V10'].json.task_query || $node['Init V8 Security & Analysis'].json.query }}",
            "trace_id": "={{ $node['Init V8 Security & Analysis'].json.trace_id }}",
            "user_context": "={{ JSON.stringify({ tenant_id: $node['Init V8 Security & Analysis'].json.tenant_id || 'default', groups: $node['Init V8 Security & Analysis'].json.user_groups || ['default'] }) }}",
            "topK": 20
          },
          "matchingColumns": [],
          "schema": [
            {
              "id": "query",
              "displayName": "query",
              "type": "string"
            },
            {
              "id": "trace_id",
              "displayName": "trace_id",
              "type": "string"
            },
            {
              "id": "user_context",
              "displayName": "user_context",
              "type": "string"
            },
            {
              "id": "topK",
              "displayName": "topK",
              "type": "number"
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": true,
          "mappingMode": "defineBelow"
        },
        "options": {
          "waitForSubWorkflow": true
        }
      },
      "id": "e3d043ea-96ab-4413-a1a5-683b090596a4",
      "name": "Invoke WF2: Graph",
      "type": "n8n-nodes-base.executeWorkflow",
      "position": [
        21840,
        22656
      ],
      "typeVersion": 1.2,
      "alwaysOutputData": true,
      "continueOnFail": true,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "workflowId": {
          "__rl": true,
          "value": "xrzL7TRX9F0UrWks0tdCI",
          "mode": "list",
          "cachedResultUrl": "/workflow/xrzL7TRX9F0UrWks0tdCI",
          "cachedResultName": "TEST - SOTA 2026 - WF4 Quantitative V2.0"
        },
        "workflowInputs": {
          "value": {
            "query": "={{ $node['\u2699\ufe0f Execution Engine V10'].json.current_task?.query || $node['\u2699\ufe0f Execution Engine V10'].json.task_query || $node['Init V8 Security & Analysis'].json.query }}",
            "trace_id": "={{ $node['Init V8 Security & Analysis'].json.trace_id }}",
            "user_context": "={{ JSON.stringify({ tenant_id: $node['Init V8 Security & Analysis'].json.tenant_id || 'default', groups: $node['Init V8 Security & Analysis'].json.user_groups || ['default'] }) }}",
            "topK": 20
          },
          "matchingColumns": [],
          "schema": [
            {
              "id": "query",
              "displayName": "query",
              "type": "string"
            },
            {
              "id": "trace_id",
              "displayName": "trace_id",
              "type": "string"
            },
            {
              "id": "user_context",
              "displayName": "user_context",
              "type": "string"
            },
            {
              "id": "topK",
              "displayName": "topK",
              "type": "number"
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": true,
          "mappingMode": "defineBelow"
        },
        "options": {
          "waitForSubWorkflow": true
        }
      },
      "id": "8d682938-416e-4a7c-915e-b9a02cca209a",
      "name": "Invoke WF4: Quantitative",
      "type": "n8n-nodes-base.executeWorkflow",
      "position": [
        21856,
        22416
      ],
      "typeVersion": 1.2,
      "alwaysOutputData": true,
      "continueOnFail": true,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "jsCode": "// ============================================\n// PATCH - Response Builder V9.6\n// FIX: Lit correctement les donn\u00e9es depuis Execution Engine\n// ============================================\n//\n// PROBL\u00c8ME: Response Builder ne recevait pas les donn\u00e9es car il lisait\n// depuis des nodes qui n'\u00e9taient pas dans son flux direct.\n//\n// SOLUTION: Lire depuis $json qui vient directement de l'IF node\n// qui lui-m\u00eame vient de Execution Engine.\n// ============================================\n\nconst inputData = $json;\nconst traceId = inputData.trace_id || $node['Init V8 Security & Analysis']?.json?.trace_id || 'unknown';\nconst isChat = inputData.is_chat || $node['Input Merger V8']?.json?.is_chat || false;\nconst originalQuery = inputData.original_query || $node['Init V8 Security & Analysis']?.json?.query || '';\n\nconsole.log(`[${traceId}] Response Builder V9.6 starting...`);\nconsole.log(`[${traceId}] Input keys: ${Object.keys(inputData).join(', ')}`);\n\n// === 1. R\u00c9CUP\u00c9RER LES R\u00c9SULTATS ===\n// Priorit\u00e9 1: Donn\u00e9es directes depuis Execution Engine (via IF node)\nlet completedTasks = inputData.completed_tasks || [];\nlet allResponses = inputData.all_responses || [];\nlet finalResponse = inputData.final_response || '';\nlet confidence = inputData.confidence || 0;\n\nconsole.log(`[${traceId}] From input: ${completedTasks.length} completed, ${allResponses.length} responses`);\nconsole.log(`[${traceId}] Pre-computed final_response: ${finalResponse.length} chars`);\n\n// === 2. SI PAS DE R\u00c9PONSE PR\u00c9-CALCUL\u00c9E, CONSTRUIRE ===\nif (!finalResponse || finalResponse.length < 10) {\n    console.log(`[${traceId}] Building response from completed_tasks...`);\n    \n    if (allResponses.length > 0) {\n        // Trier par confidence\n        const sorted = allResponses.sort((a, b) => (b.confidence || 0) - (a.confidence || 0));\n        \n        if (sorted.length === 1) {\n            finalResponse = sorted[0].response;\n            confidence = sorted[0].confidence || 0.5;\n        } else {\n            // Combiner les r\u00e9ponses de diff\u00e9rents RAGs\n            const usedRags = new Set(sorted.map(r => r.rag));\n            \n            if (usedRags.size > 1) {\n                // R\u00e9ponses de diff\u00e9rents RAGs\n                finalResponse = sorted.map(r => {\n                    const icon = r.rag === 'STANDARD' ? '\ud83d\udcda' : r.rag === 'GRAPH' ? '\ud83d\udd17' : '\ud83d\udcca';\n                    return `${icon} **${r.rag}:**\\n${r.response}`;\n                }).join('\\n\\n---\\n\\n');\n                \n                confidence = sorted.reduce((sum, r) => sum + (r.confidence || 0), 0) / sorted.length;\n            } else {\n                // M\u00eame RAG - prendre la meilleure\n                finalResponse = sorted[0].response;\n                confidence = sorted[0].confidence || 0.5;\n            }\n        }\n        \n        console.log(`[${traceId}] Built response: ${finalResponse.length} chars`);\n    }\n}\n\n// === 3. FALLBACK SI TOUJOURS VIDE ===\nif (!finalResponse || finalResponse.length < 10) {\n    // Essayer de lire depuis completed_tasks directement\n    if (completedTasks.length > 0) {\n        const tasksWithResponse = completedTasks.filter(t => t.response && t.response.length > 10);\n        if (tasksWithResponse.length > 0) {\n            // Prendre la meilleure\n            const best = tasksWithResponse.sort((a, b) => (b.confidence || 0) - (a.confidence || 0))[0];\n            finalResponse = best.response;\n            confidence = best.confidence || 0.5;\n            console.log(`[${traceId}] Fallback: used completed_tasks response`);\n        }\n    }\n}\n\n// === 4. DERNIER FALLBACK ===\nif (!finalResponse || finalResponse.length < 10) {\n    finalResponse = \"Je n'ai pas pu trouver d'information pertinente pour r\u00e9pondre \u00e0 votre question. Pourriez-vous reformuler ?\";\n    confidence = 0.1;\n    console.log(`[${traceId}] Using default fallback message`);\n}\n\n// === 5. AJOUTER LES SOURCES ===\nlet sources = [];\ncompletedTasks.forEach(t => {\n    if (t.sources && Array.isArray(t.sources)) {\n        sources.push(...t.sources);\n    }\n});\n\n// D\u00e9dupliquer\nconst uniqueSources = [];\nconst seenIds = new Set();\nfor (const s of sources) {\n    const id = s.id || s.source || JSON.stringify(s);\n    if (!seenIds.has(id)) {\n        seenIds.add(id);\n        uniqueSources.push(s);\n    }\n}\n\n// Formater avec sources\nlet formattedResponse = finalResponse;\nif (uniqueSources.length > 0) {\n    formattedResponse += '\\n\\n---\\n**Sources:**\\n';\n    formattedResponse += uniqueSources.slice(0, 5).map((s, i) => {\n        const name = s.source || s.id || 'Document';\n        const score = s.score ? ` (${(s.score * 100).toFixed(0)}%)` : '';\n        return `[${i + 1}] ${name}${score}`;\n    }).join('\\n');\n}\n\n// Note si confiance faible\nif (confidence < 0.4) {\n    formattedResponse += '\\n\\n*\u26a0\ufe0f Confiance mod\u00e9r\u00e9e - v\u00e9rifiez les informations.*';\n}\n\nconsole.log(`[${traceId}] Final response: ${formattedResponse.length} chars, confidence: ${confidence.toFixed(2)}`);\n\n// === 6. OUTPUT ===\nreturn {\n    final_response: formattedResponse,\n    chat_message: formattedResponse,  // Pour Chat: Final V8\n    confidence: confidence,\n    sources: uniqueSources.slice(0, 10),\n    sources_count: uniqueSources.length,\n    trace_id: traceId,\n    is_chat: isChat,\n    original_query: originalQuery,\n    \n    // Stats\n    tasks_completed: completedTasks.length,\n    responses_merged: allResponses.length,\n    \n    // Debug\n    _debug: {\n        input_had_final_response: !!inputData.final_response,\n        input_completed_count: inputData.completed_tasks?.length || 0,\n        input_responses_count: inputData.all_responses?.length || 0\n    }\n};\n"
      },
      "id": "161210a8-05be-4341-b5ac-b58a79026c32",
      "name": "Response Builder V9",
      "type": "n8n-nodes-base.code",
      "position": [
        24144,
        22112
      ],
      "typeVersion": 2
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO rlhf_training_data (conversation_id, query, response, feedback_score, feedback_type, reasoning_path, is_good_example, is_bad_example, needs_review) \nVALUES ($1, $2, $3, $4, 'implicit', $5, $6, $7, $8) \nON CONFLICT DO NOTHING",
        "options": {
          "queryReplacement": "={{ [\n  $('Init V8 Security & Analysis').item.json.conversation_id,\n  $('Init V8 Security & Analysis').item.json.query,\n  $('Response Builder V9').item.json.final_response,\n  $('Response Builder V9').item.json.confidence || 0.5,\n  JSON.stringify($('Response Builder V9').item.json.reasoning_path || {}),\n  ($('Response Builder V9').item.json.confidence || 0.5) > 0.7,\n  ($('Response Builder V9').item.json.confidence || 0.5) < 0.3,\n  true\n] }}"
        }
      },
      "id": "9b24efe5-41c2-42ea-889a-b704ece3b592",
      "name": "Store RLHF Data V8",
      "type": "n8n-nodes-base.postgres",
      "position": [
        24400,
        22512
      ],
      "typeVersion": 2.4,
      "credentials": {
        "postgres": {
          "id": "zEr7jPswZNv6lWKu",
          "name": "Supabase PostgreSQL"
        }
      },
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "operation": "set",
        "key": "={{ 'conv:' + $node['Init V8 Security & Analysis'].json.conversation_id }}",
        "value": "={{ JSON.stringify({ history: [...(($node['\ud83d\udce6 Context Compression V10.1'].json?.compressed_history) || []), { query: $node['Init V8 Security & Analysis'].json.query, response: $node['Response Builder V9'].json.final_response, timestamp: new Date().toISOString() }].slice(-10), cache: { [$node['Init V8 Security & Analysis'].json.query_hash]: { response: $node['Response Builder V9'].json.final_response, timestamp: new Date().toISOString() } } }) }}"
      },
      "id": "d5455c64-0042-471f-88f1-d8a64c8d26ff",
      "name": "Redis: Store Conv V8",
      "type": "n8n-nodes-base.redis",
      "position": [
        24384,
        21984
      ],
      "typeVersion": 1,
      "credentials": {
        "redis": {
          "id": "O2KEPiv7VzgDG5ZX",
          "name": "Redis Upstash"
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO conversation_context (conversation_id, tenant_id, entities_json, last_intent, updated_at) VALUES ($1, $2, $3, $4, NOW()) ON CONFLICT (conversation_id, tenant_id) DO UPDATE SET entities_json = $3, last_intent = $4, updated_at = NOW()",
        "options": {
          "queryReplacement": "={{ [\n  $('Init V8 Security & Analysis').first().json.conversation_id,\n  $('Init V8 Security & Analysis').first().json.tenant_id || 'default',\n  JSON.stringify($('\ud83d\udce6 Context Compression V10.1').first().json.entities_of_interest || {}),\n  $('\ud83d\udd0d Query Classifier V10.1').first().json.query_route || 'UNKNOWN'\n] }}"
        }
      },
      "id": "8fe8eadb-9f5d-421c-bbb5-798d1966e937",
      "name": "Postgres: Update Context V8",
      "type": "n8n-nodes-base.postgres",
      "position": [
        24384,
        22240
      ],
      "typeVersion": 2.4,
      "credentials": {
        "postgres": {
          "id": "zEr7jPswZNv6lWKu",
          "name": "Supabase PostgreSQL"
        }
      },
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "loose",
            "version": 1
          },
          "conditions": [
            {
              "id": "is-chat-final",
              "leftValue": "={{ $('Response Builder V9').item.json.is_chat }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {
          "looseTypeValidation": true
        }
      },
      "id": "fcc058cf-79a3-4c2c-a27a-e57e4b7d0c5b",
      "name": "Output Router (Final)",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        25088,
        22192
      ]
    },
    {
      "parameters": {
        "respondWith": "text",
        "responseBody": "={{ $('Response Builder V9').item.json.chat_message }}",
        "options": {}
      },
      "id": "55f180e4-5489-47b0-97fe-de50a127cc48",
      "name": "Chat: Final V8",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [
        25264,
        22048
      ]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={\n  \"success\": true,\n  \"response\": {{ $('Response Builder V9').item.json.final_response ? JSON.stringify($('Response Builder V9').item.json.final_response) : '\"\"' }},\n  \"confidence\": {{ $('Response Builder V9').item.json.confidence || 0 }},\n  \"trace_id\": {{ $('Response Builder V9').item.json.trace_id ? JSON.stringify($('Response Builder V9').item.json.trace_id) : '\"\"' }},\n  \"version\": \"V8.0-CoT\",\n  \"perf\": {{ $('Response Builder V9').item.json.perf ? JSON.stringify($('Response Builder V9').item.json.perf) : '{}' }},\n  \"reasoning_path\": {{ $('Response Builder V9').item.json.reasoning_path ? JSON.stringify($('Response Builder V9').item.json.reasoning_path) : '{}' }}\n}",
        "options": {}
      },
      "id": "906694a2-098b-480b-9705-8c9f6fa397f3",
      "name": "Return Response V8",
      "type": "n8n-nodes-base.respondToWebhook",
      "position": [
        25264,
        22256
      ],
      "typeVersion": 1.1
    },
    {
      "parameters": {},
      "id": "3b1040f3-8d0e-4a98-9bf1-6a54193a3aa9",
      "name": "Error Handler V8",
      "type": "n8n-nodes-base.errorTrigger",
      "position": [
        16528,
        22544
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "jsCode": "// Error Payload Builder V8\nconst error = $json.error || { message: 'Unknown error' };\nlet traceId = 'unknown';\ntry { traceId = $node['Init V8 Security & Analysis'].json?.trace_id; } catch(e) {}\n\nreturn {\n  event_id: `err-${Date.now()}`,\n  trace_id: traceId,\n  timestamp: new Date().toISOString(),\n  level: 'error',\n  message: error.message,\n  stack: error.stack?.substring(0, 1000),\n  context: {\n    workflow: $workflow.name,\n    node: $prevNode?.name,\n    execution_id: $execution.id\n  },\n  user_input: '[REDACTED]',\n  version: 'V8.0-CoT'\n};"
      },
      "id": "3a540e97-79d1-4d12-ac5b-ca731b3374b8",
      "name": "Error Payload V8",
      "type": "n8n-nodes-base.code",
      "position": [
        16704,
        22544
      ],
      "typeVersion": 2
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{ $vars.SENTRY_DSN || 'https://sentry.io/api/ingest' }}",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json }}",
        "options": {
          "timeout": 5000
        }
      },
      "id": "f7a8b350-4099-442a-b35e-fa2e64e74c32",
      "name": "Export Error V8",
      "type": "n8n-nodes-base.httpRequest",
      "position": [
        16896,
        22544
      ],
      "typeVersion": 4.3,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={\n  \"success\": false,\n  \"response\": \"An error occurred while processing your request. Please try again.\",\n  \"error\": {{ JSON.stringify($json.message || 'Internal workflow error') }},\n  \"trace_id\": {{ JSON.stringify($json.trace_id || '') }},\n  \"version\": \"V8.0-CoT\"\n}",
        "options": {
          "responseCode": 200
        }
      },
      "id": "err-respond-v8-001",
      "name": "Return: Error Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [
        17088,
        22544
      ]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{ $vars.OPENROUTER_BASE_URL || 'https://openrouter.ai/api/v1/chat/completions' }}",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "openRouterApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"{{ $vars.LLM_INTENT_MODEL || 'deepseek/deepseek-chat' }}\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"You are the INTENT ANALYZER of a sophisticated multi-engine RAG system.\\n\\n=== YOUR MISSION ===\\n1. Analyze the user query\\n2. Identify ALL intents (explicit AND implicit)\\n3. Determine DEPENDENCIES between intents\\n4. Assign the optimal RAG engine for each intent\\n\\n=== AVAILABLE RAG ENGINES ===\\n\\n**STANDARD (Pinecone + BM25)**\\n- Hybrid document retrieval (dense + sparse)\\n- topK=20, Cohere reranking\\n- Latency: ~3s\\n- Strengths: facts, procedures, definitions, technical documentation\\n- Weaknesses: poor for precise numbers, complex relationships\\n\\n**GRAPH (Neo4j)**\\n- Multi-hop traversal (4 levels max)\\n- Community detection, intelligent pruning\\n- Latency: ~5s\\n- Strengths: relationships, hierarchies, impacts, multi-hop reasoning, bridging facts across entities\\n- Weaknesses: no quantitative data, slow for simple queries\\n- USE FOR ANY question that requires CHAINING 2+ facts across different entities or documents:\\n  * 'Who voices the character named after X?' (chain: X -> character -> voice actor)\\n  * 'In what year did the founder of X die?' (chain: X -> founder -> death year)\\n  * 'What country is the birthplace of the director of film Y located in?' (chain: Y -> director -> birthplace -> country)\\n  * 'Which film has the director who died first?' (chain: film -> director -> death date, compare)\\n  * Any question mentioning a person/place/org indirectly through another entity\\n- CRITICAL: If answering requires looking up entity A to find entity B, then looking up entity B to find the answer, this is GRAPH, NOT STANDARD\\n- When in doubt between STANDARD and GRAPH, prefer GRAPH for questions about people, places, organizations, or historical facts that involve indirect references\\n\\n**QUANTITATIVE (PostgreSQL)**\\n- Automatic SQL generation with self-healing\\n- Access to tables: sales, employees, products, kpis\\n- Latency: ~4s\\n- Strengths: numbers, totals, averages, comparisons, KPIs, trends\\n- Weaknesses: no narrative text, requires structured data\\n\\n=== PRIORITIZATION RULES ===\\n1. Numbers/totals/averages/KPIs -> QUANTITATIVE\\n2. Simple factual lookups (single entity, direct answer) -> STANDARD\\n3. Multi-hop chains (answer requires 2+ fact lookups) -> GRAPH\\n4. If the question refers to an entity INDIRECTLY (e.g. 'the founder of X', 'the director of Y', 'the birthplace of Z') -> GRAPH\\n5. Comparisons between entities (which is older, who died first) -> GRAPH\\n6. Questions about people, places, orgs connected through events/works -> GRAPH\\n7. If two intents are INDEPENDENT, mark 'can_parallelize': true\\n8. When unsure between STANDARD and GRAPH, choose GRAPH\\n\\n=== STRICT JSON FORMAT ===\\nRespond ONLY with this JSON, no text before/after:\\n{\\n  \\\"reasoning\\\": \\\"<your step-by-step analysis in 2-3 sentences>\\\",\\n  \\\"intents\\\": [\\n    {\\n      \\\"id\\\": \\\"intent-1\\\",\\n      \\\"description\\\": \\\"<what the user wants to know>\\\",\\n      \\\"type\\\": \\\"FACTUAL|QUANTITATIVE|RELATIONAL|PROCEDURAL|COMPARATIVE\\\",\\n      \\\"suggested_rag\\\": \\\"STANDARD|GRAPH|QUANTITATIVE\\\",\\n      \\\"priority\\\": 1,\\n      \\\"depends_on\\\": [],\\n      \\\"can_parallelize_with\\\": [\\\"intent-X\\\"]\\n    }\\n  ],\\n  \\\"execution_order\\\": [\\\"intent-1\\\"],\\n  \\\"has_parallel_intents\\\": false,\\n  \\\"complexity\\\": \\\"SIMPLE|MODERATE|COMPLEX\\\"\\n}\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"=== QUERY TO ANALYZE ===\\n{{ $node['Init V8 Security & Analysis'].json.query }}\"\n    }\n  ],\n  \"temperature\": 0.1,\n  \"max_tokens\": 800,\n  \"response_format\": { \"type\": \"json_object\" }\n}",
        "options": {
          "timeout": 30000
        }
      },
      "id": "5a69dda9-8989-4837-87f4-69f6ea39e462",
      "name": "\ud83e\udde0 LLM 1: Intent Analyzer",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        19840,
        22304
      ],
      "credentials": {
        "openRouterApi": {
          "id": "aTHBqnntMBApo0Dy",
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Intent Parser V9.1 - Parse LLM 1 output avec support parall\u00e9lisation\nconst llmResponse = $json;\nconst initData = $node['Init V8 Security & Analysis'].json;\nconst guardrailData = $node['\ud83d\udee1\ufe0f Advanced Guardrails'].json;\n\nlet intentsData;\ntry {\n  const content = llmResponse.body?.choices?.[0]?.message?.content \n               || llmResponse.choices?.[0]?.message?.content || '{}';\n  intentsData = JSON.parse(content);\n} catch (e) {\n  // Fallback: single intent based on router\n  intentsData = {\n    reasoning: 'Fallback due to parsing error: ' + e.message,\n    intents: [{\n      id: 'intent-1',\n      description: initData.query,\n      type: 'FACTUAL',\n      suggested_rag: guardrailData.engine || 'STANDARD',\n      priority: 1,\n      depends_on: [],\n      can_parallelize_with: []\n    }],\n    execution_order: ['intent-1'],\n    has_parallel_intents: false,\n    complexity: 'SIMPLE'\n  };\n}\n\n// Validate intents\nconst validRags = ['STANDARD', 'GRAPH', 'QUANTITATIVE'];\nintentsData.intents = (intentsData.intents || []).map((intent, idx) => ({\n  ...intent,\n  id: intent.id || `intent-${idx + 1}`,\n  suggested_rag: validRags.includes(intent.suggested_rag) ? intent.suggested_rag : 'STANDARD',\n  priority: intent.priority || idx + 1,\n  depends_on: Array.isArray(intent.depends_on) ? intent.depends_on : [],\n  can_parallelize_with: Array.isArray(intent.can_parallelize_with) ? intent.can_parallelize_with : []\n}));\n\n// Determine if parallel execution is possible\nconst hasParallel = intentsData.has_parallel_intents || \n  intentsData.intents.some(i => i.can_parallelize_with?.length > 0);\n\n// Output format for LLM 2\nreturn {\n  trace_id: initData.trace_id,\n  original_query: initData.query,\n  user_context: initData.user_context,\n  \n  // Intent analysis\n  intents: intentsData.intents,\n  execution_order: intentsData.execution_order || intentsData.intents.map(i => i.id),\n  reasoning: intentsData.reasoning,\n  complexity: intentsData.complexity || 'MODERATE',\n  \n  // Parallelization info\n  has_parallel_intents: hasParallel,\n  \n  // Pass through\n  is_chat: $node['Input Merger V8'].json.is_chat,\n  is_webhook: $node['Input Merger V8'].json.is_webhook,\n  conversation_id: initData.conversation_id\n};"
      },
      "id": "bdea704a-e190-4948-b5df-8452da164e03",
      "name": "Intent Parser V9",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        20032,
        22304
      ]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{ $vars.OPENROUTER_BASE_URL || 'https://openrouter.ai/api/v1/chat/completions' }}",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "openRouterApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"{{ $vars.LLM_PLANNER_MODEL || 'anthropic/claude-sonnet-4-5-20250929' }}\",\n  \"temperature\": 0.2,\n  \"max_tokens\": 2000,\n  \"response_format\": {\"type\": \"json_object\"},\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": {{ JSON.stringify(`You are the TASK PLANNER of a multi-engine RAG system. You receive analyzed intents and must create an optimal execution plan.\n\n=== DETAILED RAG ENGINE CAPABILITIES ===\n\n**STANDARD (RAG Multi-Index V3.4)**\n- Technology: Pinecone (1536 dims) + BM25 sparse\n- Retrieval: HyDE (hypothetical document), optional Query Decomposition\n- Reranking: Cohere rerank-multilingual-v3\n- topK: 20 chunks, ~500 tokens/chunk\n- Latency: 2-4 seconds\n- OPTIMAL FOR: Factual questions, procedures, definitions, technical documentation\n- AVOID FOR: precise numbers, hierarchical relationships\n\n**GRAPH (Neo4j Graph RAG V3.3)**\n- Technology: Neo4j + 4-hop traversal\n- Capabilities: community detection, path finding, pruning\n- Entities: Person, Team, Project, Document, Skill\n- Relations: WORKS_IN, MANAGES, REPORTS_TO, CONTRIBUTES_TO\n- Latency: 3-6 seconds\n- OPTIMAL FOR: Relationships, hierarchies, impacts, org charts, multi-hop reasoning, entity traversal, comparison between entities\n- AVOID FOR: numbers, long narrative text\n\n**QUANTITATIVE (SQL RAG V2.0)**\n- Technology: PostgreSQL + Text-to-SQL (CoT)\n- Self-healing: automatic SQL correction\n- Tables: sales, employees, products, kpis\n- Latency: 2-5 seconds\n- OPTIMAL FOR: Totals, averages, comparisons, KPIs, trends\n- AVOID FOR: text, non-numeric relationships\n\n=== PLANNING RULES ===\n1. PARALLELIZATION: If two tasks have NO dependency, same parallel_group (max 3)\n2. DEPENDENCIES: A task needing another's result -> depends_on\n3. SKIP CONDITIONS: If one answer can cover multiple intents -> if_success_covers\n4. FALLBACKS: Always provide a fallback_rag DIFFERENT from target_rag\n\n=== RECEIVED INTENTS ===\n${JSON.stringify($json.intents, null, 2)}\n\n=== SUGGESTED ORDER ===\n${$json.execution_order.join(' -> ')}\n\n=== PARALLELIZABLE INTENTS ===\n${$json.has_parallel_intents ? 'YES' : 'NO'}\n\n=== ORIGINAL QUERY ===\n${$json.original_query}\n\n=== STRICT JSON FORMAT ===\nRespond ONLY with this JSON:\n{\n  \"plan_id\": \"plan-<timestamp>\",\n  \"reasoning\": \"<your reasoning in 2-3 sentences>\",\n  \"execution_mode\": \"SEQUENTIAL|PARALLEL|MIXED\",\n  \"parallel_groups\": [{\"group_id\": 1, \"task_ids\": [1, 2], \"reason\": \"...\"}],\n  \"tasks\": [\n    {\n      \"task_id\": 1,\n      \"intent_id\": \"intent-1\",\n      \"query\": \"<query OPTIMIZED for this RAG>\",\n      \"target_rag\": \"STANDARD|GRAPH|QUANTITATIVE\",\n      \"fallback_rag\": \"STANDARD|GRAPH|QUANTITATIVE\",\n      \"parallel_group\": null,\n      \"depends_on_task\": null,\n      \"success_criteria\": {\"min_confidence\": 0.6, \"min_sources\": 1},\n      \"if_success_covers\": []\n    }\n  ],\n  \"total_tasks\": 1,\n  \"estimated_latency_ms\": 3000\n}`) }}\n    }\n  ]\n}",
        "options": {
          "timeout": 20000
        }
      },
      "id": "a2123ca5-27d8-41d5-85c1-a8c6dd96c1d2",
      "name": "\ud83c\udfaf LLM 2: Task Planner",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        20256,
        22304
      ],
      "credentials": {
        "openRouterApi": {
          "id": "aTHBqnntMBApo0Dy",
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "content": "# \ud83d\udd27 CONFIGURATION SOTA 2026\n## Variables d'environnement requises\n\n### APIs (cl\u00e9s requises)\n- `DEEPSEEK_API_KEY` - api.deepseek.com\n- `ANTHROPIC_API_KEY` - planning complexe\n- `GOOGLE_API_KEY` - Gemini Flash (optionnel)\n\n### Mod\u00e8les LLM (optionnel, d\u00e9fauts inclus)\n- `SQL_MODEL` = deepseek-chat (BIRD-SQL 72.3%)\n- `INTENT_MODEL` = deepseek-chat\n- `PLANNING_MODEL` = claude-sonnet-4-5\n- `GENERATION_MODEL` = deepseek-chat\n- `ROUTER_MODEL` = gemini-2.0-flash\n\n### Embedding (FORTEMENT RECOMMAND\u00c9)\n- `EMBEDDING_API_URL` \u2192 self-hosted Qwen3\n- `EMBEDDING_MODEL` = Qwen3-Embedding-8B\n- Impact: +15 pts MTEB vs text-embedding-3-small\n\n### Reranking (FORTEMENT RECOMMAND\u00c9)\n- `RERANKER_API_URL` \u2192 self-hosted Qwen3\n- `RERANKER_MODEL` = Qwen3-Reranker-8B\n- Impact: +2 pts BEIR, $0 vs $2/1k\n\n### Impact \u00e9conomique estim\u00e9:\n- Ingestion: -89% co\u00fbt\n- Requ\u00eates: -95% co\u00fbt\n- Qualit\u00e9 SQL: +3%\n- Qualit\u00e9 retrieval: +15%",
        "height": 804,
        "width": 188
      },
      "id": "dae9fb50-b9e9-44c8-9f01-82fe249bb3ed",
      "name": "\ud83d\udccb Config SOTA 2026",
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        16320,
        21360
      ]
    },
    {
      "parameters": {
        "jsCode": "// === RATE LIMIT GUARD - Post Redis Cache ===\nconst redisData = $json;\nconst initData = $node['Init V8 Security & Analysis'].json;\nconst conversationHistory = redisData.conversation_history || [];\nconst now = Date.now();\nconst traceId = initData.trace_id;\n\n// Analyser les timestamps des messages r\u00e9cents\nconst recentWindow = 60000; // 1 minute\nconst recentMessages = conversationHistory.filter(msg => \n  msg.timestamp && (now - msg.timestamp) < recentWindow\n);\n\n// Rate limit: max 10 messages par minute\nconst MAX_REQUESTS_PER_MINUTE = 10;\nconst isRateLimited = recentMessages.length >= MAX_REQUESTS_PER_MINUTE;\n\n// Pattern abuse detection: plus de 5 messages en 10 secondes\nconst veryRecentMessages = conversationHistory.filter(msg =>\n  msg.timestamp && (now - msg.timestamp) < 10000\n);\nconst isAbuse = veryRecentMessages.length > 5;\n\nif (isRateLimited || isAbuse) {\n  console.log(`[${traceId}] RATE LIMITED: ${recentMessages.length} req/min, ${veryRecentMessages.length} req/10s`);\n  \n  return {\n    rate_limited: true,\n    blocked_until: now + recentWindow,\n    message: \"Rate limit exceeded. Please slow down your requests.\",\n    recent_count: recentMessages.length,\n    abuse_detected: isAbuse,\n    trace_id: traceId\n  };\n}\n\n// Pas de rate limit - passer les donn\u00e9es\nreturn {\n  rate_limited: false,\n  ...redisData,\n  trace_id: traceId\n};\n"
      },
      "id": "f5371300-cc52-4f1b-aad6-f95d8d67eaf3",
      "name": "\ud83d\udee1\ufe0f Rate Limit Guard",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        17520,
        22384
      ]
    },
    {
      "parameters": {
        "conditions": {
          "boolean": [
            {
              "value1": "={{ $json.rate_limited }}",
              "value2": true
            }
          ]
        },
        "options": {}
      },
      "id": "479a0220-29c2-42a9-8374-ccf4ca47c4aa",
      "name": "IF: Rate Limited?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        17696,
        22384
      ]
    },
    {
      "parameters": {
        "respondWith": "text",
        "responseBody": "={{ $json.message }}",
        "options": {}
      },
      "id": "e84e2158-ce59-4d66-90af-07526b4fb5da",
      "name": "Return: Rate Limited",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [
        17904,
        22400
      ]
    },
    {
      "parameters": {
        "jsCode": "// === CACHE PARSER - V\u00e9rifie hit/miss ===\nconst redisResult = $json;\nconst initData = $node['Init V8 Security & Analysis'].json;\n\nlet cacheHit = false;\nlet cachedResponse = null;\n\ntry {\n    if (redisResult && redisResult.value) {\n        const cached = JSON.parse(redisResult.value);\n        const cacheAge = Date.now() - (cached.timestamp || 0);\n        \n        // Cache valide si < 1h\n        if (cacheAge < 3600000) {\n            cacheHit = true;\n            cachedResponse = cached.response;\n            console.log(`[${initData.trace_id}] Cache HIT: ${initData.query_hash}`);\n        } else {\n            console.log(`[${initData.trace_id}] Cache expired: ${cacheAge}ms old`);\n        }\n    }\n} catch (e) {\n    console.log(`[${initData.trace_id}] Cache parse error: ${e.message}`);\n}\n\nreturn {\n    cache_hit: cacheHit,\n    cached_response: cachedResponse,\n    query: initData.query,\n    query_hash: initData.query_hash,\n    trace_id: initData.trace_id\n};\n"
      },
      "id": "6afac6d0-4023-43ae-9b7e-76fd1f199862",
      "name": "Cache Parser",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        19072,
        21888
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "e0d9ad14-ed75-46a4-a1bf-d804801bd1c0",
              "leftValue": "={{ $json.cached_response }}",
              "rightValue": "Null",
              "operator": {
                "type": "string",
                "operation": "equals",
                "name": "filter.operator.equals"
              }
            },
            {
              "id": "a61487b3-0cc9-470c-af6b-e4e5b57f1538",
              "leftValue": "",
              "rightValue": "",
              "operator": {
                "type": "string",
                "operation": "equals",
                "name": "filter.operator.equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "cd442267-b982-44c2-af3e-cd85bad12a24",
      "name": "IF: Cache Hit?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        19216,
        21888
      ]
    },
    {
      "parameters": {
        "respondWith": "text",
        "responseBody": "={{ $json.cached_response + '\\n\\n_\ud83d\ude80 R\u00e9ponse en cache_' }}",
        "options": {}
      },
      "id": "4fbc2f9b-57a0-4004-9305-ae5b50045464",
      "name": "Return: Cached",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [
        19408,
        21888
      ]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "CREATE TABLE IF NOT EXISTS rag_task_executions (\n  id SERIAL PRIMARY KEY,\n  trace_id VARCHAR(255) NOT NULL,\n  task_id INTEGER NOT NULL,\n  intent_id VARCHAR(255),\n  status VARCHAR(50) DEFAULT 'pending',\n  rag_called VARCHAR(50),\n  attempt INTEGER DEFAULT 1,\n  query TEXT,\n  response TEXT,\n  error_message TEXT,\n  sources JSONB,\n  confidence FLOAT,\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW(),\n  UNIQUE(trace_id, task_id)\n);\n\nCREATE INDEX IF NOT EXISTS idx_task_status ON rag_task_executions(trace_id, status);\nCREATE INDEX IF NOT EXISTS idx_task_attempt ON rag_task_executions(trace_id, task_id, attempt);\n",
        "options": {}
      },
      "id": "ea82be59-7036-4626-acfd-11822f852c0f",
      "name": "Postgres: Init Tasks Table",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        20592,
        22448
      ],
      "credentials": {
        "postgres": {
          "id": "zEr7jPswZNv6lWKu",
          "name": "Supabase PostgreSQL"
        }
      },
      "continueOnFail": true,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "jsCode": "// ============================================\n// FORMAT & DISPATCH V10.2 - MULTI-INTENT FIXED\n// ============================================\n\nvar plannerRawOutput = $json;\nvar traceId = $node['Init V8 Security & Analysis'].json.trace_id;\nvar originalQuery = $node['Init V8 Security & Analysis'].json.query;\n\nvar RAG_MAPPING = {\n  'standard': 'STANDARD',\n  'graph': 'GRAPH',\n  'quantitative': 'QUANTITATIVE'\n};\n\nfunction normalizeRAGName(ragName) {\n  if (!ragName) return 'STANDARD';\n  var key = String(ragName).toLowerCase().trim();\n  if (RAG_MAPPING[key]) return RAG_MAPPING[key];\n  return String(ragName).toUpperCase();\n}\n\nvar tasks = [];\nvar plannerData = null;\n\n// === 1. PARSER LA R\u00c9PONSE LLM 2 ===\ntry {\n  var contentString = '';\n  \n  // Support OpenRouter format\n  if (plannerRawOutput.choices && plannerRawOutput.choices[0] && \n      plannerRawOutput.choices[0].message && plannerRawOutput.choices[0].message.content) {\n    contentString = plannerRawOutput.choices[0].message.content;\n  }\n  // Support Anthropic format\n  else if (plannerRawOutput.content && plannerRawOutput.content[0] && \n           plannerRawOutput.content[0].text) {\n    contentString = plannerRawOutput.content[0].text;\n  }\n  \n  // Nettoyer les markdown code blocks\n  contentString = contentString.replace(/```json/g, '').replace(/```/g, '').trim();\n  \n  // Parser le JSON\n  plannerData = JSON.parse(contentString);\n  \n  if (plannerData && plannerData.tasks && Array.isArray(plannerData.tasks)) {\n    tasks = plannerData.tasks;\n    console.log('[' + traceId + '] Parsed ' + tasks.length + ' tasks from LLM 2');\n  }\n  \n} catch (parseError) {\n  console.error('[' + traceId + '] LLM 2 parse error: ' + parseError.message);\n  // Continue vers le fallback\n}\n\n// === 2. FALLBACK : CR\u00c9ER UNE T\u00c2CHE PAR INTENT ===\nif (tasks.length === 0) {\n  console.log('[' + traceId + '] Fallback: creating tasks from Intent Parser');\n  \n  var intentData = $node['Intent Parser V9'].json;\n  var intents = intentData.intents || [];\n  \n  if (intents.length > 0) {\n    // Cr\u00e9er une t\u00e2che pour CHAQUE intent\n    for (var i = 0; i < intents.length; i++) {\n      var intent = intents[i];\n      \n      tasks.push({\n        task_id: i + 1,\n        intent_id: intent.id || ('intent-' + (i + 1)),\n        // Utiliser la description de l'intent OU la query optimis\u00e9e\n        query: intent.query || intent.description || originalQuery,\n        target_rag: intent.suggested_rag || 'STANDARD',\n        fallback_rag: 'STANDARD',\n        parallel_group: intent.can_parallelize_with && intent.can_parallelize_with.length > 0 ? 1 : null\n      });\n    }\n    \n    console.log('[' + traceId + '] Created ' + tasks.length + ' tasks from ' + intents.length + ' intents');\n  } else {\n    // Dernier fallback : une seule t\u00e2che g\u00e9n\u00e9rique\n    tasks = [{\n      task_id: 1,\n      intent_id: 'intent-1',\n      query: originalQuery,\n      target_rag: 'STANDARD',\n      fallback_rag: 'GRAPH'\n    }];\n    \n    console.log('[' + traceId + '] Ultimate fallback: single generic task');\n  }\n}\n\n// === 3. CONSTRUIRE tasksToInsert ===\nvar tasksToInsert = [];\n\nfor (var i = 0; i < tasks.length; i++) {\n  var task = tasks[i];\n  \n  // R\u00e9cup\u00e9rer le RAG cible\n  var targetRag = task.target_rag || task.rag || 'STANDARD';\n  var normalizedRAG = normalizeRAGName(targetRag);\n  \n  // \u00c9chapper les quotes pour PostgreSQL\n  var cleanQuery = String(task.query || originalQuery).replace(/'/g, \"''\");\n  \n  tasksToInsert.push({\n    trace_id: traceId,\n    task_id: task.task_id || (i + 1),\n    intent_id: task.intent_id || ('intent-' + (i + 1)),\n    status: 'pending',\n    rag_called: normalizedRAG,\n    attempt: 1,\n    query: cleanQuery,\n    response: null,\n    error_message: null,\n    sources: null,\n    confidence: task.success_criteria ? task.success_criteria.min_confidence : 0.8\n  });\n}\n\nconsole.log('[' + traceId + '] Final output: ' + tasksToInsert.length + ' tasks ready for DB');\n\n// === 4. OUTPUT ===\nreturn {\n  trace_id: traceId,\n  tasks_to_insert: tasksToInsert,\n  total_tasks: tasksToInsert.length,\n  execution_mode: plannerData ? (plannerData.execution_mode || 'SEQUENTIAL') : 'SEQUENTIAL',\n  parallel_groups: plannerData ? (plannerData.parallel_groups || []) : [],\n  // Debug info\n  _debug: {\n    parser_success: plannerData !== null,\n    fallback_used: tasks.length === 0,\n    original_task_count: tasks.length\n  }\n};"
      },
      "id": "6e28b992-6c41-495d-a21d-812ec7120d63",
      "name": "\ud83d\udcdd Format & Dispatch (Plan\u2192DB)",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        20832,
        22304
      ]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO rag_task_executions \n  (trace_id, task_id, intent_id, status, rag_called, attempt, query, confidence)\nVALUES {{ $json.tasks_to_insert.map(t => \n  `('${t.trace_id}', ${t.task_id}, '${t.intent_id}', '${t.status}', '${t.rag_called}', ${t.attempt}, '${t.query}', ${t.confidence})`\n).join(', ') }}\nON CONFLICT (trace_id, task_id) DO UPDATE \nSET status = 'pending', updated_at = NOW();\n",
        "options": {}
      },
      "id": "dd492a5d-32aa-4a72-9d90-7c9253e6f228",
      "name": "Postgres: Insert Tasks",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        21024,
        22304
      ],
      "credentials": {
        "postgres": {
          "id": "zEr7jPswZNv6lWKu",
          "name": "Supabase PostgreSQL"
        }
      },
      "continueOnFail": true,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "jsCode": "// ============================================\n// PATCH - Execution Engine V10.9\n// FIX 1: Passe correctement les donn\u00e9es \u00e0 Response Builder\n// FIX 2: Marque le workflow comme termin\u00e9 pour \u00e9viter re-trigger\n// ============================================\n\nconst traceId = $node['Init V8 Security & Analysis'].json.trace_id;\nconst originalQuery = $node['Init V8 Security & Analysis'].json.query;\nconst isChat = $node['Input Merger V8'].json.is_chat || false;\n\n// === 1. ANTI-LOOP avec staticData ===\nconst staticData = $getWorkflowStaticData('global');\n\n// Check si d\u00e9j\u00e0 termin\u00e9\nconst completeKey = `complete_${traceId}`;\nif (staticData[completeKey]) {\n    console.log(`[${traceId}] \u26a0\ufe0f Workflow d\u00e9j\u00e0 termin\u00e9 - ignoring re-trigger`);\n    // Retourner un objet vide pour ne pas continuer\n    return [];\n}\n\n// Counter de boucle\nif (!staticData.loopCounters) {\n    staticData.loopCounters = {};\n}\nconst loopKey = `loop_${traceId}`;\nif (!staticData.loopCounters[loopKey]) {\n    staticData.loopCounters[loopKey] = 0;\n}\nstaticData.loopCounters[loopKey]++;\n\nconst currentIteration = staticData.loopCounters[loopKey];\nconst MAX_ITERATIONS = 10;\n\nconsole.log(`[${traceId}] Execution Engine V10.9 - iteration ${currentIteration}/${MAX_ITERATIONS}`);\n\n// === 2. SAFETY - Max iterations ===\nif (currentIteration > MAX_ITERATIONS) {\n    console.error(`[${traceId}] MAX ITERATIONS - Breaking!`);\n    staticData[completeKey] = true;  // Marquer comme termin\u00e9\n    delete staticData.loopCounters[loopKey];\n    \n    return {\n        all_complete: true,\n        trace_id: traceId,\n        is_chat: isChat,\n        original_query: originalQuery,\n        completed_tasks: [],\n        all_responses: [],\n        final_response: \"Erreur: limite d'it\u00e9rations atteinte.\",\n        error: \"MAX_ITERATIONS_EXCEEDED\"\n    };\n}\n\n// === 3. LECTURE DES T\u00c2CHES ===\nlet dbTasks = [];\nlet currentTask = null;\nlet isFromFallback = false;\n\n// Check fallback\ntry {\n    const fallbackData = $node['\ud83d\udd04 Fallback Dispatch']?.json;\n    if (fallbackData?.current_task?.status === 'pending') {\n        currentTask = fallbackData.current_task;\n        isFromFallback = true;\n        console.log(`[${traceId}] From fallback: task ${currentTask.task_id}`);\n    }\n} catch (e) {}\n\n// Lecture depuis input\nif (!currentTask) {\n    try {\n        const allItems = $input.all();\n        if (allItems?.length > 0) {\n            dbTasks = allItems.map(item => item.json).filter(t => t && t.task_id);\n            console.log(`[${traceId}] Read ${dbTasks.length} tasks from input`);\n        }\n    } catch (e) {\n        const inputData = $json;\n        if (Array.isArray(inputData)) {\n            dbTasks = inputData;\n        } else if (inputData?.task_id) {\n            dbTasks = [inputData];\n        }\n    }\n    \n    // Fallback premi\u00e8re ex\u00e9cution\n    if (dbTasks.length === 0) {\n        try {\n            dbTasks = $node['\ud83d\udcdd Format & Dispatch (Plan\u2192DB)'].json.tasks_to_insert || [];\n            console.log(`[${traceId}] First run: ${dbTasks.length} tasks`);\n        } catch (e) {}\n    }\n}\n\n// === 4. ANALYSE DES T\u00c2CHES ===\nif (!currentTask && dbTasks.length > 0) {\n    const pendingTasks = dbTasks.filter(t => t.status === 'pending');\n    const completedTasks = dbTasks.filter(t => t.status === 'complete');\n    const errorTasks = dbTasks.filter(t => t.status === 'error');\n    const skippedTasks = dbTasks.filter(t => t.status === 'skipped');\n    \n    const total = dbTasks.length;\n    \n    console.log(`[${traceId}] Tasks: ${pendingTasks.length} pending, ${completedTasks.length} complete, ${skippedTasks.length} skipped, ${errorTasks.length} error`);\n    \n    // === 5. ALL COMPLETE ===\n    if (pendingTasks.length === 0) {\n        console.log(`[${traceId}] \u2705 ALL COMPLETE - routing to Response Builder`);\n        \n        // MARQUER COMME TERMIN\u00c9 pour \u00e9viter re-trigger\n        staticData[completeKey] = true;\n        delete staticData.loopCounters[loopKey];\n        \n        // Formatter les r\u00e9sultats pour Response Builder\n        const formattedCompleted = completedTasks.map(t => {\n            let sources = t.sources || [];\n            if (typeof sources === 'string') {\n                try { sources = JSON.parse(sources); } catch (e) { sources = []; }\n            }\n            return {\n                task_id: t.task_id,\n                rag_called: t.rag_called,\n                query: t.query,\n                response: t.response || '',\n                confidence: parseFloat(t.confidence) || 0.5,\n                sources: sources\n            };\n        });\n        \n        // Construire all_responses\n        const allResponses = formattedCompleted\n            .filter(t => t.response && t.response.length > 10)\n            .map(t => ({\n                task_id: t.task_id,\n                rag: t.rag_called,\n                response: t.response,\n                confidence: t.confidence\n            }));\n        \n        // Calculer la meilleure r\u00e9ponse\n        let bestResponse = '';\n        let bestConfidence = 0;\n        for (const resp of allResponses) {\n            if (resp.confidence > bestConfidence) {\n                bestConfidence = resp.confidence;\n                bestResponse = resp.response;\n            }\n        }\n        \n        console.log(`[${traceId}] Best response: ${bestResponse.length} chars, confidence ${bestConfidence}`);\n        \n        // === OUTPUT COMPLET POUR RESPONSE BUILDER ===\n        return {\n            all_complete: true,\n            trace_id: traceId,\n            is_chat: isChat,\n            original_query: originalQuery,\n            \n            // Donn\u00e9es pour Response Builder\n            completed_tasks: formattedCompleted,\n            all_responses: allResponses,\n            pending_tasks: [],\n            error_tasks: errorTasks.map(t => ({\n                task_id: t.task_id,\n                rag_called: t.rag_called,\n                error_message: t.error_message || 'Unknown'\n            })),\n            skipped_tasks: skippedTasks.map(t => ({\n                task_id: t.task_id,\n                rag_called: t.rag_called\n            })),\n            \n            // Pr\u00e9-calculer pour Response Builder\n            final_response: bestResponse,\n            confidence: bestConfidence,\n            \n            // Stats\n            total_tasks: total,\n            summary: {\n                completed: completedTasks.length,\n                pending: 0,\n                errors: errorTasks.length,\n                skipped: skippedTasks.length\n            }\n        };\n    }\n    \n    // === 6. NEXT TASK ===\n    currentTask = pendingTasks[0];\n    console.log(`[${traceId}] Next: task ${currentTask.task_id} \u2192 ${currentTask.rag_called}`);\n}\n\n// === 7. VALIDATION ===\nif (!currentTask?.rag_called) {\n    console.error(`[${traceId}] No valid task found`);\n    staticData[completeKey] = true;\n    \n    return {\n        all_complete: true,\n        trace_id: traceId,\n        is_chat: isChat,\n        original_query: originalQuery,\n        completed_tasks: [],\n        all_responses: [],\n        final_response: \"Aucune t\u00e2che valide trouv\u00e9e.\",\n        error: \"NO_VALID_TASK\"\n    };\n}\n\n// === 8. NORMALIZE RAG ===\nconst ragName = String(currentTask.rag_called).toUpperCase().trim();\nconst validRags = ['STANDARD', 'GRAPH', 'QUANTITATIVE'];\nconst normalizedRag = validRags.includes(ragName) ? ragName : 'STANDARD';\n\nconsole.log(`[${traceId}] Executing: ${normalizedRag}`);\n\n// === 9. OUTPUT POUR DYNAMIC SWITCH ===\nreturn {\n    all_complete: false,\n    trace_id: traceId,\n    is_chat: isChat,\n    original_query: originalQuery,\n    \n    current_task: {\n        ...currentTask,\n        rag_called: normalizedRag,\n        trace_id: traceId\n    },\n    route_to: normalizedRag,\n    task_id: currentTask.task_id,\n    task_query: currentTask.query,\n    attempt: currentTask.attempt || 1,\n    is_fallback: isFromFallback,\n    iteration: currentIteration\n};\n"
      },
      "id": "e234ca05-5574-404b-b92b-43f9db307ae7",
      "name": "\u2699\ufe0f Execution Engine V10",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        21376,
        22288
      ]
    },
    {
      "parameters": {
        "rules": {
          "values": [
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "leftValue": "={{ $json.route_to }}",
                    "rightValue": "STANDARD",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "id": "a54bbcc1-b6ef-4975-b887-1b300668f194"
                  }
                ],
                "combinator": "and"
              }
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "leftValue": "={{ $json.route_to }}",
                    "rightValue": "GRAPH",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "id": "21dd21c6-f1b2-4d94-addf-2480f828b96f"
                  }
                ],
                "combinator": "and"
              }
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "leftValue": "={{ $json.route_to }}",
                    "rightValue": "QUANTITATIVE",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "id": "06843e71-20ab-456a-a49f-4f17db5ff26e"
                  }
                ],
                "combinator": "and"
              }
            }
          ]
        },
        "options": {
          "fallbackOutput": "none"
        }
      },
      "id": "2813f987-c594-4ae1-9942-9fbeadd78b9d",
      "name": "\ud83d\udd00 Dynamic Switch V10",
      "type": "n8n-nodes-base.switch",
      "typeVersion": 3.2,
      "position": [
        21616,
        22400
      ]
    },
    {
      "parameters": {
        "jsCode": "// ============================================\n// PATCH - Task Result Handler V10.1.3\n// FIX: Parsing robuste multi-format + fallback_response\n// ============================================\n//\n// PROBL\u00c8MES R\u00c9SOLUS:\n// 1. Ne lisait pas le format fallback_response du Standard RAG\n// 2. Graph RAG: pas de v\u00e9rification du flag fallback\n// 3. Confidence toujours \u00e0 0 car mauvais parsing\n//\n// INSTRUCTIONS:\n// 1. Ouvrir workflow \"V10.1 orchestrator copy\" (FZxkpldDbgV8AD_cg7IWG)\n// 2. \u00c9diter le n\u0153ud \"\ud83d\udce5 Task Result Handler\"\n// 3. Remplacer tout le code par celui-ci\n// 4. Sauvegarder et tester\n// ============================================\n\nconst workflowResult = $json;\nconst currentTask = $node['\u2699\ufe0f Execution Engine V10'].json.current_task;\nconst traceId = $node['Init V8 Security & Analysis'].json.trace_id;\n\nlet response = '';\nlet sources = [];\nlet confidence = 0;\nlet error = null;\nlet success = false;\nlet formatDetected = 'unknown';\n\n// === FORMAT 0: Fallback Response (Standard RAG skip_llm=true) ===\nif (workflowResult.fallback_response) {\n  formatDetected = 'fallback_response';\n  response = workflowResult.fallback_response.response || '';\n  sources = workflowResult.fallback_response.sources || [];\n  confidence = workflowResult.fallback_response.confidence || 0.1;\n  success = response.length > 10;\n}\n// === FORMAT 1: Standard RAG direct (avec engine marker) ===\nelse if (workflowResult.engine === 'STANDARD' && workflowResult.response) {\n  formatDetected = 'standard_rag';\n  response = workflowResult.response;\n  sources = (workflowResult.sources || []).map(s => ({\n    source: s.source || 'document',\n    content: s.excerpt || s.content || '',\n    score: s.score || s.combined_score || 0\n  }));\n  confidence = workflowResult.confidence || 0.5;\n  success = response.length > 10;\n}\n// === FORMAT 2: Graph RAG nested (budgeted_context) ===\nelse if (workflowResult.status === 'SUCCESS' && workflowResult.response) {\n  const nestedResponse = workflowResult.response;\n  \n  if (nestedResponse.budgeted_context) {\n    formatDetected = 'graph_rag';\n    const ctx = nestedResponse.budgeted_context;\n    \n    // Check for fallback mode (no real graph traversal)\n    const isFallback = nestedResponse.fallback === true;\n    const traversalDepth = nestedResponse.traversal_depth || 0;\n    const hasGraphData = ctx.graph && ctx.graph.length > 0;\n    const hasRelationships = ctx.relationships && ctx.relationships.length > 10;\n    const hasValidData = hasGraphData || hasRelationships;\n    \n    if (isFallback || (!hasValidData && traversalDepth === 0)) {\n      // Graph traversal failed - mark as failure to trigger fallback\n      success = false;\n      error = `Graph RAG fallback: no data (fallback=${isFallback}, depth=${traversalDepth})`;\n      console.log(`[${traceId}] Graph RAG returned no useful data - will trigger fallback`);\n    } else {\n      response = ctx.relationships || '';\n      \n      // Combine graph and vector sources\n      const graphSources = (ctx.graph || []).map(s => ({\n        source: s.source || s.id || 'graph_entity',\n        content: s.content || s.properties || '',\n        type: 'graph'\n      }));\n      const vectorSources = (ctx.vector || []).map(s => ({\n        source: s.source || s.id || 'vector_doc',\n        content: s.content || '',\n        type: 'vector'\n      }));\n      sources = [...graphSources, ...vectorSources];\n      confidence = 0.6;\n      success = response.length > 10 || sources.length > 0;\n    }\n  }\n}\n// === FORMAT 3: Quantitative RAG (SQL interpretation) ===\nelse if (workflowResult.interpretation) {\n  formatDetected = 'quantitative_rag';\n  response = workflowResult.interpretation;\n  sources = (workflowResult.raw_results || []).map((r, i) => ({\n    source: `SQL Result ${i + 1}`,\n    content: JSON.stringify(r).substring(0, 500),\n    type: 'sql'\n  }));\n  confidence = 0.7;\n  success = true;\n}\n// === FORMAT 4: Generic response (simple format) ===\nelse if (workflowResult.response) {\n  formatDetected = 'generic';\n  response = typeof workflowResult.response === 'string' \n    ? workflowResult.response \n    : JSON.stringify(workflowResult.response);\n  sources = workflowResult.sources || [];\n  confidence = workflowResult.confidence || 0.5;\n  success = response.length > 10;\n}\n// === FORMAT 5: Answer field (some workflows) ===\nelse if (workflowResult.answer) {\n  formatDetected = 'answer_field';\n  response = workflowResult.answer;\n  sources = [];\n  confidence = 0.5;\n  success = response.length > 10;\n}\n// === FORMAT 6: Explicit error ===\nelse if (workflowResult.error || workflowResult.errorMessage) {\n  formatDetected = 'error';\n  error = workflowResult.error || workflowResult.errorMessage;\n  if (typeof error === 'object') {\n    error = error.message || JSON.stringify(error);\n  }\n  success = false;\n}\n// === FORMAT 7: Empty result (no documents) ===\nelse if (workflowResult.result_count === 0 || workflowResult.has_results === false) {\n  formatDetected = 'empty_result';\n  response = \"Aucun document pertinent trouv\u00e9.\";\n  confidence = 0.1;\n  success = false; // Trigger fallback\n}\n// === FORMAT 8: Unrecognized ===\nelse {\n  formatDetected = 'unrecognized';\n  console.log(`[${traceId}] Unrecognized format. Keys: ${Object.keys(workflowResult).join(', ')}`);\n  \n  // Try to extract anything useful\n  const possibleResponse = workflowResult.text || workflowResult.content || workflowResult.output || '';\n  if (possibleResponse && possibleResponse.length > 10) {\n    response = possibleResponse;\n    confidence = 0.3;\n    success = true;\n  } else {\n    success = false;\n    error = 'Unrecognized response format';\n  }\n}\n\n// === VALIDATION FINALE ===\nconst hasValidResponse = response && String(response).trim().length > 10;\nconst finalSuccess = success && (hasValidResponse || sources.length > 0);\n\n// Ensure confidence is a valid number\nif (typeof confidence !== 'number' || isNaN(confidence)) {\n  confidence = finalSuccess ? 0.5 : 0.1;\n}\n\nconsole.log(`[${traceId}] Task ${currentTask.task_id} (${currentTask.rag_called}): ${finalSuccess ? 'SUCCESS' : 'FAILED'}`);\nconsole.log(`[${traceId}]   Format: ${formatDetected}, Response: ${response.length} chars, Sources: ${sources.length}, Confidence: ${confidence.toFixed(4)}`);\n\nif (error) {\n  console.log(`[${traceId}]   Error: ${error}`);\n}\n\n// === OUTPUT ===\nreturn {\n  task: currentTask,\n  success: finalSuccess,\n  response: response,\n  sources: sources.slice(0, 10),\n  confidence: confidence,\n  error_message: error,\n  trace_id: traceId,\n  format_detected: formatDetected,\n  raw_result: workflowResult // Pour debug\n};"
      },
      "id": "69968841-95e5-4717-9acd-9a80d2b3a215",
      "name": "\ud83d\udce5 Task Result Handler",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        22128,
        22336
      ]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "UPDATE rag_task_executions\nSET \n  status = $1,\n  response = $2,\n  error_message = $3,\n  sources = $4::jsonb,\n  updated_at = NOW()\nWHERE trace_id = $5 \n  AND task_id = $6",
        "options": {
          "queryReplacement": "={{ [$json.success ? 'complete' : 'error', $json.response || '', $json.error_message || '', JSON.stringify($json.sources || []), $json.trace_id, $json.task.task_id] }}"
        }
      },
      "id": "6bd0234e-efea-4e89-8cf5-3448af22cbda",
      "name": "Postgres: Update Task",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        22224,
        21744
      ],
      "credentials": {
        "postgres": {
          "id": "zEr7jPswZNv6lWKu",
          "name": "Supabase PostgreSQL"
        }
      },
      "continueOnFail": true,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "jsCode": "// === FALLBACK MONITOR V10.1.6 - FIXED: Read from correct source ===\nconst traceId = $node['Init V8 Security & Analysis'].json.trace_id;\n\n// CORRECTION: Lire depuis Task Result Handler, PAS depuis $json\nconst taskHandlerData = $node['\ud83d\udce5 Task Result Handler'].json;\nconst currentTask = taskHandlerData.task || {};\n\n// Extraire les VRAIES donn\u00e9es (apr\u00e8s parsing)\nconst originalSuccess = taskHandlerData.success || false;\nconst response = taskHandlerData.response || '';\nconst sources = taskHandlerData.sources || [];\nconst confidence = taskHandlerData.confidence || 0;\nconst attempt = currentTask.attempt || 1;\nconst taskId = currentTask.task_id;\nconst errorMessage = taskHandlerData.error_message || '';\n\nconsole.log(`[${traceId}] Task ${taskId} - Validating: success=${originalSuccess}, response_length=${response.length}, sources=${sources.length}, confidence=${confidence.toFixed(4)}`);\n\n// === VALIDATION CRITERIA (FIXED) ===\nconst hasValidResponse = response && String(response).trim().length > 10;\nconst hasSources = Array.isArray(sources) && sources.length > 0;\n\n// Accept low reranker scores (often < 0.1) OR valid response\nconst hasMinConfidence = confidence >= 0.01 || hasValidResponse;\n\n// Determine if we have usable content\nconst hasUsableContent = hasValidResponse || hasSources;\n\n// Final success determination\nconst success = originalSuccess && hasUsableContent && hasMinConfidence;\n\n// === FAILURE REASON TRACKING ===\nlet failureReason = '';\nif (!originalSuccess) {\n  failureReason = 'execution_error';\n} else if (!hasUsableContent) {\n  if (!hasValidResponse && !hasSources) {\n    failureReason = 'empty_response_and_no_sources';\n  } else if (!hasValidResponse) {\n    failureReason = 'invalid_response_length';\n  } else {\n    failureReason = 'no_sources';\n  }\n} else if (!hasMinConfidence) {\n  failureReason = `low_confidence_${confidence.toFixed(4)}`;\n}\n\nif (!success) {\n  console.log(`[${traceId}] Task ${taskId} FAILED validation: ${failureReason} (RAG: ${currentTask.rag_called})`);\n} else {\n  console.log(`[${traceId}] Task ${taskId} SUCCESS (RAG: ${currentTask.rag_called}, confidence: ${confidence.toFixed(4)})`);\n}\n\n// === FALLBACK MAPPING ===\nconst FALLBACK_MAP = {\n  'STANDARD': { 1: 'GRAPH', 2: 'QUANTITATIVE' },\n  'GRAPH': { 1: 'STANDARD', 2: 'QUANTITATIVE' },\n  'QUANTITATIVE': { 1: 'STANDARD', 2: 'GRAPH' }\n};\n\nconst MAX_ATTEMPTS = 3;\nlet fallbackNeeded = false;\nlet nextRAG = currentTask.rag_called;\nlet nextAttempt = attempt;\n\n// === FALLBACK DECISION LOGIC ===\nif (!success) {\n  if (attempt < MAX_ATTEMPTS) {\n    fallbackNeeded = true;\n    nextAttempt = attempt + 1;\n    \n    const fallbacks = FALLBACK_MAP[currentTask.rag_called] || {};\n    nextRAG = fallbacks[attempt] || 'STANDARD';\n    \n    console.log(`[${traceId}] FALLBACK triggered: attempt ${nextAttempt}/${MAX_ATTEMPTS}, ${currentTask.rag_called} \u2192 ${nextRAG} (reason: ${failureReason})`);\n  } else {\n    fallbackNeeded = false;\n    console.log(`[${traceId}] MAX ATTEMPTS (${MAX_ATTEMPTS}) reached for task ${taskId}, marking as final failure`);\n  }\n} else {\n  fallbackNeeded = false;\n}\n\n// === OUTPUT ===\nreturn {\n  fallback_needed: fallbackNeeded,\n  task_id: taskId,\n  trace_id: traceId,\n  current_rag: currentTask.rag_called,\n  next_rag: nextRAG,\n  attempt: nextAttempt,\n  success: success,\n  response: response,\n  sources: sources,\n  confidence: confidence,\n  original_query: currentTask.query,\n  failure_reason: failureReason,\n  had_empty_response: !hasValidResponse,\n  had_no_sources: !hasSources,\n  validation_details: {\n    original_success: originalSuccess,\n    has_valid_response: hasValidResponse,\n    has_sources: hasSources,\n    has_min_confidence: hasMinConfidence,\n    response_length: response.length,\n    sources_count: sources.length,\n    confidence_value: confidence\n  }\n};"
      },
      "id": "760a5d3c-6e1e-4d91-aff1-eb0cf96a1c4e",
      "name": "\ud83d\udd04 Fallback Monitor V10",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        22400,
        21744
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "id-1",
              "leftValue": "={{ $json.fallback_needed }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "67332e02-80d8-4dfc-9d94-d1427dcefd26",
      "name": "IF: Fallback Needed?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        22576,
        21744
      ]
    },
    {
      "parameters": {
        "jsCode": "// === FALLBACK DISPATCH V10.1.2 - Pr\u00e9paration compl\u00e8te pour retry ===\nconst fb = $json;\nconst traceId = fb.trace_id;\n\nconsole.log(`[${traceId}] Dispatching fallback: task ${fb.task_id} \u2192 ${fb.next_rag} (attempt ${fb.attempt})`);\n\n// Construire une t\u00e2che compl\u00e8te pour le retry\nconst retriedTask = {\n  task_id: fb.task_id,\n  trace_id: traceId,\n  intent_id: fb.task?.intent_id || 'fallback',\n  status: 'pending',\n  rag_called: fb.next_rag,\n  attempt: fb.attempt,\n  query: fb.original_query,\n  confidence: 0.8,\n  // M\u00e9tadonn\u00e9es de fallback\n  is_fallback: true,\n  previous_rag: fb.current_rag,\n  failure_reason: fb.failure_reason\n};\n\nreturn {\n  // Pour Postgres: Update Fallback\n  trace_id: traceId,\n  task_id: fb.task_id,\n  new_status: 'pending',\n  new_rag: fb.next_rag,\n  new_attempt: fb.attempt,\n  \n  // Pour Dynamic Switch (route_to)\n  route_to: fb.next_rag,\n  \n  // T\u00e2che compl\u00e8te pour Execution Engine\n  current_task: retriedTask,\n  task_query: fb.original_query,\n  \n  // Pour debug\n  fallback_chain: [fb.current_rag, fb.next_rag],\n  all_complete: false\n};"
      },
      "id": "2aaeab2f-9a91-421e-b4a2-b9c9ab19b7be",
      "name": "\ud83d\udd04 Fallback Dispatch",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        22800,
        21776
      ]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "UPDATE rag_task_executions\nSET \n  status = 'pending',\n  rag_called = '{{ $json.new_rag }}',\n  attempt = {{ $json.new_attempt }},\n  updated_at = NOW()\nWHERE trace_id = '{{ $json.trace_id }}' \n  AND task_id = {{ $json.task_id }};\n",
        "options": {}
      },
      "id": "960461ba-c688-4993-98ec-1ea16be7d883",
      "name": "Postgres: Update Fallback",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        22960,
        21776
      ],
      "credentials": {
        "postgres": {
          "id": "zEr7jPswZNv6lWKu",
          "name": "Supabase PostgreSQL"
        }
      },
      "continueOnFail": true,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "jsCode": "// === CACHE STORAGE - Stocke les r\u00e9ponses simples ===\nconst finalResponse = $node['Response Builder V9'].json.final_response;\nconst initData = $node['Init V8 Security & Analysis'].json;\n\n// Pr\u00e9parer les donn\u00e9es de cache\nconst cacheKey = `faq:${initData.query_hash}`;\nconst cacheValue = JSON.stringify({\n  response: finalResponse,\n  timestamp: Date.now(),\n  query: initData.query\n});\n\nconsole.log(`[${initData.trace_id}] Storing in cache: ${cacheKey}`);\n\nreturn {\n  cache_key: cacheKey,\n  cache_value: cacheValue,\n  ttl: 3600,\n  trace_id: initData.trace_id\n};"
      },
      "id": "ca85038c-26c6-4002-b9c1-b231dc51e10f",
      "name": "\ud83d\udcbe Cache Storage",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        24320,
        22816
      ]
    },
    {
      "parameters": {
        "operation": "set",
        "key": "={{ $json.cache_key }}",
        "value": "={{ $json.cache_value }}",
        "keyType": "string",
        "expire": true,
        "ttl": "={{ $json.ttl }}"
      },
      "id": "c295072a-deaf-494d-84c7-6b569fc810e4",
      "name": "Redis: Set Cache",
      "type": "n8n-nodes-base.redis",
      "typeVersion": 1,
      "position": [
        24512,
        22816
      ],
      "credentials": {
        "redis": {
          "id": "O2KEPiv7VzgDG5ZX",
          "name": "Redis Upstash"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// ============================================\n// NODE: \ud83e\udde0 Memory Merger V10.1 (FIXED)\n// PURPOSE: Fusion Redis + Postgres avec gestion erreurs\n// ============================================\n\n// === 1. R\u00c9CUP\u00c9RER REDIS DATA ===\nlet redisData = {};\ntry {\n  redisData = $node['\ud83d\udee1\ufe0f Redis Failure Handler V10.1']?.json || {};\n} catch(e) {\n  console.log('Redis Failure Handler not found, trying raw Redis');\n  try {\n    redisData = $node['Redis: Fetch Conversation']?.json || {};\n    // Fallback parsing\n    if (redisData.data) {\n      try {\n        const parsed = JSON.parse(redisData.data || '{}');\n        redisData = {\n          conversation_history: parsed.history || [],\n          redis_available: true\n        };\n      } catch(e2) {\n        redisData = { conversation_history: [], redis_available: true };\n      }\n    }\n  } catch(e2) {\n    redisData = { conversation_history: [], redis_available: false };\n  }\n}\n\nconst initData = $node['Init V8 Security & Analysis'].json;\nconst traceId = redisData.trace_id || initData.trace_id;\n\n// Historique court terme (Redis)\nconst shortTermHistory = redisData.conversation_history || [];\n\n// === 2. R\u00c9CUP\u00c9RER POSTGRES DATA (AVEC GESTION ERREURS) ===\nlet postgresData = {};\nlet postgresAvailable = false;\n\ntry {\n  const pgResult = $node['Postgres L2/L3 Memory']?.json;\n  \n  // V\u00e9rifications multiples\n  if (pgResult && \n      !pgResult.error && \n      pgResult.entities_json !== null && \n      pgResult.entities_json !== undefined) {\n    \n    postgresData = pgResult;\n    postgresAvailable = true;\n    console.log(`[${traceId}] Postgres L2/L3 OK`);\n    \n  } else if (pgResult?.error) {\n    console.warn(`[${traceId}] Postgres L2/L3 ERROR:`, pgResult.error.message || pgResult.error);\n  } else {\n    console.log(`[${traceId}] Postgres L2/L3 empty (new user)`);\n  }\n  \n} catch (e) {\n  console.error(`[${traceId}] Postgres L2/L3 exception:`, e.message);\n}\n\n// === 3. FUSIONNER INTELLIGEMMENT ===\nlet entitiesJson = {};\nif (postgresData.entities_json) {\n  if (typeof postgresData.entities_json === 'string') {\n    try {\n      entitiesJson = JSON.parse(postgresData.entities_json);\n    } catch(e) {\n      entitiesJson = {};\n    }\n  } else {\n    entitiesJson = postgresData.entities_json;\n  }\n}\n\nconst lastIntent = postgresData.last_intent || 'UNKNOWN';\n\n// Construire contexte fusionn\u00e9\nconst mergedContext = {\n  recent_messages: shortTermHistory.slice(-10),\n  user_profile: postgresData.user_context || {},\n  user_preferences: postgresData.preferences || {},\n  entities_of_interest: entitiesJson,\n  last_intent: lastIntent,\n  conversation_id: initData.conversation_id,\n  session_id: initData.session_id,\n  trace_id: traceId,\n  query: initData.query,\n  query_hash: initData.query_hash,\n  redis_available: redisData.redis_available !== false,\n  postgres_available: postgresAvailable,\n  context_status: redisData.context_status || 'UNKNOWN'\n};\n\nconsole.log(`[${traceId}] Memory merged: ${shortTermHistory.length} msgs (Redis), ${postgresAvailable ? 'Postgres OK' : 'Postgres unavailable'}`);\n\nreturn mergedContext;"
      },
      "id": "771afac4-90da-4e02-a8e8-d4032075bb64",
      "name": "\ud83e\udde0 Memory Merger (Redis + Postgres)",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        17696,
        21888
      ]
    },
    {
      "parameters": {
        "jsCode": "// === ADVANCED GUARDRAILS - Prompt Injection, Jailbreak, Content Safety ===\nconst mergedContext = $json;\nconst query = mergedContext.query || '';\nconst traceId = mergedContext.trace_id;\n\n// Patterns de prompt injection\nconst INJECTION_PATTERNS = [\n  /ignore (previous|all) (instructions|prompts)/i,\n  /you are now|pretend (you are|to be)/i,\n  /system:|<\\|im_start\\|>|<\\|im_end\\|>/i,\n  /\\n\\nHuman:|\\n\\nAssistant:/i,\n  /<script|javascript:|onerror=|eval\\(/i,\n  /forget (everything|all)|disregard (previous|all)/i\n];\n\n// Patterns de jailbreak\nconst JAILBREAK_PATTERNS = [\n  /DAN|Do Anything Now/i,\n  /evil mode|developer mode/i,\n  /sudo mode|admin mode/i,\n  /without any (restrictions|limitations|ethical)/i\n];\n\n// Patterns de contenu sensible\nconst SENSITIVE_PATTERNS = [\n  /how to (make|create|build) (bomb|weapon|explosive)/i,\n  /hack|exploit|vulnerability|backdoor/i,\n  /(illegal|illicit) (drugs|substances)/i\n];\n\n// V\u00e9rifications\nconst hasInjection = INJECTION_PATTERNS.some(p => p.test(query));\nconst hasJailbreak = JAILBREAK_PATTERNS.some(p => p.test(query));\nconst hasSensitive = SENSITIVE_PATTERNS.some(p => p.test(query));\n\nconst isBlocked = hasInjection || hasJailbreak || hasSensitive;\n\nlet blockReason = null;\nif (hasInjection) blockReason = \"prompt_injection\";\nif (hasJailbreak) blockReason = \"jailbreak_attempt\";\nif (hasSensitive) blockReason = \"sensitive_content\";\n\nif (isBlocked) {\n  console.log(`[${traceId}] BLOCKED: ${blockReason}`);\n}\n\nreturn {\n  ...mergedContext,\n  guardrail_passed: !isBlocked,\n  guardrail_blocked: isBlocked,\n  block_reason: blockReason,\n  injection_detected: hasInjection,\n  jailbreak_detected: hasJailbreak,\n  sensitive_detected: hasSensitive\n};\n"
      },
      "id": "5195d53f-ba51-4531-a015-08d5a22b67ed",
      "name": "\ud83d\udee1\ufe0f Advanced Guardrails",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        17888,
        21888
      ]
    },
    {
      "parameters": {
        "conditions": {
          "boolean": [
            {
              "value1": "={{ $json.guardrail_passed }}",
              "value2": true
            }
          ]
        },
        "options": {}
      },
      "id": "dac0a336-6e67-4b4c-b5ae-80ff733d4414",
      "name": "IF: Guardrail Passed?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        18080,
        21888
      ]
    },
    {
      "parameters": {
        "respondWith": "text",
        "responseBody": "I cannot respond to this request because it contains inappropriate or potentially harmful content.",
        "options": {}
      },
      "id": "b6bd01b0-8d5f-47d3-9c7d-98de8d2e77ae",
      "name": "Return: Guardrail Blocked",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [
        18256,
        21952
      ]
    },
    {
      "parameters": {
        "rules": {
          "values": [
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "leftValue": "={{ $json.query_route }}",
                    "rightValue": "conversational",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "id": "09b9e899-fec1-4e05-a4ba-58262fb5c072"
                  }
                ],
                "combinator": "and"
              }
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "leftValue": "={{ $json.query_route }}",
                    "rightValue": "cache_check",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "id": "52bd6b24-bf82-48ff-b1aa-4d8266ade86f"
                  }
                ],
                "combinator": "and"
              }
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "dae8b9a1-a47c-490e-93d2-549bf166c3ab",
                    "leftValue": "={{ $json.query_route }}",
                    "rightValue": " direct_llm",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              }
            }
          ]
        },
        "options": {
          "fallbackOutput": "extra"
        }
      },
      "id": "3a29a41a-fe91-4c3d-bce6-ddc3206f734b",
      "name": "\ud83d\udd00 Query Router",
      "type": "n8n-nodes-base.switch",
      "typeVersion": 3.2,
      "position": [
        18528,
        21808
      ]
    },
    {
      "parameters": {
        "jsCode": "// === CONVERSATIONAL HANDLER - R\u00e9ponses directes conversationnelles ===\nconst context = $json;\nconst query = context.query.toLowerCase().trim();\nconst traceId = context.trace_id;\n\n// R\u00e9ponses template\nconst RESPONSES = {\n  'hi': \"Bonjour ! Comment puis-je vous aider aujourd'hui ?\",\n  'hello': \"Hello! How can I assist you today?\",\n  'bonjour': \"Bonjour ! Je suis l\u00e0 pour vous aider. Que puis-je faire pour vous ?\",\n  'thanks': \"De rien ! N'h\u00e9sitez pas si vous avez d'autres questions.\",\n  'thank you': \"You're welcome! Feel free to ask if you need anything else.\",\n  'merci': \"Avec plaisir ! Je reste \u00e0 votre disposition.\",\n  'bye': \"Au revoir ! \u00c0 bient\u00f4t.\",\n  'goodbye': \"Goodbye! Have a great day!\",\n  'ok': \"D'accord ! Y a-t-il autre chose ?\",\n  'yes': \"Parfait ! Que puis-je faire d'autre pour vous ?\",\n  'no': \"D'accord, n'h\u00e9sitez pas si vous changez d'avis.\"\n};\n\n// Trouver la r\u00e9ponse\nlet response = \"Je suis l\u00e0 pour vous aider. Que puis-je faire pour vous ?\";\nfor (const [pattern, resp] of Object.entries(RESPONSES)) {\n  if (query.includes(pattern)) {\n    response = resp;\n    break;\n  }\n}\n\nconsole.log(`[${traceId}] Conversational response generated`);\n\nreturn {\n  trace_id: traceId,\n  query: context.query,\n  response: response,\n  is_conversational: true,\n  conversation_id: context.conversation_id\n};\n"
      },
      "id": "b7212bb1-ec8d-45c3-b19a-919acd65f460",
      "name": "\ud83d\udcac Conversational Handler",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        18768,
        21712
      ]
    },
    {
      "parameters": {
        "respondWith": "text",
        "responseBody": "={{ $json.response }}",
        "options": {}
      },
      "id": "bb985081-d04e-41eb-a725-5169e456ad02",
      "name": "Return: Conversational",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [
        18928,
        21744
      ]
    },
    {
      "parameters": {
        "jsCode": "// === CACHE SEMANTIC SEARCH - Trouve questions similaires ===\nconst context = $json;\nconst query = context.query;\nconst queryHash = context.query_hash;\nconst traceId = context.trace_id;\n\n// Note: Ici on simule une recherche s\u00e9mantique\n// En production, on utiliserait un vector store (Pinecone, Qdrant, etc.)\n// ou Redis avec RedisSearch/RediSearch VSS\n\n// Pour l'instant, on checke juste le hash exact\n// Le node Redis suivant fera le vrai travail\n\nreturn {\n  ...context,\n  cache_search_query: queryHash,\n  semantic_search_enabled: true\n};\n"
      },
      "id": "8211b2d7-c032-4617-adcf-037d1b8c0b27",
      "name": "\ud83d\udd0e Cache Semantic Search",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        18768,
        21920
      ]
    },
    {
      "parameters": {
        "operation": "get",
        "key": "={{ 'faq:' + $json.query_hash }}",
        "options": {}
      },
      "id": "97a611eb-b47f-4066-b00d-6b0a6cda5650",
      "name": "Redis: Cache + Generator",
      "type": "n8n-nodes-base.redis",
      "typeVersion": 1,
      "position": [
        18944,
        21920
      ],
      "credentials": {
        "redis": {
          "id": "O2KEPiv7VzgDG5ZX",
          "name": "Redis Upstash"
        }
      }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{ $vars.OPENROUTER_BASE_URL || 'https://openrouter.ai/api/v1/chat/completions' }}",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "openRouterApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ {\n  \"model\": $vars.LLM_AGENT_MODEL || 'anthropic/claude-3-5-sonnet-20241022',\n  \"max_tokens\": 2000,\n  \"temperature\": 0.3,\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"You are the JUDGE of a multi-engine RAG system. Your role is to decide if the obtained results are sufficient to answer the user's question.\\n\\n=== YOUR ROLE ===\\n1. Analyze the user's ORIGINAL QUERY\\n2. Examine the OBTAINED RESPONSES from completed tasks\\n3. JUDGE whether these responses are sufficient to answer the query\\n4. Decide what to do with remaining pending tasks\\n\\n=== YOUR POSSIBLE DECISIONS ===\\n\\n**all_tasks_complete: true** \u2192 The obtained responses are sufficient to answer the user\\n- Set all pending tasks to SKIP\\n- The workflow will generate the final response\\n\\n**all_tasks_complete: false** \u2192 Information is still missing\\n- KEEP necessary pending tasks\\n- SKIP redundant pending tasks\\n- Optional: ADD new tasks\\n\\n=== JSON RESPONSE FORMAT ===\\n{\\n  \\\"all_tasks_complete\\\": true/false,\\n  \\\"judgment\\\": \\\"Explanation of why responses are sufficient or not\\\",\\n  \\\"actions\\\": [\\n    {\\\"action\\\": \\\"SKIP\\\", \\\"task_id\\\": 2, \\\"reason\\\": \\\"...\\\"},\\n    {\\\"action\\\": \\\"KEEP\\\", \\\"task_id\\\": 3, \\\"reason\\\": \\\"...\\\"}\\n  ],\\n  \\\"missing_info\\\": \\\"What is missing if all_tasks_complete=false\\\"\\n}\\n\\n=== RULES ===\\n- You MUST provide an action for EVERY pending task\\n- If all_tasks_complete=true, ALL pending tasks must be SKIP\\n- Do NOT handle fallbacks/errors (another system handles that)\\n- Respond ONLY with valid JSON\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"=== USER'S ORIGINAL QUERY ===\\n\" + $node['Init V8 Security & Analysis'].json.query + \"\\n\\n=== OBTAINED RESPONSES (completed tasks) ===\\n\" + JSON.stringify($node['\ud83d\udcca Task Status Aggregator'].json.completed_tasks || [], null, 2) + \"\\n\\n=== PENDING TASKS ===\\n\" + JSON.stringify($node['\ud83d\udcca Task Status Aggregator'].json.pending_tasks || [], null, 2) + \"\\n\\n=== ERROR TASKS ===\\n\" + JSON.stringify($node['\ud83d\udcca Task Status Aggregator'].json.error_tasks || [], null, 2) + \"\\n\\nAnalyze whether the obtained responses are sufficient to answer the original query. Return your decision in JSON.\"\n    }\n  ]\n} }}",
        "options": {
          "timeout": 30000
        }
      },
      "id": "65630655-5b38-4faa-9a4d-a30faa4ce90a",
      "name": "\ud83c\udfaf LLM 3: Agent Harness (Opus 4.5)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        22944,
        22096
      ],
      "credentials": {
        "httpHeaderAuth": {
          "id": "nTJdf91Z5vhsI7cm",
          "name": "Unstructured API"
        },
        "openRouterApi": {
          "id": "aTHBqnntMBApo0Dy",
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// ============================================\n// NODE: \ud83d\udcca Agent Decision Parser V10.3\n// PURPOSE: Parse LLM3 Agent Harness (JUGE) response\n// ============================================\n\nconst agentResponse = $json;\nconst traceId = $node['Init V8 Security & Analysis'].json.trace_id;\n\nlet decisions = null;\n\ntry {\n    // === 1. EXTRACT CONTENT FROM API RESPONSE ===\n    let content = '';\n    \n    // OpenRouter format: choices[0].message.content\n    if (agentResponse.choices?.[0]?.message?.content) {\n        content = agentResponse.choices[0].message.content;\n        console.log(`[${traceId}] Detected OpenRouter format`);\n    }\n    // Anthropic format: content[0].text\n    else if (agentResponse.content?.[0]?.text) {\n        content = agentResponse.content[0].text;\n        console.log(`[${traceId}] Detected Anthropic format`);\n    }\n    // Body wrapper (some API configs)\n    else if (agentResponse.body?.choices?.[0]?.message?.content) {\n        content = agentResponse.body.choices[0].message.content;\n        console.log(`[${traceId}] Detected wrapped OpenRouter format`);\n    }\n    // Anthropic body wrapper\n    else if (agentResponse.body?.content?.[0]?.text) {\n        content = agentResponse.body.content[0].text;\n        console.log(`[${traceId}] Detected wrapped Anthropic format`);\n    }\n    \n    if (!content) {\n        throw new Error('No content found in LLM response. Available keys: ' + Object.keys(agentResponse).join(', '));\n    }\n    \n    // === 2. CLEAN AND PARSE JSON ===\n    let cleanedContent = content.trim();\n    \n    // Remove markdown code blocks if present\n    cleanedContent = cleanedContent.replace(/```json\\s*/g, '').replace(/```\\s*/g, '');\n    \n    // Try to extract JSON object\n    const jsonMatch = cleanedContent.match(/\\{[\\s\\S]*\\}/);\n    if (jsonMatch) {\n        decisions = JSON.parse(jsonMatch[0]);\n    } else {\n        decisions = JSON.parse(cleanedContent);\n    }\n    \n    console.log(`[${traceId}] LLM3 Agent Harness parsed successfully`);\n    \n} catch (e) {\n    console.error(`[${traceId}] Agent parsing error: ${e.message}`);\n    console.error(`[${traceId}] Response structure: ${JSON.stringify(agentResponse, null, 2).substring(0, 500)}`);\n    \n    // Fallback: continue without modifications\n    decisions = {\n        all_tasks_complete: false,\n        judgment: 'Parse error - continuing with existing tasks',\n        actions: [],\n        missing_info: 'Unable to parse LLM3 response: ' + e.message\n    };\n}\n\n// === 3. EXTRACT DECISIONS ===\nconst allTasksComplete = decisions.all_tasks_complete === true;\nconst judgment = decisions.judgment || 'No judgment provided';\nconst actions = Array.isArray(decisions.actions) ? decisions.actions : [];\nconst missingInfo = decisions.missing_info || '';\n\n// === 4. LOGGING ===\nconsole.log(`[${traceId}] === LLM3 JUDGMENT ===`);\nconsole.log(`[${traceId}] all_tasks_complete: ${allTasksComplete}`);\nconsole.log(`[${traceId}] judgment: ${judgment}`);\nconsole.log(`[${traceId}] actions: ${actions.length}`);\n\nif (allTasksComplete) {\n    console.log(`[${traceId}] \u2705 LLM3 says: Responses are sufficient!`);\n} else {\n    console.log(`[${traceId}] \u23f3 LLM3 says: Missing info: ${missingInfo}`);\n}\n\nactions.forEach((action, idx) => {\n    console.log(`[${traceId}]   Action ${idx + 1}: ${action.action} task_id=${action.task_id} - ${action.reason || 'no reason'}`);\n});\n\n// === 5. OUTPUT ===\nreturn {\n    trace_id: traceId,\n    \n    // Main signal for Task Updater\n    all_tasks_complete: allTasksComplete,\n    judgment: judgment,\n    missing_info: missingInfo,\n    \n    // Actions array for Task Updater\n    actions: actions,\n    \n    // Compatibility with old format\n    plan_updated: actions.length > 0,\n    reasoning: judgment,\n    \n    // Debug info\n    _debug: {\n        actions_count: actions.length,\n        has_skip_actions: actions.some(a => a.action === 'SKIP'),\n        has_keep_actions: actions.some(a => a.action === 'KEEP'),\n        has_add_actions: actions.some(a => a.action === 'ADD')\n    }\n};"
      },
      "id": "4e969cfa-9585-4d55-b7dc-3809bd6b3284",
      "name": "\ud83d\udcca Agent Decision Parser",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        23104,
        22096
      ]
    },
    {
      "parameters": {
        "jsCode": "// ============================================\n// PATCH - Task Updater V10.6\n// FIX: Ne reboucle PAS quand all_tasks_complete=true\n// ============================================\n//\n// PROBL\u00c8ME R\u00c9SOLU:\n// Avant: Task Updater \u2192 Postgres: Apply Skips \u2192 Postgres: Get Current Tasks \u2192 Execution Engine\n// Cela causait une boucle m\u00eame apr\u00e8s que Response Builder ait fini!\n//\n// SOLUTION:\n// Quand all_tasks_complete=true, on NE FAIT PAS de skip dans la DB\n// car Execution Engine a d\u00e9j\u00e0 rout\u00e9 vers Response Builder.\n// Les t\u00e2ches pending seront ignor\u00e9es, pas besoin de les skipper.\n//\n// CHANGEMENT ARCHITECTURAL REQUIS:\n// Ajouter un IF node apr\u00e8s Task Updater:\n// - Si all_tasks_complete=true \u2192 NE PAS connecter \u00e0 Postgres: Apply Skips\n// - Si all_tasks_complete=false \u2192 Connecter normalement\n// ============================================\n\nconst parsed = $json;\nconst traceId = parsed.trace_id;\n\nconst allTasksComplete = parsed.all_tasks_complete === true;\nconst judgment = parsed.judgment || '';\nconst actions = parsed.actions || [];\n\nconsole.log(`[${traceId}] Task Updater V10.6`);\nconsole.log(`[${traceId}] all_tasks_complete: ${allTasksComplete}`);\n\n// === CAS 1: TERMINAISON - NE PAS REBOUCLER ===\nif (allTasksComplete) {\n    console.log(`[${traceId}] \u2705 TERMINAISON D\u00c9TECT\u00c9E`);\n    console.log(`[${traceId}] Judgment: ${judgment}`);\n    console.log(`[${traceId}] \u26a0\ufe0f NE PAS reboucler - Response Builder va g\u00e9rer`);\n    \n    // IMPORTANT: On ne fait PAS de skip_updates\n    // Car on ne veut PAS trigger Postgres: Apply Skips \u2192 Get Current Tasks \u2192 Execution Engine\n    // Execution Engine a d\u00e9j\u00e0 rout\u00e9 vers Response Builder via le IF node\n    \n    return {\n        trace_id: traceId,\n        all_tasks_complete: true,\n        should_loop: false,  // FLAG IMPORTANT pour le IF node\n        judgment: judgment,\n        skip_updates: [],    // VIDE - pas de reboucle\n        new_tasks: [],\n        total_skipped: 0,\n        total_added: 0,\n        has_pending_after: false\n    };\n}\n\n// === CAS 2: TRAVAIL RESTANT - Appliquer les actions ===\nconsole.log(`[${traceId}] \u23f3 Travail restant, ${actions.length} actions`);\n\n// R\u00e9cup\u00e9rer les t\u00e2ches pending\nlet pendingTasks = [];\nlet maxTaskId = 0;\ntry {\n    const dbResult = $('Postgres : Get Current Tasks').all();\n    const dbTasks = dbResult.map(item => item.json);\n    pendingTasks = dbTasks.filter(t => t.status === 'pending');\n    dbTasks.forEach(t => {\n        if (t.task_id > maxTaskId) maxTaskId = t.task_id;\n    });\n} catch (e) {\n    console.log(`[${traceId}] DB read error: ${e.message}`);\n}\n\nconst skips = [];\nconst newTasks = [];\n\nfor (const action of actions) {\n    if (action.action === 'SKIP') {\n        skips.push({\n            task_id: action.task_id,\n            trace_id: traceId,\n            reason: action.reason || 'LLM3 decision',\n            new_status: 'skipped'\n        });\n        console.log(`[${traceId}] SKIP task ${action.task_id}`);\n        \n    } else if (action.action === 'KEEP') {\n        console.log(`[${traceId}] KEEP task ${action.task_id}`);\n        \n    } else if (action.action === 'ADD' && action.new_task) {\n        const newTaskId = maxTaskId + newTasks.length + 1;\n        newTasks.push({\n            trace_id: traceId,\n            task_id: newTaskId,\n            intent_id: 'llm3_added',\n            status: 'pending',\n            rag_called: action.new_task.rag || 'STANDARD',\n            attempt: 1,\n            query: (action.new_task.query || '').replace(/'/g, \"''\"),\n            confidence: 0.8\n        });\n        console.log(`[${traceId}] ADD task ${newTaskId}`);\n    }\n}\n\nconst skippedIds = new Set(skips.map(s => s.task_id));\nconst remainingPending = pendingTasks.filter(t => !skippedIds.has(t.task_id));\nconst hasPendingAfter = remainingPending.length > 0 || newTasks.length > 0;\n\nconsole.log(`[${traceId}] Result: ${skips.length} skips, ${newTasks.length} adds, ${remainingPending.length} remaining`);\n\nreturn {\n    trace_id: traceId,\n    all_tasks_complete: false,\n    should_loop: true,  // FLAG pour le IF node - continuer la boucle\n    judgment: judgment,\n    skip_updates: skips,\n    new_tasks: newTasks,\n    total_skipped: skips.length,\n    total_added: newTasks.length,\n    has_pending_after: hasPendingAfter\n};\n"
      },
      "id": "04172aae-947d-4181-b3ca-cac2102249b3",
      "name": "\ud83d\udd04 Task Updater",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        23280,
        22080
      ]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "={{ $json.skip_updates && $json.skip_updates.length > 0 ? \n  \"UPDATE rag_task_executions SET status = 'skipped', updated_at = NOW() WHERE \" +\n  $json.skip_updates.map(s => `(trace_id = '${s.trace_id}' AND task_id = ${s.task_id})`).join(' OR ')\n  : \"SELECT 1\" \n}}",
        "options": {}
      },
      "id": "ba3d7b7d-adfb-423f-a43c-ce2b670484a2",
      "name": "Postgres: Apply Skips",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        23696,
        22208
      ],
      "credentials": {
        "postgres": {
          "id": "zEr7jPswZNv6lWKu",
          "name": "Supabase PostgreSQL"
        }
      },
      "continueOnFail": true,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "={{ $json.new_tasks && $json.new_tasks.length > 0 ? \"INSERT INTO rag_task_executions (trace_id, task_id, intent_id, status, rag_called, attempt, query, confidence) VALUES \" + $json.new_tasks.map(t => `('${t.trace_id}', ${t.task_id}, '${t.intent_id}', '${t.status}', '${t.rag_called}', ${t.attempt}, '${t.query}', ${t.confidence})`).join(', ') + \" ON CONFLICT (trace_id, task_id) DO NOTHING\" : \"SELECT 1\" }}",
        "options": {}
      },
      "id": "3501e6a9-d1e6-41c8-8298-1b310f2f05f0",
      "name": "Postgres: Insert New Tasks",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        23680,
        22416
      ],
      "credentials": {
        "postgres": {
          "id": "zEr7jPswZNv6lWKu",
          "name": "Supabase PostgreSQL"
        }
      },
      "continueOnFail": true,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "jsCode": "// ============================================\n// PATCH - Task Status Aggregator V10.4\n// FIX: Accumulation robuste des r\u00e9sultats pour Response Builder\n// ============================================\n//\n// PROBL\u00c8ME R\u00c9SOLU:\n// Le Response Builder V9.3 lit depuis staticData[`results_${traceId}`]\n// mais le Task Status Aggregator ne stockait pas toujours les r\u00e9sultats.\n//\n// SOLUTION:\n// 1. Toujours lire le r\u00e9sultat depuis Task Result Handler\n// 2. Toujours stocker dans staticData m\u00eame si pas de fallback\n// 3. Ajouter des logs pour debug\n//\n// INSTRUCTIONS:\n// 1. Ouvrir workflow \"V10.1 orchestrator copy\" (FZxkpldDbgV8AD_cg7IWG)\n// 2. \u00c9diter le n\u0153ud \"\ud83d\udcca Task Status Aggregator\"\n// 3. Remplacer tout le code par celui-ci\n// 4. Sauvegarder et tester\n// ============================================\n\nconst traceId = $node['Init V8 Security & Analysis'].json.trace_id;\nconst inputData = $json; // Donn\u00e9es du Fallback Monitor\n\nconsole.log(`[${traceId}] Task Status Aggregator V10.4 starting...`);\n\n// === 1. \u00c9TAT GLOBAL POUR ACCUMULATION ===\nconst staticData = $getWorkflowStaticData('global');\n\nconst resultsKey = `results_${traceId}`;\nif (!staticData[resultsKey]) {\n  staticData[resultsKey] = {\n    completed_tasks: [],\n    error_tasks: [],\n    skipped_tasks: [],\n    all_responses: []\n  };\n  console.log(`[${traceId}] Initialized results storage`);\n}\n\nconst accumulated = staticData[resultsKey];\n\n// === 2. LIRE LE R\u00c9SULTAT ACTUEL ===\n// IMPORTANT: Toujours lire depuis Task Result Handler\nlet currentResult = null;\n\ntry {\n  // Priorit\u00e9 1: Lire directement depuis Task Result Handler\n  const taskHandlerData = $node['\ud83d\udce5 Task Result Handler']?.json;\n  if (taskHandlerData) {\n    currentResult = {\n      task: taskHandlerData.task || {},\n      success: taskHandlerData.success || false,\n      response: taskHandlerData.response || '',\n      sources: taskHandlerData.sources || [],\n      confidence: taskHandlerData.confidence || 0,\n      error_message: taskHandlerData.error_message || null,\n      format_detected: taskHandlerData.format_detected || 'unknown'\n    };\n    console.log(`[${traceId}] Read from Task Result Handler: success=${currentResult.success}, format=${currentResult.format_detected}, response_length=${currentResult.response.length}`);\n  }\n} catch (e) {\n  console.log(`[${traceId}] Could not read Task Result Handler: ${e.message}`);\n}\n\n// Priorit\u00e9 2: Fallback Monitor (si disponible dans input)\nif (!currentResult && inputData && inputData.success !== undefined) {\n  currentResult = {\n    task: inputData.task || { task_id: inputData.task_id },\n    success: inputData.success,\n    response: inputData.response || '',\n    sources: inputData.sources || [],\n    confidence: inputData.confidence || 0,\n    error_message: inputData.failure_reason || null\n  };\n  console.log(`[${traceId}] Read from Fallback Monitor input`);\n}\n\n// === 3. AJOUTER LE R\u00c9SULTAT \u00c0 L'ACCUMULATION ===\nif (currentResult && currentResult.task) {\n  const taskId = currentResult.task.task_id;\n  const ragCalled = currentResult.task.rag_called || 'UNKNOWN';\n  \n  // \u00c9viter les doublons\n  const existsCompleted = accumulated.completed_tasks.some(t => t.task_id === taskId);\n  const existsError = accumulated.error_tasks.some(t => t.task_id === taskId);\n  \n  if (!existsCompleted && !existsError) {\n    if (currentResult.success) {\n      const completedTask = {\n        task_id: taskId,\n        rag_called: ragCalled,\n        response: currentResult.response || '',\n        sources: currentResult.sources || [],\n        confidence: currentResult.confidence || 0.5\n      };\n      \n      accumulated.completed_tasks.push(completedTask);\n      \n      // Ajouter \u00e0 all_responses pour la fusion\n      if (currentResult.response && currentResult.response.length > 10) {\n        accumulated.all_responses.push({\n          task_id: taskId,\n          rag: ragCalled,\n          response: currentResult.response,\n          confidence: currentResult.confidence || 0.5\n        });\n      }\n      \n      console.log(`[${traceId}] \u2705 Accumulated completed task ${taskId} (${ragCalled}): ${currentResult.response.length} chars, confidence=${currentResult.confidence}`);\n    } else {\n      accumulated.error_tasks.push({\n        task_id: taskId,\n        rag_called: ragCalled,\n        error_message: currentResult.error_message || 'Unknown error'\n      });\n      \n      console.log(`[${traceId}] \u274c Accumulated error task ${taskId} (${ragCalled}): ${currentResult.error_message}`);\n    }\n  } else {\n    console.log(`[${traceId}] Task ${taskId} already accumulated, skipping`);\n  }\n} else {\n  console.log(`[${traceId}] No valid current result to accumulate`);\n}\n\n// === 4. LIRE LE PLAN ORIGINAL POUR LE TOTAL ===\nlet totalTasks = 1;\nlet pendingTasks = [];\n\ntry {\n  const planData = $node['\ud83d\udcdd Format & Dispatch (Plan\u2192DB)'].json;\n  totalTasks = planData.total_tasks || planData.tasks_to_insert?.length || 1;\n  \n  // Calculer les pending\n  const completedIds = accumulated.completed_tasks.map(t => t.task_id);\n  const errorIds = accumulated.error_tasks.map(t => t.task_id);\n  const processedIds = [...completedIds, ...errorIds];\n  \n  const allTaskIds = (planData.tasks_to_insert || []).map(t => t.task_id);\n  pendingTasks = allTaskIds\n    .filter(id => !processedIds.includes(id))\n    .map(id => {\n      const task = planData.tasks_to_insert.find(t => t.task_id === id);\n      return {\n        task_id: id,\n        query: task?.query || '',\n        rag_called: task?.rag_called || 'STANDARD'\n      };\n    });\n    \n} catch (e) {\n  console.log(`[${traceId}] Could not read plan: ${e.message}`);\n}\n\n// === 5. CALCULER LES M\u00c9TRIQUES ===\nconst completedCount = accumulated.completed_tasks.length;\nconst errorCount = accumulated.error_tasks.length;\nconst pendingCount = pendingTasks.length;\nconst processedCount = completedCount + errorCount;\n\nconst completionRate = totalTasks > 0 ? processedCount / totalTasks : 0;\nconst avgConfidence = completedCount > 0 \n  ? accumulated.completed_tasks.reduce((sum, t) => sum + (t.confidence || 0), 0) / completedCount\n  : 0;\n\nconsole.log(`[${traceId}] Aggregation summary:`);\nconsole.log(`[${traceId}]   Completed: ${completedCount}, Errors: ${errorCount}, Pending: ${pendingCount}`);\nconsole.log(`[${traceId}]   Total tasks: ${totalTasks}, Completion: ${Math.round(completionRate * 100)}%`);\nconsole.log(`[${traceId}]   Avg confidence: ${avgConfidence.toFixed(4)}`);\nconsole.log(`[${traceId}]   All responses count: ${accumulated.all_responses.length}`);\n\n// === 6. DEBUG: Afficher les r\u00e9ponses accumul\u00e9es ===\nif (accumulated.all_responses.length > 0) {\n  accumulated.all_responses.forEach((r, i) => {\n    console.log(`[${traceId}]   Response ${i+1} (${r.rag}): ${r.response.substring(0, 100)}...`);\n  });\n}\n\n// === 7. FLAG DE COMPL\u00c9TION ===\nconst isComplete = pendingCount === 0;\n\n// === 8. OUTPUT ===\nreturn {\n  trace_id: traceId,\n  \n  // T\u00e2ches par statut\n  completed_tasks: accumulated.completed_tasks,\n  pending_tasks: pendingTasks,\n  error_tasks: accumulated.error_tasks,\n  \n  // R\u00e9ponses pour fusion (crucial pour Response Builder!)\n  accumulated_results: accumulated.completed_tasks,\n  all_responses: accumulated.all_responses,\n  \n  // M\u00e9triques\n  total_tasks: totalTasks,\n  completion_rate: completionRate,\n  average_confidence: avgConfidence,\n  \n  // Flags\n  has_failures: errorCount > 0,\n  has_pending: pendingCount > 0,\n  is_complete: isComplete,\n  \n  // R\u00e9sum\u00e9\n  summary: {\n    completed: completedCount,\n    pending: pendingCount,\n    errors: errorCount,\n    total: totalTasks,\n    completion_percentage: Math.round(completionRate * 100)\n  },\n  \n  // Debug info\n  _debug: {\n    results_key: resultsKey,\n    staticData_has_key: !!staticData[resultsKey],\n    responses_accumulated: accumulated.all_responses.length\n  }\n};\n"
      },
      "id": "11209e3f-7603-46d2-be3a-995b47251435",
      "name": "\ud83d\udcca Task Status Aggregator",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        22784,
        22112
      ]
    },
    {
      "parameters": {
        "jsCode": "// ============================================\n// NODE: Redis Failure Handler V10.1\n// PURPOSE: Graceful degradation si Redis down\n// ============================================\n\nconst redisData = $json;\nconst redisError = redisData.error || null;\n\n// R\u00e9cup\u00e9rer trace_id depuis Init\nlet traceId = 'unknown';\ntry {\n  traceId = $node['Init V8 Security & Analysis'].json.trace_id;\n} catch(e) {\n  traceId = `fallback-${Date.now()}`;\n}\n\n// === CAS 1: REDIS ERROR (service down) ===\nif (redisError) {\n  console.error(`[${traceId}] REDIS_FAILURE:`, {\n    error: redisError.message || 'Unknown',\n    timestamp: new Date().toISOString(),\n    trace_id: traceId\n  });\n  \n  return {\n    conversation_history: [],\n    context_status: 'DEGRADED',\n    redis_available: false,\n    warning: 'Redis unavailable - running in stateless mode',\n    trace_id: traceId\n  };\n}\n\n// === CAS 2: REDIS OK - Parser les donn\u00e9es ===\ntry {\n  const rawData = redisData.data;\n  \n  // Si pas de data \u2192 conversation nouvelle\n  if (!rawData || rawData === null || rawData === 'null') {\n    console.log(`[${traceId}] New conversation - no Redis data`);\n    return {\n      conversation_history: [],\n      context_status: 'NEW',\n      redis_available: true,\n      trace_id: traceId\n    };\n  }\n  \n  // Parser le JSON\n  const parsedData = JSON.parse(rawData);\n  const history = parsedData.history || [];\n  \n  console.log(`[${traceId}] Redis OK: ${history.length} messages in history`);\n  \n  return {\n    conversation_history: history,\n    context_status: 'FULL',\n    redis_available: true,\n    trace_id: traceId\n  };\n  \n} catch (parseError) {\n  // === CAS 3: REDIS DATA CORRUPTED ===\n  console.error(`[${traceId}] REDIS_PARSE_ERROR:`, parseError.message);\n  \n  return {\n    conversation_history: [],\n    context_status: 'CORRUPTED',\n    redis_available: true,\n    warning: 'Redis data corrupted - starting fresh',\n    trace_id: traceId\n  };\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        17408,
        22624
      ],
      "id": "c7ee4ae3-47e2-44d7-b012-f138a2ed80c3",
      "name": "\ud83d\udee1\ufe0f Redis Failure Handler V10.1"
    },
    {
      "parameters": {
        "jsCode": "// ============================================\n// NODE: Context Compression V10.1\n// ============================================\n\nconst mergedContext = $json;\nconst conversationHistory = mergedContext.recent_messages || [];\nconst traceId = mergedContext.trace_id;\n\n// 3 derniers messages seulement\nconst recentHistory = conversationHistory.slice(-3);\n\n// R\u00e9sum\u00e9 compress\u00e9 des anciens\nlet compressedSummary = '';\nif (conversationHistory.length > 3) {\n  const olderHistory = conversationHistory.slice(0, -3);\n  compressedSummary = olderHistory\n    .map(h => h.query || h.message || '')\n    .filter(q => q.length > 0)\n    .join(' | ')\n    .substring(0, 500);\n}\n\n// D\u00e9tecter changement d'intention\nconst lastIntent = mergedContext.last_intent;\nconst intentionShift = lastIntent && lastIntent !== 'UNKNOWN';\n\n// Tokens \u00e9conomis\u00e9s\nconst originalTokens = conversationHistory.reduce((sum, h) => \n  sum + (h.query?.length || 0) + (h.response?.length || 0), 0) / 4;\nconst compressedTokens = recentHistory.reduce((sum, h) => \n  sum + (h.query?.length || 0) + (h.response?.length || 0), 0) / 4;\nconst tokensSaved = Math.max(0, originalTokens - compressedTokens);\n\nconsole.log(`[${traceId}] Compressed: ${conversationHistory.length} \u2192 ${recentHistory.length} msgs, ~${Math.round(tokensSaved)} tokens saved`);\n\nreturn {\n  ...mergedContext,\n  compressed_history: recentHistory,\n  compressed_summary: compressedSummary,\n  full_history_length: conversationHistory.length,\n  intention_shift: intentionShift,\n  tokens_saved: Math.round(tokensSaved)\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        17792,
        21728
      ],
      "id": "ee9b5dbc-f858-451d-bf3e-2dabf78bdffe",
      "name": "\ud83d\udce6 Context Compression V10.1"
    },
    {
      "parameters": {
        "jsCode": "// ============================================\n// NODE: \ud83d\udd0d Query Classifier V10.1 + Adaptive Retrieval Gate\n// ============================================\n\nconst context = $json;\nconst query = context.query || '';\nconst traceId = context.trace_id;\nconst recentMessages = context.compressed_history || context.recent_messages || [];\n\n// === 1. CONVERSATIONAL DETECTION ===\nconst CONVERSATIONAL_PATTERNS = [\n  /^(hi|hello|hey|bonjour|salut)/i,\n  /^(thanks|thank you|merci)/i,\n  /^(ok|okay|yes|no|oui|non)$/i,\n  /^(bye|goodbye|au revoir)/i,\n  /how are you|comment (vas-tu|allez-vous)/i,\n  /can you help me/i\n];\n\nconst isConversational = \n  CONVERSATIONAL_PATTERNS.some(p => p.test(query)) ||\n  query.length < 5 ||\n  (recentMessages.length > 0 && query.split(' ').length < 5);\n\n// === 2. CACHE CHECK ===\nconst shouldCheckCache = \n  !isConversational && \n  query.length > 10 && \n  query.length < 200;\n\n// === 3. ADAPTIVE RETRIEVAL GATE ===\nconst RETRIEVAL_REQUIRED = [\n  /combien|quel.*total|quelle.*somme/i,\n  /qui.*responsable|quelle.*relation/i,\n  /selon|d'apr\u00e8s|dans.*document|notre/i,\n  /proc\u00e9dure|process|\u00e9tape|comment faire/i,\n  /politique|r\u00e8gle|r\u00e8glement/i\n];\n\nconst DIRECT_ANSWER = [\n  /qu'est-ce qu'un|d\u00e9finition de|c'est quoi/i,\n  /explique.*concept|comment.*fonctionne/i\n];\n\nlet needsRetrieval = true;\nlet retrievalReason = 'DEFAULT';\n\nfor (const pattern of RETRIEVAL_REQUIRED) {\n  if (pattern.test(query)) {\n    needsRetrieval = true;\n    retrievalReason = 'DOMAIN_SPECIFIC';\n    break;\n  }\n}\n\nif (retrievalReason === 'DEFAULT') {\n  for (const pattern of DIRECT_ANSWER) {\n    if (pattern.test(query)) {\n      needsRetrieval = false;\n      retrievalReason = 'GENERAL_KNOWLEDGE';\n      break;\n    }\n  }\n}\n\n// === 4. ROUTE DECISION ===\nlet route = 'agent';\n\nif (isConversational) {\n  route = 'conversational';\n} else if (shouldCheckCache) {\n  route = 'cache_check';\n} else if (!needsRetrieval) {\n  route = 'direct_llm';\n}\n\nconsole.log(`[${traceId}] Route: ${route}, Retrieval: ${needsRetrieval} (${retrievalReason})`);\n\nreturn {\n  ...context,\n  query_route: route,\n  is_conversational: isConversational,\n  should_check_cache: shouldCheckCache,\n  needs_retrieval: needsRetrieval,\n  retrieval_reason: retrievalReason\n};\n"
      },
      "id": "9e99068a-a937-4369-99d4-b3b062c83ac4",
      "name": "\ud83d\udd0d Query Classifier V10.1",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        18256,
        21904
      ]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{ $vars.OPENROUTER_BASE_URL || 'https://openrouter.ai/api/v1' }}/chat/completions",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "openRouterApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"{{ $vars.LLM_FAST_MODEL || 'google/gemini-2.5-flash' }}\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"Tu es l'INTENT ANALYZER d'un syst\u00e8me RAG multi-moteurs sophistiqu\u00e9.\\n\\n=== TA MISSION ===\\n1. Analyser la query utilisateur\\n2. Identifier TOUS les intents (explicites ET implicites)\\n3. D\u00e9terminer les D\u00c9PENDANCES entre intents\\n4. Assigner le moteur RAG optimal pour chaque intent\\n\\n=== MOTEURS RAG DISPONIBLES ===\\n\\n**STANDARD (Pinecone + BM25)**\\n- Forces: faits, proc\u00e9dures, d\u00e9finitions\\n\\n**GRAPH (Neo4j)**\\n- Forces: relations, hi\u00e9rarchies, impacts\\n\\n**QUANTITATIVE (PostgreSQL)**\\n- Forces: chiffres, totaux, moyennes, KPIs\\n\\n=== FORMAT JSON STRICT ===\\n{\\n  \\\"reasoning\\\": \\\"<ton analyse>\\\",\\n  \\\"intents\\\": [{\\\"id\\\": \\\"intent-1\\\", \\\"type\\\": \\\"FACTUAL|QUANTITATIVE|RELATIONAL\\\", \\\"suggested_rag\\\": \\\"STANDARD|GRAPH|QUANTITATIVE\\\", \\\"priority\\\": 1}],\\n  \\\"execution_order\\\": [\\\"intent-1\\\"],\\n  \\\"complexity\\\": \\\"SIMPLE|MODERATE|COMPLEX\\\"\\n}\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"=== QUERY TO ANALYZE ===\\n{{ $node['Init V8 Security & Analysis'].json.query }}\"\n    }\n  ],\n  \"temperature\": 0.1,\n  \"max_tokens\": 800,\n  \"response_format\": { \"type\": \"json_object\" }\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        19056,
        22496
      ],
      "id": "6bfcc7d3-9915-43c4-abd9-4c299b5dd4b1",
      "name": "HTTP Request",
      "credentials": {
        "openRouterApi": {
          "id": "aTHBqnntMBApo0Dy",
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT task_id, intent_id, status, rag_called, attempt, query, response, confidence\nFROM rag_task_executions \nWHERE trace_id = '{{ $node[\"Init V8 Security & Analysis\"].json.trace_id }}'\nORDER BY task_id ASC",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        21216,
        22528
      ],
      "id": "7fa85861-eefe-48f9-a03c-7dad6fc40c94",
      "name": "Postgres : Get Current Tasks",
      "credentials": {
        "postgres": {
          "id": "zEr7jPswZNv6lWKu",
          "name": "Supabase PostgreSQL"
        }
      }
    },
    {
      "parameters": {
        "numberInputs": 4
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        24864,
        22160
      ],
      "id": "713d6797-3083-4119-a1b3-a86bcf0b5c77",
      "name": "Merge",
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 3
          },
          "conditions": [
            {
              "id": "ebee2253-8093-451a-bf3b-5b00e78fdc69",
              "leftValue": "={{ $json.all_complete }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.3,
      "position": [
        21504,
        22816
      ],
      "id": "357e6360-0498-4633-b5f8-30061ecd941a",
      "name": "If"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 3
          },
          "conditions": [
            {
              "id": "f64b093e-7578-418f-aa48-03ebc26d5a02",
              "leftValue": "={{$json.all_tasks_complete}}",
              "rightValue": false,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.3,
      "position": [
        23504,
        21984
      ],
      "id": "ea57ed6e-ec10-4c32-9600-d5859f56d625",
      "name": "If1"
    }
  ],
  "connections": {
    "Webhook V8": {
      "main": [
        [
          {
            "node": "Input Merger V8",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Chat Trigger V8": {
      "main": [
        [
          {
            "node": "Input Merger V8",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Input Merger V8": {
      "main": [
        [
          {
            "node": "Init V8 Security & Analysis",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Init V8 Security & Analysis": {
      "main": [
        [
          {
            "node": "Redis: Fetch Conversation",
            "type": "main",
            "index": 0
          },
          {
            "node": "Postgres L2/L3 Memory",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Redis: Fetch Conversation": {
      "main": [
        [
          {
            "node": "\ud83d\udee1\ufe0f Redis Failure Handler V10.1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "\ud83d\udee1\ufe0f Rate Limit Guard": {
      "main": [
        [
          {
            "node": "IF: Rate Limited?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "IF: Rate Limited?": {
      "main": [
        [
          {
            "node": "\ud83e\udde0 Memory Merger (Redis + Postgres)",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Return: Rate Limited",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Postgres L2/L3 Memory": {
      "main": [
        [
          {
            "node": "\ud83e\udde0 Memory Merger (Redis + Postgres)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "\ud83e\udde0 Memory Merger (Redis + Postgres)": {
      "main": [
        [
          {
            "node": "\ud83d\udce6 Context Compression V10.1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "\ud83d\udee1\ufe0f Advanced Guardrails": {
      "main": [
        [
          {
            "node": "IF: Guardrail Passed?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "IF: Guardrail Passed?": {
      "main": [
        [
          {
            "node": "\ud83d\udd0d Query Classifier V10.1",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Return: Guardrail Blocked",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "\ud83d\udd00 Query Router": {
      "main": [
        [
          {
            "node": "\ud83d\udcac Conversational Handler",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "\ud83d\udd0e Cache Semantic Search",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "HTTP Request",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "\ud83e\udde0 LLM 1: Intent Analyzer",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "\ud83d\udcac Conversational Handler": {
      "main": [
        [
          {
            "node": "Return: Conversational",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "\ud83d\udd0e Cache Semantic Search": {
      "main": [
        [
          {
            "node": "Redis: Cache + Generator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Redis: Cache + Generator": {
      "main": [
        [
          {
            "node": "Cache Parser",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Cache Parser": {
      "main": [
        [
          {
            "node": "IF: Cache Hit?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "IF: Cache Hit?": {
      "main": [
        [
          {
            "node": "Return: Cached",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "\ud83e\udde0 LLM 1: Intent Analyzer",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "\ud83e\udde0 LLM 1: Intent Analyzer": {
      "main": [
        [
          {
            "node": "Intent Parser V9",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Intent Parser V9": {
      "main": [
        [
          {
            "node": "\ud83c\udfaf LLM 2: Task Planner",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "\ud83c\udfaf LLM 2: Task Planner": {
      "main": [
        [
          {
            "node": "Postgres: Init Tasks Table",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Postgres: Init Tasks Table": {
      "main": [
        [
          {
            "node": "\ud83d\udcdd Format & Dispatch (Plan\u2192DB)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "\ud83d\udcdd Format & Dispatch (Plan\u2192DB)": {
      "main": [
        [
          {
            "node": "Postgres: Insert Tasks",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Postgres: Insert Tasks": {
      "main": [
        [
          {
            "node": "Postgres : Get Current Tasks",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "\u2699\ufe0f Execution Engine V10": {
      "main": [
        [
          {
            "node": "If",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "\ud83d\udd00 Dynamic Switch V10": {
      "main": [
        [
          {
            "node": "Invoke WF5: Standard",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Invoke WF2: Graph",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Invoke WF4: Quantitative",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Invoke WF5: Standard": {
      "main": [
        [
          {
            "node": "\ud83d\udce5 Task Result Handler",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Invoke WF2: Graph": {
      "main": [
        [
          {
            "node": "\ud83d\udce5 Task Result Handler",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Invoke WF4: Quantitative": {
      "main": [
        [
          {
            "node": "\ud83d\udce5 Task Result Handler",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "\ud83d\udce5 Task Result Handler": {
      "main": [
        [
          {
            "node": "Postgres: Update Task",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Postgres: Update Task": {
      "main": [
        [
          {
            "node": "\ud83d\udd04 Fallback Monitor V10",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "\ud83d\udd04 Fallback Monitor V10": {
      "main": [
        [
          {
            "node": "IF: Fallback Needed?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "IF: Fallback Needed?": {
      "main": [
        [
          {
            "node": "\ud83d\udd04 Fallback Dispatch",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "\ud83d\udcca Task Status Aggregator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "\ud83d\udd04 Fallback Dispatch": {
      "main": [
        [
          {
            "node": "Postgres: Update Fallback",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Postgres: Update Fallback": {
      "main": [
        [
          {
            "node": "Postgres : Get Current Tasks",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "\ud83d\udcca Task Status Aggregator": {
      "main": [
        [
          {
            "node": "\ud83c\udfaf LLM 3: Agent Harness (Opus 4.5)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "\ud83c\udfaf LLM 3: Agent Harness (Opus 4.5)": {
      "main": [
        [
          {
            "node": "\ud83d\udcca Agent Decision Parser",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "\ud83d\udcca Agent Decision Parser": {
      "main": [
        [
          {
            "node": "\ud83d\udd04 Task Updater",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "\ud83d\udd04 Task Updater": {
      "main": [
        [
          {
            "node": "If1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Postgres: Apply Skips": {
      "main": [
        [
          {
            "node": "Postgres : Get Current Tasks",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Postgres: Insert New Tasks": {
      "main": [
        [
          {
            "node": "Postgres : Get Current Tasks",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Response Builder V9": {
      "main": [
        [
          {
            "node": "\ud83d\udcbe Cache Storage",
            "type": "main",
            "index": 0
          },
          {
            "node": "Store RLHF Data V8",
            "type": "main",
            "index": 0
          },
          {
            "node": "Redis: Store Conv V8",
            "type": "main",
            "index": 0
          },
          {
            "node": "Postgres: Update Context V8",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "\ud83d\udcbe Cache Storage": {
      "main": [
        [
          {
            "node": "Redis: Set Cache",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Redis: Set Cache": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 2
          }
        ]
      ]
    },
    "Store RLHF Data V8": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Redis: Store Conv V8": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 3
          }
        ]
      ]
    },
    "Postgres: Update Context V8": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Output Router (Final)": {
      "main": [
        [
          {
            "node": "Chat: Final V8",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Return Response V8",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Error Handler V8": {
      "main": [
        [
          {
            "node": "Error Payload V8",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Error Payload V8": {
      "main": [
        [
          {
            "node": "Export Error V8",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Export Error V8": {
      "main": [
        [
          {
            "node": "Return: Error Response",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Return: Error Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "\ud83d\udee1\ufe0f Redis Failure Handler V10.1": {
      "main": [
        [
          {
            "node": "\ud83d\udee1\ufe0f Rate Limit Guard",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "\ud83d\udce6 Context Compression V10.1": {
      "main": [
        [
          {
            "node": "\ud83d\udee1\ufe0f Advanced Guardrails",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "\ud83d\udd0d Query Classifier V10.1": {
      "main": [
        [
          {
            "node": "\ud83d\udd00 Query Router",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HTTP Request": {
      "main": [
        [
          {
            "node": "Intent Parser V9",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Postgres : Get Current Tasks": {
      "main": [
        [
          {
            "node": "\u2699\ufe0f Execution Engine V10",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge": {
      "main": [
        [
          {
            "node": "Output Router (Final)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If": {
      "main": [
        [
          {
            "node": "Response Builder V9",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "\ud83d\udd00 Dynamic Switch V10",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If1": {
      "main": [
        [
          {
            "node": "Postgres: Apply Skips",
            "type": "main",
            "index": 0
          },
          {
            "node": "Postgres: Insert New Tasks",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Postgres : Get Current Tasks",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1",
    "availableInMCP": false,
    "timeSavedMode": "fixed",
    "callerPolicy": "workflowsFromSameOwner"
  },
  "staticData": null,
  "meta": {
    "templateCredsSetupCompleted": true
  },
  "pinData": {},
  "versionId": "a14aa943-38f0-4b6e-b06f-7562f21ceea4",
  "activeVersionId": "a14aa943-38f0-4b6e-b06f-7562f21ceea4",
  "versionCounter": 257,
  "triggerCount": 2,
  "shared": [
    {
      "updatedAt": "2026-01-30T12:15:52.954Z",
      "createdAt": "2026-01-30T12:15:52.954Z",
      "role": "workflow:owner",
      "workflowId": "FZxkpldDbgV8AD_cg7IWG",
      "projectId": "JV7MbqBbWPTstXIo",
      "project": {
        "updatedAt": "2026-01-07T13:20:26.996Z",
        "createdAt": "2026-01-07T13:20:21.870Z",
        "id": "JV7MbqBbWPTstXIo",
        "name": "Alexis Moret <alexis.moret6@outlook.fr>",
        "type": "personal",
        "icon": null,
        "description": null,
        "creatorId": "215767e0-958a-4c74-a67a-e335807eba64",
        "projectRelations": [
          {
            "updatedAt": "2026-01-07T13:20:21.870Z",
            "createdAt": "2026-01-07T13:20:21.870Z",
            "userId": "215767e0-958a-4c74-a67a-e335807eba64",
            "projectId": "JV7MbqBbWPTstXIo",
            "user": {
              "updatedAt": "2026-02-07T23:03:02.000Z",
              "createdAt": "2026-01-07T13:20:20.003Z",
              "id": "215767e0-958a-4c74-a67a-e335807eba64",
              "email": "alexis.moret6@outlook.fr",
              "firstName": "Alexis",
              "lastName": "Moret",
              "personalizationAnswers": null,
              "settings": {
                "userActivated": true,
                "userClaimedAiCredits": true,
                "easyAIWorkflowOnboarded": true,
                "firstSuccessfulWorkflowId": "e3_89vptJG7PPA-OHyAg3",
                "userActivatedAt": 1767837780144,
                "npsSurvey": {
                  "responded": true,
                  "lastShownAt": 1768407850905
                }
              },
              "disabled": false,
              "mfaEnabled": false,
              "lastActiveAt": "2026-02-07",
              "isPending": false
            }
          }
        ]
      }
    }
  ],
  "tags": [],
  "activeVersion": {
    "updatedAt": "2026-02-07T10:32:05.558Z",
    "createdAt": "2026-02-07T10:32:05.558Z",
    "versionId": "a14aa943-38f0-4b6e-b06f-7562f21ceea4",
    "workflowId": "FZxkpldDbgV8AD_cg7IWG",
    "nodes": [
      {
        "parameters": {
          "httpMethod": "POST",
          "path": "92217bb8-ffc8-459a-8331-3f553812c3d0",
          "responseMode": "responseNode",
          "options": {
            "rawBody": false
          }
        },
        "id": "f744daf0-5a48-444c-800a-b1b3cc4ae510",
        "name": "Webhook V8",
        "type": "n8n-nodes-base.webhook",
        "position": [
          16768,
          22288
        ],
        "typeVersion": 2.1,
        "webhookId": "92217bb8-ffc8-459a-8331-3f553812c3d0"
      },
      {
        "parameters": {
          "public": true,
          "initialMessages": "\ud83e\udde0 Bienvenue! Je suis l'assistant RAG SOTA 2026 **V8.0 CoT**.\n\n\u2728 Nouveaut\u00e9s:\n- Chain-of-Thought reasoning\n- Adaptive retrieval\n- Meilleure planification\n\nPosez-moi vos questions!",
          "options": {
            "responseMode": "responseNode"
          }
        },
        "id": "ad2972dd-a8f8-4368-8546-aeb5f5449ca8",
        "name": "Chat Trigger V8",
        "type": "@n8n/n8n-nodes-langchain.chatTrigger",
        "typeVersion": 1.1,
        "position": [
          16768,
          22080
        ],
        "webhookId": "95045bc0-7635-45e7-9cbb-5e96b93b32af"
      },
      {
        "parameters": {
          "jsCode": "// INPUT MERGER V8 - Unifie Webhook et Chat Trigger\nconst inputItem = $input.first().json;\nconst startTime = Date.now();\n\nlet source = 'unknown';\nlet body = {};\nlet rawQuery = '';\n\nif (inputItem.headers !== undefined && inputItem.body !== undefined) {\n  source = 'webhook';\n  body = inputItem.body || {};\n  rawQuery = body.query || '';\n} else if (inputItem.chatInput !== undefined || inputItem.sessionId !== undefined) {\n  source = 'chat';\n  rawQuery = inputItem.chatInput || inputItem.message || '';\n  body = {\n    query: rawQuery,\n    conversation_id: inputItem.sessionId || 'chat-' + Date.now(),\n    tenant_id: 'chat-user',\n    user_groups: ['chat-user'],\n    roles: ['viewer']\n  };\n} else if (inputItem.query) {\n  source = 'direct';\n  body = inputItem;\n  rawQuery = inputItem.query;\n} else {\n  throw new Error('INPUT_ERROR: No valid input detected');\n}\n\nif (!rawQuery || rawQuery.trim().length === 0) {\n  throw new Error('VALIDATION_ERROR: query is required');\n}\n\nreturn [{\n  json: {\n    source: source,\n    body: body,\n    query: rawQuery.trim(),\n    session_id: body.conversation_id || inputItem.sessionId,\n    is_chat: source === 'chat',\n    is_webhook: source === 'webhook' || source === 'direct',\n    _perf: { start_time: startTime }\n  }\n}];"
        },
        "id": "935fb493-3928-400b-b87a-53a312b97015",
        "name": "Input Merger V8",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          16960,
          22192
        ]
      },
      {
        "parameters": {
          "jsCode": "// INIT V8 - Security Gate + Pre-Classification + CoT Prep + Query Hash\nconst body = $node[\"Input Merger V8\"].json.body || {};\nconst inputMerger = $node[\"Input Merger V8\"].json;\nconst startTime = Date.now();\n\n// Crypto pour hash\nconst crypto = require('crypto');\n\n// Extraction query\nlet rawQuery = body.query || inputMerger.query || '';\nconst query = rawQuery.trim();\n\n// G\u00e9n\u00e9rer query_hash pour cache\nconst queryHash = crypto.createHash('sha256')\n  .update(query.toLowerCase().trim())\n  .digest('hex').substring(0, 16);\n\n// Trace ID\nconst traceId = body.conversation_id || inputMerger.conversation_id || \n  `trace-${Date.now()}-${Math.random().toString(36).substring(7)}`;\n\n// Security checks\nconst isSuspicious = /(<script|javascript:|onerror=|eval\\()/i.test(query);\nconst isEmpty = query.length < 2;\n\nreturn {\n  trace_id: traceId,\n  query: query,\n  query_hash: queryHash,\n  conversation_id: body.conversation_id || traceId,\n  session_id: body.session_id || body.conversation_id || traceId,\n  tenant_id: body.tenant_id || 'default',\n  user_groups: body.user_groups || ['default'],\n  metadata: body.metadata || {},\n  is_suspicious: isSuspicious,\n  is_empty: isEmpty,\n  timestamp: startTime,\n  source: inputMerger.source || 'unknown'\n};\n"
        },
        "id": "3e534116-e58f-4aff-802c-66b4c5db2b2e",
        "name": "Init V8 Security & Analysis",
        "type": "n8n-nodes-base.code",
        "position": [
          17152,
          22192
        ],
        "typeVersion": 2
      },
      {
        "parameters": {
          "operation": "get",
          "key": "={{ 'conv:' + $node['Init V8 Security & Analysis'].json.conversation_id }}",
          "options": {}
        },
        "id": "a9f97e14-db82-4bd7-b0db-51b6eca8f667",
        "name": "Redis: Fetch Conversation",
        "type": "n8n-nodes-base.redis",
        "position": [
          17296,
          22384
        ],
        "typeVersion": 1,
        "credentials": {
          "redis": {
            "id": "O2KEPiv7VzgDG5ZX",
            "name": "Redis Upstash"
          }
        },
        "onError": "continueErrorOutput"
      },
      {
        "parameters": {
          "operation": "executeQuery",
          "query": "SELECT \n  COALESCE(entities_json, '{}'::jsonb) as entities_json,\n  COALESCE(last_intent, 'UNKNOWN') as last_intent,\n  COALESCE(updated_at, NOW()) as updated_at\nFROM conversation_context \nWHERE conversation_id = $1 AND tenant_id = $2\nLIMIT 1",
          "options": {
            "queryReplacement": "=={{ [$json.conversation_id, $json.user_context.tenant_id] }}"
          }
        },
        "id": "da7327db-154d-4cea-9020-96650b124966",
        "name": "Postgres L2/L3 Memory",
        "type": "n8n-nodes-base.postgres",
        "position": [
          17344,
          21904
        ],
        "typeVersion": 2.4,
        "credentials": {
          "postgres": {
            "id": "zEr7jPswZNv6lWKu",
            "name": "Supabase PostgreSQL"
          }
        },
        "onError": "continueErrorOutput"
      },
      {
        "parameters": {
          "workflowId": {
            "__rl": true,
            "value": "qtBs2Wbi_raU2o_dqfdDC",
            "mode": "id",
            "cachedResultUrl": "/workflow/qtBs2Wbi_raU2o_dqfdDC"
          },
          "workflowInputs": {
            "value": {
              "query": "={{ $node['\u2699\ufe0f Execution Engine V10'].json.current_task?.query || $node['\u2699\ufe0f Execution Engine V10'].json.task_query || $node['Init V8 Security & Analysis'].json.query }}",
              "trace_id": "={{ $node['Init V8 Security & Analysis'].json.trace_id }}",
              "user_context": "={{ JSON.stringify({ tenant_id: $node['Init V8 Security & Analysis'].json.tenant_id || 'default', groups: $node['Init V8 Security & Analysis'].json.user_groups || ['default'] }) }}",
              "topK": 20
            },
            "matchingColumns": [],
            "schema": [
              {
                "id": "query",
                "displayName": "query",
                "type": "string"
              },
              {
                "id": "trace_id",
                "displayName": "trace_id",
                "type": "string"
              },
              {
                "id": "user_context",
                "displayName": "user_context",
                "type": "string"
              },
              {
                "id": "topK",
                "displayName": "topK",
                "type": "number"
              }
            ],
            "attemptToConvertTypes": false,
            "convertFieldsToString": true,
            "mappingMode": "defineBelow"
          },
          "options": {
            "waitForSubWorkflow": true
          }
        },
        "id": "72c191ac-677e-4f9c-a64f-1cc328680e31",
        "name": "Invoke WF5: Standard",
        "type": "n8n-nodes-base.executeWorkflow",
        "position": [
          21840,
          22224
        ],
        "typeVersion": 1.2,
        "alwaysOutputData": false,
        "continueOnFail": true,
        "onError": "continueErrorOutput"
      },
      {
        "parameters": {
          "workflowId": {
            "__rl": true,
            "value": "95x2BBAbJlLWZtWEJn6rb",
            "mode": "id",
            "cachedResultUrl": "/workflow/95x2BBAbJlLWZtWEJn6rb"
          },
          "workflowInputs": {
            "value": {
              "query": "={{ $node['\u2699\ufe0f Execution Engine V10'].json.current_task?.query || $node['\u2699\ufe0f Execution Engine V10'].json.task_query || $node['Init V8 Security & Analysis'].json.query }}",
              "trace_id": "={{ $node['Init V8 Security & Analysis'].json.trace_id }}",
              "user_context": "={{ JSON.stringify({ tenant_id: $node['Init V8 Security & Analysis'].json.tenant_id || 'default', groups: $node['Init V8 Security & Analysis'].json.user_groups || ['default'] }) }}",
              "topK": 20
            },
            "matchingColumns": [],
            "schema": [
              {
                "id": "query",
                "displayName": "query",
                "type": "string"
              },
              {
                "id": "trace_id",
                "displayName": "trace_id",
                "type": "string"
              },
              {
                "id": "user_context",
                "displayName": "user_context",
                "type": "string"
              },
              {
                "id": "topK",
                "displayName": "topK",
                "type": "number"
              }
            ],
            "attemptToConvertTypes": false,
            "convertFieldsToString": true,
            "mappingMode": "defineBelow"
          },
          "options": {
            "waitForSubWorkflow": true
          }
        },
        "id": "e3d043ea-96ab-4413-a1a5-683b090596a4",
        "name": "Invoke WF2: Graph",
        "type": "n8n-nodes-base.executeWorkflow",
        "position": [
          21840,
          22656
        ],
        "typeVersion": 1.2,
        "alwaysOutputData": true,
        "continueOnFail": true,
        "onError": "continueErrorOutput"
      },
      {
        "parameters": {
          "workflowId": {
            "__rl": true,
            "value": "xrzL7TRX9F0UrWks0tdCI",
            "mode": "list",
            "cachedResultUrl": "/workflow/xrzL7TRX9F0UrWks0tdCI",
            "cachedResultName": "TEST - SOTA 2026 - WF4 Quantitative V2.0"
          },
          "workflowInputs": {
            "value": {
              "query": "={{ $node['\u2699\ufe0f Execution Engine V10'].json.current_task?.query || $node['\u2699\ufe0f Execution Engine V10'].json.task_query || $node['Init V8 Security & Analysis'].json.query }}",
              "trace_id": "={{ $node['Init V8 Security & Analysis'].json.trace_id }}",
              "user_context": "={{ JSON.stringify({ tenant_id: $node['Init V8 Security & Analysis'].json.tenant_id || 'default', groups: $node['Init V8 Security & Analysis'].json.user_groups || ['default'] }) }}",
              "topK": 20
            },
            "matchingColumns": [],
            "schema": [
              {
                "id": "query",
                "displayName": "query",
                "type": "string"
              },
              {
                "id": "trace_id",
                "displayName": "trace_id",
                "type": "string"
              },
              {
                "id": "user_context",
                "displayName": "user_context",
                "type": "string"
              },
              {
                "id": "topK",
                "displayName": "topK",
                "type": "number"
              }
            ],
            "attemptToConvertTypes": false,
            "convertFieldsToString": true,
            "mappingMode": "defineBelow"
          },
          "options": {
            "waitForSubWorkflow": true
          }
        },
        "id": "8d682938-416e-4a7c-915e-b9a02cca209a",
        "name": "Invoke WF4: Quantitative",
        "type": "n8n-nodes-base.executeWorkflow",
        "position": [
          21856,
          22416
        ],
        "typeVersion": 1.2,
        "alwaysOutputData": true,
        "continueOnFail": true,
        "onError": "continueErrorOutput"
      },
      {
        "parameters": {
          "jsCode": "// ============================================\n// PATCH - Response Builder V9.6\n// FIX: Lit correctement les donn\u00e9es depuis Execution Engine\n// ============================================\n//\n// PROBL\u00c8ME: Response Builder ne recevait pas les donn\u00e9es car il lisait\n// depuis des nodes qui n'\u00e9taient pas dans son flux direct.\n//\n// SOLUTION: Lire depuis $json qui vient directement de l'IF node\n// qui lui-m\u00eame vient de Execution Engine.\n// ============================================\n\nconst inputData = $json;\nconst traceId = inputData.trace_id || $node['Init V8 Security & Analysis']?.json?.trace_id || 'unknown';\nconst isChat = inputData.is_chat || $node['Input Merger V8']?.json?.is_chat || false;\nconst originalQuery = inputData.original_query || $node['Init V8 Security & Analysis']?.json?.query || '';\n\nconsole.log(`[${traceId}] Response Builder V9.6 starting...`);\nconsole.log(`[${traceId}] Input keys: ${Object.keys(inputData).join(', ')}`);\n\n// === 1. R\u00c9CUP\u00c9RER LES R\u00c9SULTATS ===\n// Priorit\u00e9 1: Donn\u00e9es directes depuis Execution Engine (via IF node)\nlet completedTasks = inputData.completed_tasks || [];\nlet allResponses = inputData.all_responses || [];\nlet finalResponse = inputData.final_response || '';\nlet confidence = inputData.confidence || 0;\n\nconsole.log(`[${traceId}] From input: ${completedTasks.length} completed, ${allResponses.length} responses`);\nconsole.log(`[${traceId}] Pre-computed final_response: ${finalResponse.length} chars`);\n\n// === 2. SI PAS DE R\u00c9PONSE PR\u00c9-CALCUL\u00c9E, CONSTRUIRE ===\nif (!finalResponse || finalResponse.length < 10) {\n    console.log(`[${traceId}] Building response from completed_tasks...`);\n    \n    if (allResponses.length > 0) {\n        // Trier par confidence\n        const sorted = allResponses.sort((a, b) => (b.confidence || 0) - (a.confidence || 0));\n        \n        if (sorted.length === 1) {\n            finalResponse = sorted[0].response;\n            confidence = sorted[0].confidence || 0.5;\n        } else {\n            // Combiner les r\u00e9ponses de diff\u00e9rents RAGs\n            const usedRags = new Set(sorted.map(r => r.rag));\n            \n            if (usedRags.size > 1) {\n                // R\u00e9ponses de diff\u00e9rents RAGs\n                finalResponse = sorted.map(r => {\n                    const icon = r.rag === 'STANDARD' ? '\ud83d\udcda' : r.rag === 'GRAPH' ? '\ud83d\udd17' : '\ud83d\udcca';\n                    return `${icon} **${r.rag}:**\\n${r.response}`;\n                }).join('\\n\\n---\\n\\n');\n                \n                confidence = sorted.reduce((sum, r) => sum + (r.confidence || 0), 0) / sorted.length;\n            } else {\n                // M\u00eame RAG - prendre la meilleure\n                finalResponse = sorted[0].response;\n                confidence = sorted[0].confidence || 0.5;\n            }\n        }\n        \n        console.log(`[${traceId}] Built response: ${finalResponse.length} chars`);\n    }\n}\n\n// === 3. FALLBACK SI TOUJOURS VIDE ===\nif (!finalResponse || finalResponse.length < 10) {\n    // Essayer de lire depuis completed_tasks directement\n    if (completedTasks.length > 0) {\n        const tasksWithResponse = completedTasks.filter(t => t.response && t.response.length > 10);\n        if (tasksWithResponse.length > 0) {\n            // Prendre la meilleure\n            const best = tasksWithResponse.sort((a, b) => (b.confidence || 0) - (a.confidence || 0))[0];\n            finalResponse = best.response;\n            confidence = best.confidence || 0.5;\n            console.log(`[${traceId}] Fallback: used completed_tasks response`);\n        }\n    }\n}\n\n// === 4. DERNIER FALLBACK ===\nif (!finalResponse || finalResponse.length < 10) {\n    finalResponse = \"Je n'ai pas pu trouver d'information pertinente pour r\u00e9pondre \u00e0 votre question. Pourriez-vous reformuler ?\";\n    confidence = 0.1;\n    console.log(`[${traceId}] Using default fallback message`);\n}\n\n// === 5. AJOUTER LES SOURCES ===\nlet sources = [];\ncompletedTasks.forEach(t => {\n    if (t.sources && Array.isArray(t.sources)) {\n        sources.push(...t.sources);\n    }\n});\n\n// D\u00e9dupliquer\nconst uniqueSources = [];\nconst seenIds = new Set();\nfor (const s of sources) {\n    const id = s.id || s.source || JSON.stringify(s);\n    if (!seenIds.has(id)) {\n        seenIds.add(id);\n        uniqueSources.push(s);\n    }\n}\n\n// Formater avec sources\nlet formattedResponse = finalResponse;\nif (uniqueSources.length > 0) {\n    formattedResponse += '\\n\\n---\\n**Sources:**\\n';\n    formattedResponse += uniqueSources.slice(0, 5).map((s, i) => {\n        const name = s.source || s.id || 'Document';\n        const score = s.score ? ` (${(s.score * 100).toFixed(0)}%)` : '';\n        return `[${i + 1}] ${name}${score}`;\n    }).join('\\n');\n}\n\n// Note si confiance faible\nif (confidence < 0.4) {\n    formattedResponse += '\\n\\n*\u26a0\ufe0f Confiance mod\u00e9r\u00e9e - v\u00e9rifiez les informations.*';\n}\n\nconsole.log(`[${traceId}] Final response: ${formattedResponse.length} chars, confidence: ${confidence.toFixed(2)}`);\n\n// === 6. OUTPUT ===\nreturn {\n    final_response: formattedResponse,\n    chat_message: formattedResponse,  // Pour Chat: Final V8\n    confidence: confidence,\n    sources: uniqueSources.slice(0, 10),\n    sources_count: uniqueSources.length,\n    trace_id: traceId,\n    is_chat: isChat,\n    original_query: originalQuery,\n    \n    // Stats\n    tasks_completed: completedTasks.length,\n    responses_merged: allResponses.length,\n    \n    // Debug\n    _debug: {\n        input_had_final_response: !!inputData.final_response,\n        input_completed_count: inputData.completed_tasks?.length || 0,\n        input_responses_count: inputData.all_responses?.length || 0\n    }\n};\n"
        },
        "id": "161210a8-05be-4341-b5ac-b58a79026c32",
        "name": "Response Builder V9",
        "type": "n8n-nodes-base.code",
        "position": [
          24144,
          22112
        ],
        "typeVersion": 2
      },
      {
        "parameters": {
          "operation": "executeQuery",
          "query": "INSERT INTO rlhf_training_data (conversation_id, query, response, feedback_score, feedback_type, reasoning_path, is_good_example, is_bad_example, needs_review) \nVALUES ($1, $2, $3, $4, 'implicit', $5, $6, $7, $8) \nON CONFLICT DO NOTHING",
          "options": {
            "queryReplacement": "={{ [\n  $('Init V8 Security & Analysis').item.json.conversation_id,\n  $('Init V8 Security & Analysis').item.json.query,\n  $('Response Builder V9').item.json.final_response,\n  $('Response Builder V9').item.json.confidence || 0.5,\n  JSON.stringify($('Response Builder V9').item.json.reasoning_path || {}),\n  ($('Response Builder V9').item.json.confidence || 0.5) > 0.7,\n  ($('Response Builder V9').item.json.confidence || 0.5) < 0.3,\n  true\n] }}"
          }
        },
        "id": "9b24efe5-41c2-42ea-889a-b704ece3b592",
        "name": "Store RLHF Data V8",
        "type": "n8n-nodes-base.postgres",
        "position": [
          24400,
          22512
        ],
        "typeVersion": 2.4,
        "credentials": {
          "postgres": {
            "id": "zEr7jPswZNv6lWKu",
            "name": "Supabase PostgreSQL"
          }
        },
        "onError": "continueErrorOutput"
      },
      {
        "parameters": {
          "operation": "set",
          "key": "={{ 'conv:' + $node['Init V8 Security & Analysis'].json.conversation_id }}",
          "value": "={{ JSON.stringify({ history: [...(($node['\ud83d\udce6 Context Compression V10.1'].json?.compressed_history) || []), { query: $node['Init V8 Security & Analysis'].json.query, response: $node['Response Builder V9'].json.final_response, timestamp: new Date().toISOString() }].slice(-10), cache: { [$node['Init V8 Security & Analysis'].json.query_hash]: { response: $node['Response Builder V9'].json.final_response, timestamp: new Date().toISOString() } } }) }}"
        },
        "id": "d5455c64-0042-471f-88f1-d8a64c8d26ff",
        "name": "Redis: Store Conv V8",
        "type": "n8n-nodes-base.redis",
        "position": [
          24384,
          21984
        ],
        "typeVersion": 1,
        "credentials": {
          "redis": {
            "id": "O2KEPiv7VzgDG5ZX",
            "name": "Redis Upstash"
          }
        }
      },
      {
        "parameters": {
          "operation": "executeQuery",
          "query": "INSERT INTO conversation_context (conversation_id, tenant_id, entities_json, last_intent, updated_at) VALUES ($1, $2, $3, $4, NOW()) ON CONFLICT (conversation_id, tenant_id) DO UPDATE SET entities_json = $3, last_intent = $4, updated_at = NOW()",
          "options": {
            "queryReplacement": "={{ [\n  $('Init V8 Security & Analysis').first().json.conversation_id,\n  $('Init V8 Security & Analysis').first().json.tenant_id || 'default',\n  JSON.stringify($('\ud83d\udce6 Context Compression V10.1').first().json.entities_of_interest || {}),\n  $('\ud83d\udd0d Query Classifier V10.1').first().json.query_route || 'UNKNOWN'\n] }}"
          }
        },
        "id": "8fe8eadb-9f5d-421c-bbb5-798d1966e937",
        "name": "Postgres: Update Context V8",
        "type": "n8n-nodes-base.postgres",
        "position": [
          24384,
          22240
        ],
        "typeVersion": 2.4,
        "credentials": {
          "postgres": {
            "id": "zEr7jPswZNv6lWKu",
            "name": "Supabase PostgreSQL"
          }
        },
        "onError": "continueErrorOutput"
      },
      {
        "parameters": {
          "conditions": {
            "options": {
              "caseSensitive": true,
              "leftValue": "",
              "typeValidation": "loose",
              "version": 1
            },
            "conditions": [
              {
                "id": "is-chat-final",
                "leftValue": "={{ $('Response Builder V9').item.json.is_chat }}",
                "rightValue": true,
                "operator": {
                  "type": "boolean",
                  "operation": "equals"
                }
              }
            ],
            "combinator": "and"
          },
          "options": {
            "looseTypeValidation": true
          }
        },
        "id": "fcc058cf-79a3-4c2c-a27a-e57e4b7d0c5b",
        "name": "Output Router (Final)",
        "type": "n8n-nodes-base.if",
        "typeVersion": 2,
        "position": [
          25088,
          22192
        ]
      },
      {
        "parameters": {
          "respondWith": "text",
          "responseBody": "={{ $('Response Builder V9').item.json.chat_message }}",
          "options": {}
        },
        "id": "55f180e4-5489-47b0-97fe-de50a127cc48",
        "name": "Chat: Final V8",
        "type": "n8n-nodes-base.respondToWebhook",
        "typeVersion": 1.1,
        "position": [
          25264,
          22048
        ]
      },
      {
        "parameters": {
          "respondWith": "json",
          "responseBody": "={\n  \"success\": true,\n  \"response\": {{ $('Response Builder V9').item.json.final_response ? JSON.stringify($('Response Builder V9').item.json.final_response) : '\"\"' }},\n  \"confidence\": {{ $('Response Builder V9').item.json.confidence || 0 }},\n  \"trace_id\": {{ $('Response Builder V9').item.json.trace_id ? JSON.stringify($('Response Builder V9').item.json.trace_id) : '\"\"' }},\n  \"version\": \"V8.0-CoT\",\n  \"perf\": {{ $('Response Builder V9').item.json.perf ? JSON.stringify($('Response Builder V9').item.json.perf) : '{}' }},\n  \"reasoning_path\": {{ $('Response Builder V9').item.json.reasoning_path ? JSON.stringify($('Response Builder V9').item.json.reasoning_path) : '{}' }}\n}",
          "options": {}
        },
        "id": "906694a2-098b-480b-9705-8c9f6fa397f3",
        "name": "Return Response V8",
        "type": "n8n-nodes-base.respondToWebhook",
        "position": [
          25264,
          22256
        ],
        "typeVersion": 1.1
      },
      {
        "parameters": {},
        "id": "3b1040f3-8d0e-4a98-9bf1-6a54193a3aa9",
        "name": "Error Handler V8",
        "type": "n8n-nodes-base.errorTrigger",
        "position": [
          16528,
          22544
        ],
        "typeVersion": 1
      },
      {
        "parameters": {
          "jsCode": "// Error Payload Builder V8\nconst error = $json.error || { message: 'Unknown error' };\nlet traceId = 'unknown';\ntry { traceId = $node['Init V8 Security & Analysis'].json?.trace_id; } catch(e) {}\n\nreturn {\n  event_id: `err-${Date.now()}`,\n  trace_id: traceId,\n  timestamp: new Date().toISOString(),\n  level: 'error',\n  message: error.message,\n  stack: error.stack?.substring(0, 1000),\n  context: {\n    workflow: $workflow.name,\n    node: $prevNode?.name,\n    execution_id: $execution.id\n  },\n  user_input: '[REDACTED]',\n  version: 'V8.0-CoT'\n};"
        },
        "id": "3a540e97-79d1-4d12-ac5b-ca731b3374b8",
        "name": "Error Payload V8",
        "type": "n8n-nodes-base.code",
        "position": [
          16704,
          22544
        ],
        "typeVersion": 2
      },
      {
        "parameters": {
          "method": "POST",
          "url": "={{ $vars.SENTRY_DSN || 'https://sentry.io/api/ingest' }}",
          "sendBody": true,
          "specifyBody": "json",
          "jsonBody": "={{ $json }}",
          "options": {
            "timeout": 5000
          }
        },
        "id": "f7a8b350-4099-442a-b35e-fa2e64e74c32",
        "name": "Export Error V8",
        "type": "n8n-nodes-base.httpRequest",
        "position": [
          16896,
          22544
        ],
        "typeVersion": 4.3,
        "onError": "continueErrorOutput"
      },
      {
        "parameters": {
          "respondWith": "json",
          "responseBody": "={\n  \"success\": false,\n  \"response\": \"An error occurred while processing your request. Please try again.\",\n  \"error\": {{ JSON.stringify($json.message || 'Internal workflow error') }},\n  \"trace_id\": {{ JSON.stringify($json.trace_id || '') }},\n  \"version\": \"V8.0-CoT\"\n}",
          "options": {
            "responseCode": 200
          }
        },
        "id": "err-respond-v8-001",
        "name": "Return: Error Response",
        "type": "n8n-nodes-base.respondToWebhook",
        "typeVersion": 1.1,
        "position": [
          17088,
          22544
        ]
      },
      {
        "parameters": {
          "method": "POST",
          "url": "={{ $vars.OPENROUTER_BASE_URL || 'https://openrouter.ai/api/v1/chat/completions' }}",
          "authentication": "predefinedCredentialType",
          "nodeCredentialType": "openRouterApi",
          "sendBody": true,
          "specifyBody": "json",
          "jsonBody": "={\n  \"model\": \"{{ $vars.LLM_INTENT_MODEL || 'deepseek/deepseek-chat' }}\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"You are the INTENT ANALYZER of a sophisticated multi-engine RAG system.\\n\\n=== YOUR MISSION ===\\n1. Analyze the user query\\n2. Identify ALL intents (explicit AND implicit)\\n3. Determine DEPENDENCIES between intents\\n4. Assign the optimal RAG engine for each intent\\n\\n=== AVAILABLE RAG ENGINES ===\\n\\n**STANDARD (Pinecone + BM25)**\\n- Hybrid document retrieval (dense + sparse)\\n- topK=20, Cohere reranking\\n- Latency: ~3s\\n- Strengths: facts, procedures, definitions, technical documentation\\n- Weaknesses: poor for precise numbers, complex relationships\\n\\n**GRAPH (Neo4j)**\\n- Multi-hop traversal (4 levels max)\\n- Community detection, intelligent pruning\\n- Latency: ~5s\\n- Strengths: relationships, hierarchies, impacts, multi-hop reasoning, bridging facts across entities\\n- Weaknesses: no quantitative data, slow for simple queries\\n- USE FOR ANY question that requires CHAINING 2+ facts across different entities or documents:\\n  * 'Who voices the character named after X?' (chain: X -> character -> voice actor)\\n  * 'In what year did the founder of X die?' (chain: X -> founder -> death year)\\n  * 'What country is the birthplace of the director of film Y located in?' (chain: Y -> director -> birthplace -> country)\\n  * 'Which film has the director who died first?' (chain: film -> director -> death date, compare)\\n  * Any question mentioning a person/place/org indirectly through another entity\\n- CRITICAL: If answering requires looking up entity A to find entity B, then looking up entity B to find the answer, this is GRAPH, NOT STANDARD\\n- When in doubt between STANDARD and GRAPH, prefer GRAPH for questions about people, places, organizations, or historical facts that involve indirect references\\n\\n**QUANTITATIVE (PostgreSQL)**\\n- Automatic SQL generation with self-healing\\n- Access to tables: sales, employees, products, kpis\\n- Latency: ~4s\\n- Strengths: numbers, totals, averages, comparisons, KPIs, trends\\n- Weaknesses: no narrative text, requires structured data\\n\\n=== PRIORITIZATION RULES ===\\n1. Numbers/totals/averages/KPIs -> QUANTITATIVE\\n2. Simple factual lookups (single entity, direct answer) -> STANDARD\\n3. Multi-hop chains (answer requires 2+ fact lookups) -> GRAPH\\n4. If the question refers to an entity INDIRECTLY (e.g. 'the founder of X', 'the director of Y', 'the birthplace of Z') -> GRAPH\\n5. Comparisons between entities (which is older, who died first) -> GRAPH\\n6. Questions about people, places, orgs connected through events/works -> GRAPH\\n7. If two intents are INDEPENDENT, mark 'can_parallelize': true\\n8. When unsure between STANDARD and GRAPH, choose GRAPH\\n\\n=== STRICT JSON FORMAT ===\\nRespond ONLY with this JSON, no text before/after:\\n{\\n  \\\"reasoning\\\": \\\"<your step-by-step analysis in 2-3 sentences>\\\",\\n  \\\"intents\\\": [\\n    {\\n      \\\"id\\\": \\\"intent-1\\\",\\n      \\\"description\\\": \\\"<what the user wants to know>\\\",\\n      \\\"type\\\": \\\"FACTUAL|QUANTITATIVE|RELATIONAL|PROCEDURAL|COMPARATIVE\\\",\\n      \\\"suggested_rag\\\": \\\"STANDARD|GRAPH|QUANTITATIVE\\\",\\n      \\\"priority\\\": 1,\\n      \\\"depends_on\\\": [],\\n      \\\"can_parallelize_with\\\": [\\\"intent-X\\\"]\\n    }\\n  ],\\n  \\\"execution_order\\\": [\\\"intent-1\\\"],\\n  \\\"has_parallel_intents\\\": false,\\n  \\\"complexity\\\": \\\"SIMPLE|MODERATE|COMPLEX\\\"\\n}\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"=== QUERY TO ANALYZE ===\\n{{ $node['Init V8 Security & Analysis'].json.query }}\"\n    }\n  ],\n  \"temperature\": 0.1,\n  \"max_tokens\": 800,\n  \"response_format\": { \"type\": \"json_object\" }\n}",
          "options": {
            "timeout": 30000
          }
        },
        "id": "5a69dda9-8989-4837-87f4-69f6ea39e462",
        "name": "\ud83e\udde0 LLM 1: Intent Analyzer",
        "type": "n8n-nodes-base.httpRequest",
        "typeVersion": 4.2,
        "position": [
          19840,
          22304
        ],
        "credentials": {
          "openRouterApi": {
            "id": "aTHBqnntMBApo0Dy",
            "name": "OpenRouter account"
          }
        }
      },
      {
        "parameters": {
          "jsCode": "// Intent Parser V9.1 - Parse LLM 1 output avec support parall\u00e9lisation\nconst llmResponse = $json;\nconst initData = $node['Init V8 Security & Analysis'].json;\nconst guardrailData = $node['\ud83d\udee1\ufe0f Advanced Guardrails'].json;\n\nlet intentsData;\ntry {\n  const content = llmResponse.body?.choices?.[0]?.message?.content \n               || llmResponse.choices?.[0]?.message?.content || '{}';\n  intentsData = JSON.parse(content);\n} catch (e) {\n  // Fallback: single intent based on router\n  intentsData = {\n    reasoning: 'Fallback due to parsing error: ' + e.message,\n    intents: [{\n      id: 'intent-1',\n      description: initData.query,\n      type: 'FACTUAL',\n      suggested_rag: guardrailData.engine || 'STANDARD',\n      priority: 1,\n      depends_on: [],\n      can_parallelize_with: []\n    }],\n    execution_order: ['intent-1'],\n    has_parallel_intents: false,\n    complexity: 'SIMPLE'\n  };\n}\n\n// Validate intents\nconst validRags = ['STANDARD', 'GRAPH', 'QUANTITATIVE'];\nintentsData.intents = (intentsData.intents || []).map((intent, idx) => ({\n  ...intent,\n  id: intent.id || `intent-${idx + 1}`,\n  suggested_rag: validRags.includes(intent.suggested_rag) ? intent.suggested_rag : 'STANDARD',\n  priority: intent.priority || idx + 1,\n  depends_on: Array.isArray(intent.depends_on) ? intent.depends_on : [],\n  can_parallelize_with: Array.isArray(intent.can_parallelize_with) ? intent.can_parallelize_with : []\n}));\n\n// Determine if parallel execution is possible\nconst hasParallel = intentsData.has_parallel_intents || \n  intentsData.intents.some(i => i.can_parallelize_with?.length > 0);\n\n// Output format for LLM 2\nreturn {\n  trace_id: initData.trace_id,\n  original_query: initData.query,\n  user_context: initData.user_context,\n  \n  // Intent analysis\n  intents: intentsData.intents,\n  execution_order: intentsData.execution_order || intentsData.intents.map(i => i.id),\n  reasoning: intentsData.reasoning,\n  complexity: intentsData.complexity || 'MODERATE',\n  \n  // Parallelization info\n  has_parallel_intents: hasParallel,\n  \n  // Pass through\n  is_chat: $node['Input Merger V8'].json.is_chat,\n  is_webhook: $node['Input Merger V8'].json.is_webhook,\n  conversation_id: initData.conversation_id\n};"
        },
        "id": "bdea704a-e190-4948-b5df-8452da164e03",
        "name": "Intent Parser V9",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          20032,
          22304
        ]
      },
      {
        "parameters": {
          "method": "POST",
          "url": "={{ $vars.OPENROUTER_BASE_URL || 'https://openrouter.ai/api/v1/chat/completions' }}",
          "authentication": "predefinedCredentialType",
          "nodeCredentialType": "openRouterApi",
          "sendBody": true,
          "specifyBody": "json",
          "jsonBody": "={\n  \"model\": \"{{ $vars.LLM_PLANNER_MODEL || 'anthropic/claude-sonnet-4-5-20250929' }}\",\n  \"temperature\": 0.2,\n  \"max_tokens\": 2000,\n  \"response_format\": {\"type\": \"json_object\"},\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": {{ JSON.stringify(`You are the TASK PLANNER of a multi-engine RAG system. You receive analyzed intents and must create an optimal execution plan.\n\n=== DETAILED RAG ENGINE CAPABILITIES ===\n\n**STANDARD (RAG Multi-Index V3.4)**\n- Technology: Pinecone (1536 dims) + BM25 sparse\n- Retrieval: HyDE (hypothetical document), optional Query Decomposition\n- Reranking: Cohere rerank-multilingual-v3\n- topK: 20 chunks, ~500 tokens/chunk\n- Latency: 2-4 seconds\n- OPTIMAL FOR: Factual questions, procedures, definitions, technical documentation\n- AVOID FOR: precise numbers, hierarchical relationships\n\n**GRAPH (Neo4j Graph RAG V3.3)**\n- Technology: Neo4j + 4-hop traversal\n- Capabilities: community detection, path finding, pruning\n- Entities: Person, Team, Project, Document, Skill\n- Relations: WORKS_IN, MANAGES, REPORTS_TO, CONTRIBUTES_TO\n- Latency: 3-6 seconds\n- OPTIMAL FOR: Relationships, hierarchies, impacts, org charts, multi-hop reasoning, entity traversal, comparison between entities\n- AVOID FOR: numbers, long narrative text\n\n**QUANTITATIVE (SQL RAG V2.0)**\n- Technology: PostgreSQL + Text-to-SQL (CoT)\n- Self-healing: automatic SQL correction\n- Tables: sales, employees, products, kpis\n- Latency: 2-5 seconds\n- OPTIMAL FOR: Totals, averages, comparisons, KPIs, trends\n- AVOID FOR: text, non-numeric relationships\n\n=== PLANNING RULES ===\n1. PARALLELIZATION: If two tasks have NO dependency, same parallel_group (max 3)\n2. DEPENDENCIES: A task needing another's result -> depends_on\n3. SKIP CONDITIONS: If one answer can cover multiple intents -> if_success_covers\n4. FALLBACKS: Always provide a fallback_rag DIFFERENT from target_rag\n\n=== RECEIVED INTENTS ===\n${JSON.stringify($json.intents, null, 2)}\n\n=== SUGGESTED ORDER ===\n${$json.execution_order.join(' -> ')}\n\n=== PARALLELIZABLE INTENTS ===\n${$json.has_parallel_intents ? 'YES' : 'NO'}\n\n=== ORIGINAL QUERY ===\n${$json.original_query}\n\n=== STRICT JSON FORMAT ===\nRespond ONLY with this JSON:\n{\n  \"plan_id\": \"plan-<timestamp>\",\n  \"reasoning\": \"<your reasoning in 2-3 sentences>\",\n  \"execution_mode\": \"SEQUENTIAL|PARALLEL|MIXED\",\n  \"parallel_groups\": [{\"group_id\": 1, \"task_ids\": [1, 2], \"reason\": \"...\"}],\n  \"tasks\": [\n    {\n      \"task_id\": 1,\n      \"intent_id\": \"intent-1\",\n      \"query\": \"<query OPTIMIZED for this RAG>\",\n      \"target_rag\": \"STANDARD|GRAPH|QUANTITATIVE\",\n      \"fallback_rag\": \"STANDARD|GRAPH|QUANTITATIVE\",\n      \"parallel_group\": null,\n      \"depends_on_task\": null,\n      \"success_criteria\": {\"min_confidence\": 0.6, \"min_sources\": 1},\n      \"if_success_covers\": []\n    }\n  ],\n  \"total_tasks\": 1,\n  \"estimated_latency_ms\": 3000\n}`) }}\n    }\n  ]\n}",
          "options": {
            "timeout": 45000
          }
        },
        "id": "a2123ca5-27d8-41d5-85c1-a8c6dd96c1d2",
        "name": "\ud83c\udfaf LLM 2: Task Planner",
        "type": "n8n-nodes-base.httpRequest",
        "typeVersion": 4.2,
        "position": [
          20256,
          22304
        ],
        "credentials": {
          "openRouterApi": {
            "id": "aTHBqnntMBApo0Dy",
            "name": "OpenRouter account"
          }
        }
      },
      {
        "parameters": {
          "content": "# \ud83d\udd27 CONFIGURATION SOTA 2026\n## Variables d'environnement requises\n\n### APIs (cl\u00e9s requises)\n- `DEEPSEEK_API_KEY` - api.deepseek.com\n- `ANTHROPIC_API_KEY` - planning complexe\n- `GOOGLE_API_KEY` - Gemini Flash (optionnel)\n\n### Mod\u00e8les LLM (optionnel, d\u00e9fauts inclus)\n- `SQL_MODEL` = deepseek-chat (BIRD-SQL 72.3%)\n- `INTENT_MODEL` = deepseek-chat\n- `PLANNING_MODEL` = claude-sonnet-4-5\n- `GENERATION_MODEL` = deepseek-chat\n- `ROUTER_MODEL` = gemini-2.0-flash\n\n### Embedding (FORTEMENT RECOMMAND\u00c9)\n- `EMBEDDING_API_URL` \u2192 self-hosted Qwen3\n- `EMBEDDING_MODEL` = Qwen3-Embedding-8B\n- Impact: +15 pts MTEB vs text-embedding-3-small\n\n### Reranking (FORTEMENT RECOMMAND\u00c9)\n- `RERANKER_API_URL` \u2192 self-hosted Qwen3\n- `RERANKER_MODEL` = Qwen3-Reranker-8B\n- Impact: +2 pts BEIR, $0 vs $2/1k\n\n### Impact \u00e9conomique estim\u00e9:\n- Ingestion: -89% co\u00fbt\n- Requ\u00eates: -95% co\u00fbt\n- Qualit\u00e9 SQL: +3%\n- Qualit\u00e9 retrieval: +15%",
          "height": 804,
          "width": 188
        },
        "id": "dae9fb50-b9e9-44c8-9f01-82fe249bb3ed",
        "name": "\ud83d\udccb Config SOTA 2026",
        "type": "n8n-nodes-base.stickyNote",
        "typeVersion": 1,
        "position": [
          16320,
          21360
        ]
      },
      {
        "parameters": {
          "jsCode": "// === RATE LIMIT GUARD - Post Redis Cache ===\nconst redisData = $json;\nconst initData = $node['Init V8 Security & Analysis'].json;\nconst conversationHistory = redisData.conversation_history || [];\nconst now = Date.now();\nconst traceId = initData.trace_id;\n\n// Analyser les timestamps des messages r\u00e9cents\nconst recentWindow = 60000; // 1 minute\nconst recentMessages = conversationHistory.filter(msg => \n  msg.timestamp && (now - msg.timestamp) < recentWindow\n);\n\n// Rate limit: max 10 messages par minute\nconst MAX_REQUESTS_PER_MINUTE = 10;\nconst isRateLimited = recentMessages.length >= MAX_REQUESTS_PER_MINUTE;\n\n// Pattern abuse detection: plus de 5 messages en 10 secondes\nconst veryRecentMessages = conversationHistory.filter(msg =>\n  msg.timestamp && (now - msg.timestamp) < 10000\n);\nconst isAbuse = veryRecentMessages.length > 5;\n\nif (isRateLimited || isAbuse) {\n  console.log(`[${traceId}] RATE LIMITED: ${recentMessages.length} req/min, ${veryRecentMessages.length} req/10s`);\n  \n  return {\n    rate_limited: true,\n    blocked_until: now + recentWindow,\n    message: \"Rate limit exceeded. Please slow down your requests.\",\n    recent_count: recentMessages.length,\n    abuse_detected: isAbuse,\n    trace_id: traceId\n  };\n}\n\n// Pas de rate limit - passer les donn\u00e9es\nreturn {\n  rate_limited: false,\n  ...redisData,\n  trace_id: traceId\n};\n"
        },
        "id": "f5371300-cc52-4f1b-aad6-f95d8d67eaf3",
        "name": "\ud83d\udee1\ufe0f Rate Limit Guard",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          17520,
          22384
        ]
      },
      {
        "parameters": {
          "conditions": {
            "boolean": [
              {
                "value1": "={{ $json.rate_limited }}",
                "value2": true
              }
            ]
          },
          "options": {}
        },
        "id": "479a0220-29c2-42a9-8374-ccf4ca47c4aa",
        "name": "IF: Rate Limited?",
        "type": "n8n-nodes-base.if",
        "typeVersion": 2,
        "position": [
          17696,
          22384
        ]
      },
      {
        "parameters": {
          "respondWith": "text",
          "responseBody": "={{ $json.message }}",
          "options": {}
        },
        "id": "e84e2158-ce59-4d66-90af-07526b4fb5da",
        "name": "Return: Rate Limited",
        "type": "n8n-nodes-base.respondToWebhook",
        "typeVersion": 1.1,
        "position": [
          17904,
          22400
        ]
      },
      {
        "parameters": {
          "jsCode": "// === CACHE PARSER - V\u00e9rifie hit/miss ===\nconst redisResult = $json;\nconst initData = $node['Init V8 Security & Analysis'].json;\n\nlet cacheHit = false;\nlet cachedResponse = null;\n\ntry {\n    if (redisResult && redisResult.value) {\n        const cached = JSON.parse(redisResult.value);\n        const cacheAge = Date.now() - (cached.timestamp || 0);\n        \n        // Cache valide si < 1h\n        if (cacheAge < 3600000) {\n            cacheHit = true;\n            cachedResponse = cached.response;\n            console.log(`[${initData.trace_id}] Cache HIT: ${initData.query_hash}`);\n        } else {\n            console.log(`[${initData.trace_id}] Cache expired: ${cacheAge}ms old`);\n        }\n    }\n} catch (e) {\n    console.log(`[${initData.trace_id}] Cache parse error: ${e.message}`);\n}\n\nreturn {\n    cache_hit: cacheHit,\n    cached_response: cachedResponse,\n    query: initData.query,\n    query_hash: initData.query_hash,\n    trace_id: initData.trace_id\n};\n"
        },
        "id": "6afac6d0-4023-43ae-9b7e-76fd1f199862",
        "name": "Cache Parser",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          19072,
          21888
        ]
      },
      {
        "parameters": {
          "conditions": {
            "options": {
              "caseSensitive": true,
              "leftValue": "",
              "typeValidation": "strict",
              "version": 1
            },
            "conditions": [
              {
                "id": "e0d9ad14-ed75-46a4-a1bf-d804801bd1c0",
                "leftValue": "={{ $json.cached_response }}",
                "rightValue": "Null",
                "operator": {
                  "type": "string",
                  "operation": "equals",
                  "name": "filter.operator.equals"
                }
              },
              {
                "id": "a61487b3-0cc9-470c-af6b-e4e5b57f1538",
                "leftValue": "",
                "rightValue": "",
                "operator": {
                  "type": "string",
                  "operation": "equals",
                  "name": "filter.operator.equals"
                }
              }
            ],
            "combinator": "and"
          },
          "options": {}
        },
        "id": "cd442267-b982-44c2-af3e-cd85bad12a24",
        "name": "IF: Cache Hit?",
        "type": "n8n-nodes-base.if",
        "typeVersion": 2,
        "position": [
          19216,
          21888
        ]
      },
      {
        "parameters": {
          "respondWith": "text",
          "responseBody": "={{ $json.cached_response + '\\n\\n_\ud83d\ude80 R\u00e9ponse en cache_' }}",
          "options": {}
        },
        "id": "4fbc2f9b-57a0-4004-9305-ae5b50045464",
        "name": "Return: Cached",
        "type": "n8n-nodes-base.respondToWebhook",
        "typeVersion": 1.1,
        "position": [
          19408,
          21888
        ]
      },
      {
        "parameters": {
          "operation": "executeQuery",
          "query": "CREATE TABLE IF NOT EXISTS rag_task_executions (\n  id SERIAL PRIMARY KEY,\n  trace_id VARCHAR(255) NOT NULL,\n  task_id INTEGER NOT NULL,\n  intent_id VARCHAR(255),\n  status VARCHAR(50) DEFAULT 'pending',\n  rag_called VARCHAR(50),\n  attempt INTEGER DEFAULT 1,\n  query TEXT,\n  response TEXT,\n  error_message TEXT,\n  sources JSONB,\n  confidence FLOAT,\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW(),\n  UNIQUE(trace_id, task_id)\n);\n\nCREATE INDEX IF NOT EXISTS idx_task_status ON rag_task_executions(trace_id, status);\nCREATE INDEX IF NOT EXISTS idx_task_attempt ON rag_task_executions(trace_id, task_id, attempt);\n",
          "options": {}
        },
        "id": "ea82be59-7036-4626-acfd-11822f852c0f",
        "name": "Postgres: Init Tasks Table",
        "type": "n8n-nodes-base.postgres",
        "typeVersion": 2.5,
        "position": [
          20592,
          22448
        ],
        "credentials": {
          "postgres": {
            "id": "zEr7jPswZNv6lWKu",
            "name": "Supabase PostgreSQL"
          }
        },
        "continueOnFail": true,
        "onError": "continueErrorOutput"
      },
      {
        "parameters": {
          "jsCode": "// ============================================\n// FORMAT & DISPATCH V10.2 - MULTI-INTENT FIXED\n// ============================================\n\nvar plannerRawOutput = $json;\nvar traceId = $node['Init V8 Security & Analysis'].json.trace_id;\nvar originalQuery = $node['Init V8 Security & Analysis'].json.query;\n\nvar RAG_MAPPING = {\n  'standard': 'STANDARD',\n  'graph': 'GRAPH',\n  'quantitative': 'QUANTITATIVE'\n};\n\nfunction normalizeRAGName(ragName) {\n  if (!ragName) return 'STANDARD';\n  var key = String(ragName).toLowerCase().trim();\n  if (RAG_MAPPING[key]) return RAG_MAPPING[key];\n  return String(ragName).toUpperCase();\n}\n\nvar tasks = [];\nvar plannerData = null;\n\n// === 1. PARSER LA R\u00c9PONSE LLM 2 ===\ntry {\n  var contentString = '';\n  \n  // Support OpenRouter format\n  if (plannerRawOutput.choices && plannerRawOutput.choices[0] && \n      plannerRawOutput.choices[0].message && plannerRawOutput.choices[0].message.content) {\n    contentString = plannerRawOutput.choices[0].message.content;\n  }\n  // Support Anthropic format\n  else if (plannerRawOutput.content && plannerRawOutput.content[0] && \n           plannerRawOutput.content[0].text) {\n    contentString = plannerRawOutput.content[0].text;\n  }\n  \n  // Nettoyer les markdown code blocks\n  contentString = contentString.replace(/```json/g, '').replace(/```/g, '').trim();\n  \n  // Parser le JSON\n  plannerData = JSON.parse(contentString);\n  \n  if (plannerData && plannerData.tasks && Array.isArray(plannerData.tasks)) {\n    tasks = plannerData.tasks;\n    console.log('[' + traceId + '] Parsed ' + tasks.length + ' tasks from LLM 2');\n  }\n  \n} catch (parseError) {\n  console.error('[' + traceId + '] LLM 2 parse error: ' + parseError.message);\n  // Continue vers le fallback\n}\n\n// === 2. FALLBACK : CR\u00c9ER UNE T\u00c2CHE PAR INTENT ===\nif (tasks.length === 0) {\n  console.log('[' + traceId + '] Fallback: creating tasks from Intent Parser');\n  \n  var intentData = $node['Intent Parser V9'].json;\n  var intents = intentData.intents || [];\n  \n  if (intents.length > 0) {\n    // Cr\u00e9er une t\u00e2che pour CHAQUE intent\n    for (var i = 0; i < intents.length; i++) {\n      var intent = intents[i];\n      \n      tasks.push({\n        task_id: i + 1,\n        intent_id: intent.id || ('intent-' + (i + 1)),\n        // Utiliser la description de l'intent OU la query optimis\u00e9e\n        query: intent.query || intent.description || originalQuery,\n        target_rag: intent.suggested_rag || 'STANDARD',\n        fallback_rag: 'STANDARD',\n        parallel_group: intent.can_parallelize_with && intent.can_parallelize_with.length > 0 ? 1 : null\n      });\n    }\n    \n    console.log('[' + traceId + '] Created ' + tasks.length + ' tasks from ' + intents.length + ' intents');\n  } else {\n    // Dernier fallback : une seule t\u00e2che g\u00e9n\u00e9rique\n    tasks = [{\n      task_id: 1,\n      intent_id: 'intent-1',\n      query: originalQuery,\n      target_rag: 'STANDARD',\n      fallback_rag: 'GRAPH'\n    }];\n    \n    console.log('[' + traceId + '] Ultimate fallback: single generic task');\n  }\n}\n\n// === 3. CONSTRUIRE tasksToInsert ===\nvar tasksToInsert = [];\n\nfor (var i = 0; i < tasks.length; i++) {\n  var task = tasks[i];\n  \n  // R\u00e9cup\u00e9rer le RAG cible\n  var targetRag = task.target_rag || task.rag || 'STANDARD';\n  var normalizedRAG = normalizeRAGName(targetRag);\n  \n  // \u00c9chapper les quotes pour PostgreSQL\n  var cleanQuery = String(task.query || originalQuery).replace(/'/g, \"''\");\n  \n  tasksToInsert.push({\n    trace_id: traceId,\n    task_id: task.task_id || (i + 1),\n    intent_id: task.intent_id || ('intent-' + (i + 1)),\n    status: 'pending',\n    rag_called: normalizedRAG,\n    attempt: 1,\n    query: cleanQuery,\n    response: null,\n    error_message: null,\n    sources: null,\n    confidence: task.success_criteria ? task.success_criteria.min_confidence : 0.8\n  });\n}\n\nconsole.log('[' + traceId + '] Final output: ' + tasksToInsert.length + ' tasks ready for DB');\n\n// === 4. OUTPUT ===\nreturn {\n  trace_id: traceId,\n  tasks_to_insert: tasksToInsert,\n  total_tasks: tasksToInsert.length,\n  execution_mode: plannerData ? (plannerData.execution_mode || 'SEQUENTIAL') : 'SEQUENTIAL',\n  parallel_groups: plannerData ? (plannerData.parallel_groups || []) : [],\n  // Debug info\n  _debug: {\n    parser_success: plannerData !== null,\n    fallback_used: tasks.length === 0,\n    original_task_count: tasks.length\n  }\n};"
        },
        "id": "6e28b992-6c41-495d-a21d-812ec7120d63",
        "name": "\ud83d\udcdd Format & Dispatch (Plan\u2192DB)",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          20832,
          22304
        ]
      },
      {
        "parameters": {
          "operation": "executeQuery",
          "query": "INSERT INTO rag_task_executions \n  (trace_id, task_id, intent_id, status, rag_called, attempt, query, confidence)\nVALUES {{ $json.tasks_to_insert.map(t => \n  `('${t.trace_id}', ${t.task_id}, '${t.intent_id}', '${t.status}', '${t.rag_called}', ${t.attempt}, '${t.query}', ${t.confidence})`\n).join(', ') }}\nON CONFLICT (trace_id, task_id) DO UPDATE \nSET status = 'pending', updated_at = NOW();\n",
          "options": {}
        },
        "id": "dd492a5d-32aa-4a72-9d90-7c9253e6f228",
        "name": "Postgres: Insert Tasks",
        "type": "n8n-nodes-base.postgres",
        "typeVersion": 2.5,
        "position": [
          21024,
          22304
        ],
        "credentials": {
          "postgres": {
            "id": "zEr7jPswZNv6lWKu",
            "name": "Supabase PostgreSQL"
          }
        },
        "continueOnFail": true,
        "onError": "continueErrorOutput"
      },
      {
        "parameters": {
          "jsCode": "// ============================================\n// PATCH - Execution Engine V10.9\n// FIX 1: Passe correctement les donn\u00e9es \u00e0 Response Builder\n// FIX 2: Marque le workflow comme termin\u00e9 pour \u00e9viter re-trigger\n// ============================================\n\nconst traceId = $node['Init V8 Security & Analysis'].json.trace_id;\nconst originalQuery = $node['Init V8 Security & Analysis'].json.query;\nconst isChat = $node['Input Merger V8'].json.is_chat || false;\n\n// === 1. ANTI-LOOP avec staticData ===\nconst staticData = $getWorkflowStaticData('global');\n\n// Check si d\u00e9j\u00e0 termin\u00e9\nconst completeKey = `complete_${traceId}`;\nif (staticData[completeKey]) {\n    console.log(`[${traceId}] \u26a0\ufe0f Workflow d\u00e9j\u00e0 termin\u00e9 - ignoring re-trigger`);\n    // Retourner un objet vide pour ne pas continuer\n    return [];\n}\n\n// Counter de boucle\nif (!staticData.loopCounters) {\n    staticData.loopCounters = {};\n}\nconst loopKey = `loop_${traceId}`;\nif (!staticData.loopCounters[loopKey]) {\n    staticData.loopCounters[loopKey] = 0;\n}\nstaticData.loopCounters[loopKey]++;\n\nconst currentIteration = staticData.loopCounters[loopKey];\nconst MAX_ITERATIONS = 10;\n\nconsole.log(`[${traceId}] Execution Engine V10.9 - iteration ${currentIteration}/${MAX_ITERATIONS}`);\n\n// === 2. SAFETY - Max iterations ===\nif (currentIteration > MAX_ITERATIONS) {\n    console.error(`[${traceId}] MAX ITERATIONS - Breaking!`);\n    staticData[completeKey] = true;  // Marquer comme termin\u00e9\n    delete staticData.loopCounters[loopKey];\n    \n    return {\n        all_complete: true,\n        trace_id: traceId,\n        is_chat: isChat,\n        original_query: originalQuery,\n        completed_tasks: [],\n        all_responses: [],\n        final_response: \"Erreur: limite d'it\u00e9rations atteinte.\",\n        error: \"MAX_ITERATIONS_EXCEEDED\"\n    };\n}\n\n// === 3. LECTURE DES T\u00c2CHES ===\nlet dbTasks = [];\nlet currentTask = null;\nlet isFromFallback = false;\n\n// Check fallback\ntry {\n    const fallbackData = $node['\ud83d\udd04 Fallback Dispatch']?.json;\n    if (fallbackData?.current_task?.status === 'pending') {\n        currentTask = fallbackData.current_task;\n        isFromFallback = true;\n        console.log(`[${traceId}] From fallback: task ${currentTask.task_id}`);\n    }\n} catch (e) {}\n\n// Lecture depuis input\nif (!currentTask) {\n    try {\n        const allItems = $input.all();\n        if (allItems?.length > 0) {\n            dbTasks = allItems.map(item => item.json).filter(t => t && t.task_id);\n            console.log(`[${traceId}] Read ${dbTasks.length} tasks from input`);\n        }\n    } catch (e) {\n        const inputData = $json;\n        if (Array.isArray(inputData)) {\n            dbTasks = inputData;\n        } else if (inputData?.task_id) {\n            dbTasks = [inputData];\n        }\n    }\n    \n    // Fallback premi\u00e8re ex\u00e9cution\n    if (dbTasks.length === 0) {\n        try {\n            dbTasks = $node['\ud83d\udcdd Format & Dispatch (Plan\u2192DB)'].json.tasks_to_insert || [];\n            console.log(`[${traceId}] First run: ${dbTasks.length} tasks`);\n        } catch (e) {}\n    }\n}\n\n// === 4. ANALYSE DES T\u00c2CHES ===\nif (!currentTask && dbTasks.length > 0) {\n    const pendingTasks = dbTasks.filter(t => t.status === 'pending');\n    const completedTasks = dbTasks.filter(t => t.status === 'complete');\n    const errorTasks = dbTasks.filter(t => t.status === 'error');\n    const skippedTasks = dbTasks.filter(t => t.status === 'skipped');\n    \n    const total = dbTasks.length;\n    \n    console.log(`[${traceId}] Tasks: ${pendingTasks.length} pending, ${completedTasks.length} complete, ${skippedTasks.length} skipped, ${errorTasks.length} error`);\n    \n    // === 5. ALL COMPLETE ===\n    if (pendingTasks.length === 0) {\n        console.log(`[${traceId}] \u2705 ALL COMPLETE - routing to Response Builder`);\n        \n        // MARQUER COMME TERMIN\u00c9 pour \u00e9viter re-trigger\n        staticData[completeKey] = true;\n        delete staticData.loopCounters[loopKey];\n        \n        // Formatter les r\u00e9sultats pour Response Builder\n        const formattedCompleted = completedTasks.map(t => {\n            let sources = t.sources || [];\n            if (typeof sources === 'string') {\n                try { sources = JSON.parse(sources); } catch (e) { sources = []; }\n            }\n            return {\n                task_id: t.task_id,\n                rag_called: t.rag_called,\n                query: t.query,\n                response: t.response || '',\n                confidence: parseFloat(t.confidence) || 0.5,\n                sources: sources\n            };\n        });\n        \n        // Construire all_responses\n        const allResponses = formattedCompleted\n            .filter(t => t.response && t.response.length > 10)\n            .map(t => ({\n                task_id: t.task_id,\n                rag: t.rag_called,\n                response: t.response,\n                confidence: t.confidence\n            }));\n        \n        // Calculer la meilleure r\u00e9ponse\n        let bestResponse = '';\n        let bestConfidence = 0;\n        for (const resp of allResponses) {\n            if (resp.confidence > bestConfidence) {\n                bestConfidence = resp.confidence;\n                bestResponse = resp.response;\n            }\n        }\n        \n        console.log(`[${traceId}] Best response: ${bestResponse.length} chars, confidence ${bestConfidence}`);\n        \n        // === OUTPUT COMPLET POUR RESPONSE BUILDER ===\n        return {\n            all_complete: true,\n            trace_id: traceId,\n            is_chat: isChat,\n            original_query: originalQuery,\n            \n            // Donn\u00e9es pour Response Builder\n            completed_tasks: formattedCompleted,\n            all_responses: allResponses,\n            pending_tasks: [],\n            error_tasks: errorTasks.map(t => ({\n                task_id: t.task_id,\n                rag_called: t.rag_called,\n                error_message: t.error_message || 'Unknown'\n            })),\n            skipped_tasks: skippedTasks.map(t => ({\n                task_id: t.task_id,\n                rag_called: t.rag_called\n            })),\n            \n            // Pr\u00e9-calculer pour Response Builder\n            final_response: bestResponse,\n            confidence: bestConfidence,\n            \n            // Stats\n            total_tasks: total,\n            summary: {\n                completed: completedTasks.length,\n                pending: 0,\n                errors: errorTasks.length,\n                skipped: skippedTasks.length\n            }\n        };\n    }\n    \n    // === 6. NEXT TASK ===\n    currentTask = pendingTasks[0];\n    console.log(`[${traceId}] Next: task ${currentTask.task_id} \u2192 ${currentTask.rag_called}`);\n}\n\n// === 7. VALIDATION ===\nif (!currentTask?.rag_called) {\n    console.error(`[${traceId}] No valid task found`);\n    staticData[completeKey] = true;\n    \n    return {\n        all_complete: true,\n        trace_id: traceId,\n        is_chat: isChat,\n        original_query: originalQuery,\n        completed_tasks: [],\n        all_responses: [],\n        final_response: \"Aucune t\u00e2che valide trouv\u00e9e.\",\n        error: \"NO_VALID_TASK\"\n    };\n}\n\n// === 8. NORMALIZE RAG ===\nconst ragName = String(currentTask.rag_called).toUpperCase().trim();\nconst validRags = ['STANDARD', 'GRAPH', 'QUANTITATIVE'];\nconst normalizedRag = validRags.includes(ragName) ? ragName : 'STANDARD';\n\nconsole.log(`[${traceId}] Executing: ${normalizedRag}`);\n\n// === 9. OUTPUT POUR DYNAMIC SWITCH ===\nreturn {\n    all_complete: false,\n    trace_id: traceId,\n    is_chat: isChat,\n    original_query: originalQuery,\n    \n    current_task: {\n        ...currentTask,\n        rag_called: normalizedRag,\n        trace_id: traceId\n    },\n    route_to: normalizedRag,\n    task_id: currentTask.task_id,\n    task_query: currentTask.query,\n    attempt: currentTask.attempt || 1,\n    is_fallback: isFromFallback,\n    iteration: currentIteration\n};\n"
        },
        "id": "e234ca05-5574-404b-b92b-43f9db307ae7",
        "name": "\u2699\ufe0f Execution Engine V10",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          21376,
          22288
        ]
      },
      {
        "parameters": {
          "rules": {
            "values": [
              {
                "conditions": {
                  "options": {
                    "caseSensitive": true,
                    "leftValue": "",
                    "typeValidation": "strict",
                    "version": 2
                  },
                  "conditions": [
                    {
                      "leftValue": "={{ $json.route_to }}",
                      "rightValue": "STANDARD",
                      "operator": {
                        "type": "string",
                        "operation": "equals"
                      },
                      "id": "a54bbcc1-b6ef-4975-b887-1b300668f194"
                    }
                  ],
                  "combinator": "and"
                }
              },
              {
                "conditions": {
                  "options": {
                    "caseSensitive": true,
                    "leftValue": "",
                    "typeValidation": "strict",
                    "version": 2
                  },
                  "conditions": [
                    {
                      "leftValue": "={{ $json.route_to }}",
                      "rightValue": "GRAPH",
                      "operator": {
                        "type": "string",
                        "operation": "equals"
                      },
                      "id": "21dd21c6-f1b2-4d94-addf-2480f828b96f"
                    }
                  ],
                  "combinator": "and"
                }
              },
              {
                "conditions": {
                  "options": {
                    "caseSensitive": true,
                    "leftValue": "",
                    "typeValidation": "strict",
                    "version": 2
                  },
                  "conditions": [
                    {
                      "leftValue": "={{ $json.route_to }}",
                      "rightValue": "QUANTITATIVE",
                      "operator": {
                        "type": "string",
                        "operation": "equals"
                      },
                      "id": "06843e71-20ab-456a-a49f-4f17db5ff26e"
                    }
                  ],
                  "combinator": "and"
                }
              }
            ]
          },
          "options": {
            "fallbackOutput": "none"
          }
        },
        "id": "2813f987-c594-4ae1-9942-9fbeadd78b9d",
        "name": "\ud83d\udd00 Dynamic Switch V10",
        "type": "n8n-nodes-base.switch",
        "typeVersion": 3.2,
        "position": [
          21616,
          22400
        ]
      },
      {
        "parameters": {
          "jsCode": "// ============================================\n// PATCH - Task Result Handler V10.1.3\n// FIX: Parsing robuste multi-format + fallback_response\n// ============================================\n//\n// PROBL\u00c8MES R\u00c9SOLUS:\n// 1. Ne lisait pas le format fallback_response du Standard RAG\n// 2. Graph RAG: pas de v\u00e9rification du flag fallback\n// 3. Confidence toujours \u00e0 0 car mauvais parsing\n//\n// INSTRUCTIONS:\n// 1. Ouvrir workflow \"V10.1 orchestrator copy\" (FZxkpldDbgV8AD_cg7IWG)\n// 2. \u00c9diter le n\u0153ud \"\ud83d\udce5 Task Result Handler\"\n// 3. Remplacer tout le code par celui-ci\n// 4. Sauvegarder et tester\n// ============================================\n\nconst workflowResult = $json;\nconst currentTask = $node['\u2699\ufe0f Execution Engine V10'].json.current_task;\nconst traceId = $node['Init V8 Security & Analysis'].json.trace_id;\n\nlet response = '';\nlet sources = [];\nlet confidence = 0;\nlet error = null;\nlet success = false;\nlet formatDetected = 'unknown';\n\n// === FORMAT 0: Fallback Response (Standard RAG skip_llm=true) ===\nif (workflowResult.fallback_response) {\n  formatDetected = 'fallback_response';\n  response = workflowResult.fallback_response.response || '';\n  sources = workflowResult.fallback_response.sources || [];\n  confidence = workflowResult.fallback_response.confidence || 0.1;\n  success = response.length > 10;\n}\n// === FORMAT 1: Standard RAG direct (avec engine marker) ===\nelse if (workflowResult.engine === 'STANDARD' && workflowResult.response) {\n  formatDetected = 'standard_rag';\n  response = workflowResult.response;\n  sources = (workflowResult.sources || []).map(s => ({\n    source: s.source || 'document',\n    content: s.excerpt || s.content || '',\n    score: s.score || s.combined_score || 0\n  }));\n  confidence = workflowResult.confidence || 0.5;\n  success = response.length > 10;\n}\n// === FORMAT 2: Graph RAG nested (budgeted_context) ===\nelse if (workflowResult.status === 'SUCCESS' && workflowResult.response) {\n  const nestedResponse = workflowResult.response;\n  \n  if (nestedResponse.budgeted_context) {\n    formatDetected = 'graph_rag';\n    const ctx = nestedResponse.budgeted_context;\n    \n    // Check for fallback mode (no real graph traversal)\n    const isFallback = nestedResponse.fallback === true;\n    const traversalDepth = nestedResponse.traversal_depth || 0;\n    const hasGraphData = ctx.graph && ctx.graph.length > 0;\n    const hasRelationships = ctx.relationships && ctx.relationships.length > 10;\n    const hasValidData = hasGraphData || hasRelationships;\n    \n    if (isFallback || (!hasValidData && traversalDepth === 0)) {\n      // Graph traversal failed - mark as failure to trigger fallback\n      success = false;\n      error = `Graph RAG fallback: no data (fallback=${isFallback}, depth=${traversalDepth})`;\n      console.log(`[${traceId}] Graph RAG returned no useful data - will trigger fallback`);\n    } else {\n      response = ctx.relationships || '';\n      \n      // Combine graph and vector sources\n      const graphSources = (ctx.graph || []).map(s => ({\n        source: s.source || s.id || 'graph_entity',\n        content: s.content || s.properties || '',\n        type: 'graph'\n      }));\n      const vectorSources = (ctx.vector || []).map(s => ({\n        source: s.source || s.id || 'vector_doc',\n        content: s.content || '',\n        type: 'vector'\n      }));\n      sources = [...graphSources, ...vectorSources];\n      confidence = 0.6;\n      success = response.length > 10 || sources.length > 0;\n    }\n  }\n}\n// === FORMAT 3: Quantitative RAG (SQL interpretation) ===\nelse if (workflowResult.interpretation) {\n  formatDetected = 'quantitative_rag';\n  response = workflowResult.interpretation;\n  sources = (workflowResult.raw_results || []).map((r, i) => ({\n    source: `SQL Result ${i + 1}`,\n    content: JSON.stringify(r).substring(0, 500),\n    type: 'sql'\n  }));\n  confidence = 0.7;\n  success = true;\n}\n// === FORMAT 4: Generic response (simple format) ===\nelse if (workflowResult.response) {\n  formatDetected = 'generic';\n  response = typeof workflowResult.response === 'string' \n    ? workflowResult.response \n    : JSON.stringify(workflowResult.response);\n  sources = workflowResult.sources || [];\n  confidence = workflowResult.confidence || 0.5;\n  success = response.length > 10;\n}\n// === FORMAT 5: Answer field (some workflows) ===\nelse if (workflowResult.answer) {\n  formatDetected = 'answer_field';\n  response = workflowResult.answer;\n  sources = [];\n  confidence = 0.5;\n  success = response.length > 10;\n}\n// === FORMAT 6: Explicit error ===\nelse if (workflowResult.error || workflowResult.errorMessage) {\n  formatDetected = 'error';\n  error = workflowResult.error || workflowResult.errorMessage;\n  if (typeof error === 'object') {\n    error = error.message || JSON.stringify(error);\n  }\n  success = false;\n}\n// === FORMAT 7: Empty result (no documents) ===\nelse if (workflowResult.result_count === 0 || workflowResult.has_results === false) {\n  formatDetected = 'empty_result';\n  response = \"Aucun document pertinent trouv\u00e9.\";\n  confidence = 0.1;\n  success = false; // Trigger fallback\n}\n// === FORMAT 8: Unrecognized ===\nelse {\n  formatDetected = 'unrecognized';\n  console.log(`[${traceId}] Unrecognized format. Keys: ${Object.keys(workflowResult).join(', ')}`);\n  \n  // Try to extract anything useful\n  const possibleResponse = workflowResult.text || workflowResult.content || workflowResult.output || '';\n  if (possibleResponse && possibleResponse.length > 10) {\n    response = possibleResponse;\n    confidence = 0.3;\n    success = true;\n  } else {\n    success = false;\n    error = 'Unrecognized response format';\n  }\n}\n\n// === VALIDATION FINALE ===\nconst hasValidResponse = response && String(response).trim().length > 10;\nconst finalSuccess = success && (hasValidResponse || sources.length > 0);\n\n// Ensure confidence is a valid number\nif (typeof confidence !== 'number' || isNaN(confidence)) {\n  confidence = finalSuccess ? 0.5 : 0.1;\n}\n\nconsole.log(`[${traceId}] Task ${currentTask.task_id} (${currentTask.rag_called}): ${finalSuccess ? 'SUCCESS' : 'FAILED'}`);\nconsole.log(`[${traceId}]   Format: ${formatDetected}, Response: ${response.length} chars, Sources: ${sources.length}, Confidence: ${confidence.toFixed(4)}`);\n\nif (error) {\n  console.log(`[${traceId}]   Error: ${error}`);\n}\n\n// === OUTPUT ===\nreturn {\n  task: currentTask,\n  success: finalSuccess,\n  response: response,\n  sources: sources.slice(0, 10),\n  confidence: confidence,\n  error_message: error,\n  trace_id: traceId,\n  format_detected: formatDetected,\n  raw_result: workflowResult // Pour debug\n};"
        },
        "id": "69968841-95e5-4717-9acd-9a80d2b3a215",
        "name": "\ud83d\udce5 Task Result Handler",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          22128,
          22336
        ]
      },
      {
        "parameters": {
          "operation": "executeQuery",
          "query": "UPDATE rag_task_executions\nSET \n  status = $1,\n  response = $2,\n  error_message = $3,\n  sources = $4::jsonb,\n  updated_at = NOW()\nWHERE trace_id = $5 \n  AND task_id = $6",
          "options": {
            "queryReplacement": "={{ [$json.success ? 'complete' : 'error', $json.response || '', $json.error_message || '', JSON.stringify($json.sources || []), $json.trace_id, $json.task.task_id] }}"
          }
        },
        "id": "6bd0234e-efea-4e89-8cf5-3448af22cbda",
        "name": "Postgres: Update Task",
        "type": "n8n-nodes-base.postgres",
        "typeVersion": 2.5,
        "position": [
          22224,
          21744
        ],
        "credentials": {
          "postgres": {
            "id": "zEr7jPswZNv6lWKu",
            "name": "Supabase PostgreSQL"
          }
        },
        "continueOnFail": true,
        "onError": "continueErrorOutput"
      },
      {
        "parameters": {
          "jsCode": "// === FALLBACK MONITOR V10.1.6 - FIXED: Read from correct source ===\nconst traceId = $node['Init V8 Security & Analysis'].json.trace_id;\n\n// CORRECTION: Lire depuis Task Result Handler, PAS depuis $json\nconst taskHandlerData = $node['\ud83d\udce5 Task Result Handler'].json;\nconst currentTask = taskHandlerData.task || {};\n\n// Extraire les VRAIES donn\u00e9es (apr\u00e8s parsing)\nconst originalSuccess = taskHandlerData.success || false;\nconst response = taskHandlerData.response || '';\nconst sources = taskHandlerData.sources || [];\nconst confidence = taskHandlerData.confidence || 0;\nconst attempt = currentTask.attempt || 1;\nconst taskId = currentTask.task_id;\nconst errorMessage = taskHandlerData.error_message || '';\n\nconsole.log(`[${traceId}] Task ${taskId} - Validating: success=${originalSuccess}, response_length=${response.length}, sources=${sources.length}, confidence=${confidence.toFixed(4)}`);\n\n// === VALIDATION CRITERIA (FIXED) ===\nconst hasValidResponse = response && String(response).trim().length > 10;\nconst hasSources = Array.isArray(sources) && sources.length > 0;\n\n// Accept low reranker scores (often < 0.1) OR valid response\nconst hasMinConfidence = confidence >= 0.01 || hasValidResponse;\n\n// Determine if we have usable content\nconst hasUsableContent = hasValidResponse || hasSources;\n\n// Final success determination\nconst success = originalSuccess && hasUsableContent && hasMinConfidence;\n\n// === FAILURE REASON TRACKING ===\nlet failureReason = '';\nif (!originalSuccess) {\n  failureReason = 'execution_error';\n} else if (!hasUsableContent) {\n  if (!hasValidResponse && !hasSources) {\n    failureReason = 'empty_response_and_no_sources';\n  } else if (!hasValidResponse) {\n    failureReason = 'invalid_response_length';\n  } else {\n    failureReason = 'no_sources';\n  }\n} else if (!hasMinConfidence) {\n  failureReason = `low_confidence_${confidence.toFixed(4)}`;\n}\n\nif (!success) {\n  console.log(`[${traceId}] Task ${taskId} FAILED validation: ${failureReason} (RAG: ${currentTask.rag_called})`);\n} else {\n  console.log(`[${traceId}] Task ${taskId} SUCCESS (RAG: ${currentTask.rag_called}, confidence: ${confidence.toFixed(4)})`);\n}\n\n// === FALLBACK MAPPING ===\nconst FALLBACK_MAP = {\n  'STANDARD': { 1: 'GRAPH', 2: 'QUANTITATIVE' },\n  'GRAPH': { 1: 'STANDARD', 2: 'QUANTITATIVE' },\n  'QUANTITATIVE': { 1: 'STANDARD', 2: 'GRAPH' }\n};\n\nconst MAX_ATTEMPTS = 3;\nlet fallbackNeeded = false;\nlet nextRAG = currentTask.rag_called;\nlet nextAttempt = attempt;\n\n// === FALLBACK DECISION LOGIC ===\nif (!success) {\n  if (attempt < MAX_ATTEMPTS) {\n    fallbackNeeded = true;\n    nextAttempt = attempt + 1;\n    \n    const fallbacks = FALLBACK_MAP[currentTask.rag_called] || {};\n    nextRAG = fallbacks[attempt] || 'STANDARD';\n    \n    console.log(`[${traceId}] FALLBACK triggered: attempt ${nextAttempt}/${MAX_ATTEMPTS}, ${currentTask.rag_called} \u2192 ${nextRAG} (reason: ${failureReason})`);\n  } else {\n    fallbackNeeded = false;\n    console.log(`[${traceId}] MAX ATTEMPTS (${MAX_ATTEMPTS}) reached for task ${taskId}, marking as final failure`);\n  }\n} else {\n  fallbackNeeded = false;\n}\n\n// === OUTPUT ===\nreturn {\n  fallback_needed: fallbackNeeded,\n  task_id: taskId,\n  trace_id: traceId,\n  current_rag: currentTask.rag_called,\n  next_rag: nextRAG,\n  attempt: nextAttempt,\n  success: success,\n  response: response,\n  sources: sources,\n  confidence: confidence,\n  original_query: currentTask.query,\n  failure_reason: failureReason,\n  had_empty_response: !hasValidResponse,\n  had_no_sources: !hasSources,\n  validation_details: {\n    original_success: originalSuccess,\n    has_valid_response: hasValidResponse,\n    has_sources: hasSources,\n    has_min_confidence: hasMinConfidence,\n    response_length: response.length,\n    sources_count: sources.length,\n    confidence_value: confidence\n  }\n};"
        },
        "id": "760a5d3c-6e1e-4d91-aff1-eb0cf96a1c4e",
        "name": "\ud83d\udd04 Fallback Monitor V10",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          22400,
          21744
        ]
      },
      {
        "parameters": {
          "conditions": {
            "options": {
              "caseSensitive": true,
              "leftValue": "",
              "typeValidation": "strict",
              "version": 1
            },
            "conditions": [
              {
                "id": "id-1",
                "leftValue": "={{ $json.fallback_needed }}",
                "rightValue": true,
                "operator": {
                  "type": "boolean",
                  "operation": "equals"
                }
              }
            ],
            "combinator": "and"
          },
          "options": {}
        },
        "id": "67332e02-80d8-4dfc-9d94-d1427dcefd26",
        "name": "IF: Fallback Needed?",
        "type": "n8n-nodes-base.if",
        "typeVersion": 2,
        "position": [
          22576,
          21744
        ]
      },
      {
        "parameters": {
          "jsCode": "// === FALLBACK DISPATCH V10.1.2 - Pr\u00e9paration compl\u00e8te pour retry ===\nconst fb = $json;\nconst traceId = fb.trace_id;\n\nconsole.log(`[${traceId}] Dispatching fallback: task ${fb.task_id} \u2192 ${fb.next_rag} (attempt ${fb.attempt})`);\n\n// Construire une t\u00e2che compl\u00e8te pour le retry\nconst retriedTask = {\n  task_id: fb.task_id,\n  trace_id: traceId,\n  intent_id: fb.task?.intent_id || 'fallback',\n  status: 'pending',\n  rag_called: fb.next_rag,\n  attempt: fb.attempt,\n  query: fb.original_query,\n  confidence: 0.8,\n  // M\u00e9tadonn\u00e9es de fallback\n  is_fallback: true,\n  previous_rag: fb.current_rag,\n  failure_reason: fb.failure_reason\n};\n\nreturn {\n  // Pour Postgres: Update Fallback\n  trace_id: traceId,\n  task_id: fb.task_id,\n  new_status: 'pending',\n  new_rag: fb.next_rag,\n  new_attempt: fb.attempt,\n  \n  // Pour Dynamic Switch (route_to)\n  route_to: fb.next_rag,\n  \n  // T\u00e2che compl\u00e8te pour Execution Engine\n  current_task: retriedTask,\n  task_query: fb.original_query,\n  \n  // Pour debug\n  fallback_chain: [fb.current_rag, fb.next_rag],\n  all_complete: false\n};"
        },
        "id": "2aaeab2f-9a91-421e-b4a2-b9c9ab19b7be",
        "name": "\ud83d\udd04 Fallback Dispatch",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          22800,
          21776
        ]
      },
      {
        "parameters": {
          "operation": "executeQuery",
          "query": "UPDATE rag_task_executions\nSET \n  status = 'pending',\n  rag_called = '{{ $json.new_rag }}',\n  attempt = {{ $json.new_attempt }},\n  updated_at = NOW()\nWHERE trace_id = '{{ $json.trace_id }}' \n  AND task_id = {{ $json.task_id }};\n",
          "options": {}
        },
        "id": "960461ba-c688-4993-98ec-1ea16be7d883",
        "name": "Postgres: Update Fallback",
        "type": "n8n-nodes-base.postgres",
        "typeVersion": 2.5,
        "position": [
          22960,
          21776
        ],
        "credentials": {
          "postgres": {
            "id": "zEr7jPswZNv6lWKu",
            "name": "Supabase PostgreSQL"
          }
        },
        "continueOnFail": true,
        "onError": "continueErrorOutput"
      },
      {
        "parameters": {
          "jsCode": "// === CACHE STORAGE - Stocke les r\u00e9ponses simples ===\nconst finalResponse = $node['Response Builder V9'].json.final_response;\nconst initData = $node['Init V8 Security & Analysis'].json;\n\n// Pr\u00e9parer les donn\u00e9es de cache\nconst cacheKey = `faq:${initData.query_hash}`;\nconst cacheValue = JSON.stringify({\n  response: finalResponse,\n  timestamp: Date.now(),\n  query: initData.query\n});\n\nconsole.log(`[${initData.trace_id}] Storing in cache: ${cacheKey}`);\n\nreturn {\n  cache_key: cacheKey,\n  cache_value: cacheValue,\n  ttl: 3600,\n  trace_id: initData.trace_id\n};"
        },
        "id": "ca85038c-26c6-4002-b9c1-b231dc51e10f",
        "name": "\ud83d\udcbe Cache Storage",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          24320,
          22816
        ]
      },
      {
        "parameters": {
          "operation": "set",
          "key": "={{ $json.cache_key }}",
          "value": "={{ $json.cache_value }}",
          "keyType": "string",
          "expire": true,
          "ttl": "={{ $json.ttl }}"
        },
        "id": "c295072a-deaf-494d-84c7-6b569fc810e4",
        "name": "Redis: Set Cache",
        "type": "n8n-nodes-base.redis",
        "typeVersion": 1,
        "position": [
          24512,
          22816
        ],
        "credentials": {
          "redis": {
            "id": "O2KEPiv7VzgDG5ZX",
            "name": "Redis Upstash"
          }
        }
      },
      {
        "parameters": {
          "jsCode": "// ============================================\n// NODE: \ud83e\udde0 Memory Merger V10.1 (FIXED)\n// PURPOSE: Fusion Redis + Postgres avec gestion erreurs\n// ============================================\n\n// === 1. R\u00c9CUP\u00c9RER REDIS DATA ===\nlet redisData = {};\ntry {\n  redisData = $node['\ud83d\udee1\ufe0f Redis Failure Handler V10.1']?.json || {};\n} catch(e) {\n  console.log('Redis Failure Handler not found, trying raw Redis');\n  try {\n    redisData = $node['Redis: Fetch Conversation']?.json || {};\n    // Fallback parsing\n    if (redisData.data) {\n      try {\n        const parsed = JSON.parse(redisData.data || '{}');\n        redisData = {\n          conversation_history: parsed.history || [],\n          redis_available: true\n        };\n      } catch(e2) {\n        redisData = { conversation_history: [], redis_available: true };\n      }\n    }\n  } catch(e2) {\n    redisData = { conversation_history: [], redis_available: false };\n  }\n}\n\nconst initData = $node['Init V8 Security & Analysis'].json;\nconst traceId = redisData.trace_id || initData.trace_id;\n\n// Historique court terme (Redis)\nconst shortTermHistory = redisData.conversation_history || [];\n\n// === 2. R\u00c9CUP\u00c9RER POSTGRES DATA (AVEC GESTION ERREURS) ===\nlet postgresData = {};\nlet postgresAvailable = false;\n\ntry {\n  const pgResult = $node['Postgres L2/L3 Memory']?.json;\n  \n  // V\u00e9rifications multiples\n  if (pgResult && \n      !pgResult.error && \n      pgResult.entities_json !== null && \n      pgResult.entities_json !== undefined) {\n    \n    postgresData = pgResult;\n    postgresAvailable = true;\n    console.log(`[${traceId}] Postgres L2/L3 OK`);\n    \n  } else if (pgResult?.error) {\n    console.warn(`[${traceId}] Postgres L2/L3 ERROR:`, pgResult.error.message || pgResult.error);\n  } else {\n    console.log(`[${traceId}] Postgres L2/L3 empty (new user)`);\n  }\n  \n} catch (e) {\n  console.error(`[${traceId}] Postgres L2/L3 exception:`, e.message);\n}\n\n// === 3. FUSIONNER INTELLIGEMMENT ===\nlet entitiesJson = {};\nif (postgresData.entities_json) {\n  if (typeof postgresData.entities_json === 'string') {\n    try {\n      entitiesJson = JSON.parse(postgresData.entities_json);\n    } catch(e) {\n      entitiesJson = {};\n    }\n  } else {\n    entitiesJson = postgresData.entities_json;\n  }\n}\n\nconst lastIntent = postgresData.last_intent || 'UNKNOWN';\n\n// Construire contexte fusionn\u00e9\nconst mergedContext = {\n  recent_messages: shortTermHistory.slice(-10),\n  user_profile: postgresData.user_context || {},\n  user_preferences: postgresData.preferences || {},\n  entities_of_interest: entitiesJson,\n  last_intent: lastIntent,\n  conversation_id: initData.conversation_id,\n  session_id: initData.session_id,\n  trace_id: traceId,\n  query: initData.query,\n  query_hash: initData.query_hash,\n  redis_available: redisData.redis_available !== false,\n  postgres_available: postgresAvailable,\n  context_status: redisData.context_status || 'UNKNOWN'\n};\n\nconsole.log(`[${traceId}] Memory merged: ${shortTermHistory.length} msgs (Redis), ${postgresAvailable ? 'Postgres OK' : 'Postgres unavailable'}`);\n\nreturn mergedContext;"
        },
        "id": "771afac4-90da-4e02-a8e8-d4032075bb64",
        "name": "\ud83e\udde0 Memory Merger (Redis + Postgres)",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          17696,
          21888
        ]
      },
      {
        "parameters": {
          "jsCode": "// === ADVANCED GUARDRAILS - Prompt Injection, Jailbreak, Content Safety ===\nconst mergedContext = $json;\nconst query = mergedContext.query || '';\nconst traceId = mergedContext.trace_id;\n\n// Patterns de prompt injection\nconst INJECTION_PATTERNS = [\n  /ignore (previous|all) (instructions|prompts)/i,\n  /you are now|pretend (you are|to be)/i,\n  /system:|<\\|im_start\\|>|<\\|im_end\\|>/i,\n  /\\n\\nHuman:|\\n\\nAssistant:/i,\n  /<script|javascript:|onerror=|eval\\(/i,\n  /forget (everything|all)|disregard (previous|all)/i\n];\n\n// Patterns de jailbreak\nconst JAILBREAK_PATTERNS = [\n  /DAN|Do Anything Now/i,\n  /evil mode|developer mode/i,\n  /sudo mode|admin mode/i,\n  /without any (restrictions|limitations|ethical)/i\n];\n\n// Patterns de contenu sensible\nconst SENSITIVE_PATTERNS = [\n  /how to (make|create|build) (bomb|weapon|explosive)/i,\n  /hack|exploit|vulnerability|backdoor/i,\n  /(illegal|illicit) (drugs|substances)/i\n];\n\n// V\u00e9rifications\nconst hasInjection = INJECTION_PATTERNS.some(p => p.test(query));\nconst hasJailbreak = JAILBREAK_PATTERNS.some(p => p.test(query));\nconst hasSensitive = SENSITIVE_PATTERNS.some(p => p.test(query));\n\nconst isBlocked = hasInjection || hasJailbreak || hasSensitive;\n\nlet blockReason = null;\nif (hasInjection) blockReason = \"prompt_injection\";\nif (hasJailbreak) blockReason = \"jailbreak_attempt\";\nif (hasSensitive) blockReason = \"sensitive_content\";\n\nif (isBlocked) {\n  console.log(`[${traceId}] BLOCKED: ${blockReason}`);\n}\n\nreturn {\n  ...mergedContext,\n  guardrail_passed: !isBlocked,\n  guardrail_blocked: isBlocked,\n  block_reason: blockReason,\n  injection_detected: hasInjection,\n  jailbreak_detected: hasJailbreak,\n  sensitive_detected: hasSensitive\n};\n"
        },
        "id": "5195d53f-ba51-4531-a015-08d5a22b67ed",
        "name": "\ud83d\udee1\ufe0f Advanced Guardrails",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          17888,
          21888
        ]
      },
      {
        "parameters": {
          "conditions": {
            "boolean": [
              {
                "value1": "={{ $json.guardrail_passed }}",
                "value2": true
              }
            ]
          },
          "options": {}
        },
        "id": "dac0a336-6e67-4b4c-b5ae-80ff733d4414",
        "name": "IF: Guardrail Passed?",
        "type": "n8n-nodes-base.if",
        "typeVersion": 2,
        "position": [
          18080,
          21888
        ]
      },
      {
        "parameters": {
          "respondWith": "text",
          "responseBody": "I cannot respond to this request because it contains inappropriate or potentially harmful content.",
          "options": {}
        },
        "id": "b6bd01b0-8d5f-47d3-9c7d-98de8d2e77ae",
        "name": "Return: Guardrail Blocked",
        "type": "n8n-nodes-base.respondToWebhook",
        "typeVersion": 1.1,
        "position": [
          18256,
          21952
        ]
      },
      {
        "parameters": {
          "rules": {
            "values": [
              {
                "conditions": {
                  "options": {
                    "caseSensitive": true,
                    "leftValue": "",
                    "typeValidation": "strict",
                    "version": 2
                  },
                  "conditions": [
                    {
                      "leftValue": "={{ $json.query_route }}",
                      "rightValue": "conversational",
                      "operator": {
                        "type": "string",
                        "operation": "equals"
                      },
                      "id": "09b9e899-fec1-4e05-a4ba-58262fb5c072"
                    }
                  ],
                  "combinator": "and"
                }
              },
              {
                "conditions": {
                  "options": {
                    "caseSensitive": true,
                    "leftValue": "",
                    "typeValidation": "strict",
                    "version": 2
                  },
                  "conditions": [
                    {
                      "leftValue": "={{ $json.query_route }}",
                      "rightValue": "cache_check",
                      "operator": {
                        "type": "string",
                        "operation": "equals"
                      },
                      "id": "52bd6b24-bf82-48ff-b1aa-4d8266ade86f"
                    }
                  ],
                  "combinator": "and"
                }
              },
              {
                "conditions": {
                  "options": {
                    "caseSensitive": true,
                    "leftValue": "",
                    "typeValidation": "strict",
                    "version": 2
                  },
                  "conditions": [
                    {
                      "id": "dae8b9a1-a47c-490e-93d2-549bf166c3ab",
                      "leftValue": "={{ $json.query_route }}",
                      "rightValue": " direct_llm",
                      "operator": {
                        "type": "string",
                        "operation": "equals",
                        "name": "filter.operator.equals"
                      }
                    }
                  ],
                  "combinator": "and"
                }
              }
            ]
          },
          "options": {
            "fallbackOutput": "extra"
          }
        },
        "id": "3a29a41a-fe91-4c3d-bce6-ddc3206f734b",
        "name": "\ud83d\udd00 Query Router",
        "type": "n8n-nodes-base.switch",
        "typeVersion": 3.2,
        "position": [
          18528,
          21808
        ]
      },
      {
        "parameters": {
          "jsCode": "// === CONVERSATIONAL HANDLER - R\u00e9ponses directes conversationnelles ===\nconst context = $json;\nconst query = context.query.toLowerCase().trim();\nconst traceId = context.trace_id;\n\n// R\u00e9ponses template\nconst RESPONSES = {\n  'hi': \"Bonjour ! Comment puis-je vous aider aujourd'hui ?\",\n  'hello': \"Hello! How can I assist you today?\",\n  'bonjour': \"Bonjour ! Je suis l\u00e0 pour vous aider. Que puis-je faire pour vous ?\",\n  'thanks': \"De rien ! N'h\u00e9sitez pas si vous avez d'autres questions.\",\n  'thank you': \"You're welcome! Feel free to ask if you need anything else.\",\n  'merci': \"Avec plaisir ! Je reste \u00e0 votre disposition.\",\n  'bye': \"Au revoir ! \u00c0 bient\u00f4t.\",\n  'goodbye': \"Goodbye! Have a great day!\",\n  'ok': \"D'accord ! Y a-t-il autre chose ?\",\n  'yes': \"Parfait ! Que puis-je faire d'autre pour vous ?\",\n  'no': \"D'accord, n'h\u00e9sitez pas si vous changez d'avis.\"\n};\n\n// Trouver la r\u00e9ponse\nlet response = \"Je suis l\u00e0 pour vous aider. Que puis-je faire pour vous ?\";\nfor (const [pattern, resp] of Object.entries(RESPONSES)) {\n  if (query.includes(pattern)) {\n    response = resp;\n    break;\n  }\n}\n\nconsole.log(`[${traceId}] Conversational response generated`);\n\nreturn {\n  trace_id: traceId,\n  query: context.query,\n  response: response,\n  is_conversational: true,\n  conversation_id: context.conversation_id\n};\n"
        },
        "id": "b7212bb1-ec8d-45c3-b19a-919acd65f460",
        "name": "\ud83d\udcac Conversational Handler",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          18768,
          21712
        ]
      },
      {
        "parameters": {
          "respondWith": "text",
          "responseBody": "={{ $json.response }}",
          "options": {}
        },
        "id": "bb985081-d04e-41eb-a725-5169e456ad02",
        "name": "Return: Conversational",
        "type": "n8n-nodes-base.respondToWebhook",
        "typeVersion": 1.1,
        "position": [
          18928,
          21744
        ]
      },
      {
        "parameters": {
          "jsCode": "// === CACHE SEMANTIC SEARCH - Trouve questions similaires ===\nconst context = $json;\nconst query = context.query;\nconst queryHash = context.query_hash;\nconst traceId = context.trace_id;\n\n// Note: Ici on simule une recherche s\u00e9mantique\n// En production, on utiliserait un vector store (Pinecone, Qdrant, etc.)\n// ou Redis avec RedisSearch/RediSearch VSS\n\n// Pour l'instant, on checke juste le hash exact\n// Le node Redis suivant fera le vrai travail\n\nreturn {\n  ...context,\n  cache_search_query: queryHash,\n  semantic_search_enabled: true\n};\n"
        },
        "id": "8211b2d7-c032-4617-adcf-037d1b8c0b27",
        "name": "\ud83d\udd0e Cache Semantic Search",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          18768,
          21920
        ]
      },
      {
        "parameters": {
          "operation": "get",
          "key": "={{ 'faq:' + $json.query_hash }}",
          "options": {}
        },
        "id": "97a611eb-b47f-4066-b00d-6b0a6cda5650",
        "name": "Redis: Cache + Generator",
        "type": "n8n-nodes-base.redis",
        "typeVersion": 1,
        "position": [
          18944,
          21920
        ],
        "credentials": {
          "redis": {
            "id": "O2KEPiv7VzgDG5ZX",
            "name": "Redis Upstash"
          }
        }
      },
      {
        "parameters": {
          "method": "POST",
          "url": "={{ $vars.OPENROUTER_BASE_URL || 'https://openrouter.ai/api/v1/chat/completions' }}",
          "authentication": "predefinedCredentialType",
          "nodeCredentialType": "openRouterApi",
          "sendBody": true,
          "specifyBody": "json",
          "jsonBody": "={{ {\n  \"model\": $vars.LLM_AGENT_MODEL || 'anthropic/claude-3-5-sonnet-20241022',\n  \"max_tokens\": 2000,\n  \"temperature\": 0.3,\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"You are the JUDGE of a multi-engine RAG system. Your role is to decide if the obtained results are sufficient to answer the user's question.\\n\\n=== YOUR ROLE ===\\n1. Analyze the user's ORIGINAL QUERY\\n2. Examine the OBTAINED RESPONSES from completed tasks\\n3. JUDGE whether these responses are sufficient to answer the query\\n4. Decide what to do with remaining pending tasks\\n\\n=== YOUR POSSIBLE DECISIONS ===\\n\\n**all_tasks_complete: true** \u2192 The obtained responses are sufficient to answer the user\\n- Set all pending tasks to SKIP\\n- The workflow will generate the final response\\n\\n**all_tasks_complete: false** \u2192 Information is still missing\\n- KEEP necessary pending tasks\\n- SKIP redundant pending tasks\\n- Optional: ADD new tasks\\n\\n=== JSON RESPONSE FORMAT ===\\n{\\n  \\\"all_tasks_complete\\\": true/false,\\n  \\\"judgment\\\": \\\"Explanation of why responses are sufficient or not\\\",\\n  \\\"actions\\\": [\\n    {\\\"action\\\": \\\"SKIP\\\", \\\"task_id\\\": 2, \\\"reason\\\": \\\"...\\\"},\\n    {\\\"action\\\": \\\"KEEP\\\", \\\"task_id\\\": 3, \\\"reason\\\": \\\"...\\\"}\\n  ],\\n  \\\"missing_info\\\": \\\"What is missing if all_tasks_complete=false\\\"\\n}\\n\\n=== RULES ===\\n- You MUST provide an action for EVERY pending task\\n- If all_tasks_complete=true, ALL pending tasks must be SKIP\\n- Do NOT handle fallbacks/errors (another system handles that)\\n- Respond ONLY with valid JSON\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"=== USER'S ORIGINAL QUERY ===\\n\" + $node['Init V8 Security & Analysis'].json.query + \"\\n\\n=== OBTAINED RESPONSES (completed tasks) ===\\n\" + JSON.stringify($node['\ud83d\udcca Task Status Aggregator'].json.completed_tasks || [], null, 2) + \"\\n\\n=== PENDING TASKS ===\\n\" + JSON.stringify($node['\ud83d\udcca Task Status Aggregator'].json.pending_tasks || [], null, 2) + \"\\n\\n=== ERROR TASKS ===\\n\" + JSON.stringify($node['\ud83d\udcca Task Status Aggregator'].json.error_tasks || [], null, 2) + \"\\n\\nAnalyze whether the obtained responses are sufficient to answer the original query. Return your decision in JSON.\"\n    }\n  ]\n} }}",
          "options": {
            "timeout": 30000
          }
        },
        "id": "65630655-5b38-4faa-9a4d-a30faa4ce90a",
        "name": "\ud83c\udfaf LLM 3: Agent Harness (Opus 4.5)",
        "type": "n8n-nodes-base.httpRequest",
        "typeVersion": 4.3,
        "position": [
          22944,
          22096
        ],
        "credentials": {
          "httpHeaderAuth": {
            "id": "nTJdf91Z5vhsI7cm",
            "name": "Unstructured API"
          },
          "openRouterApi": {
            "id": "aTHBqnntMBApo0Dy",
            "name": "OpenRouter account"
          }
        }
      },
      {
        "parameters": {
          "jsCode": "// ============================================\n// NODE: \ud83d\udcca Agent Decision Parser V10.3\n// PURPOSE: Parse LLM3 Agent Harness (JUGE) response\n// ============================================\n\nconst agentResponse = $json;\nconst traceId = $node['Init V8 Security & Analysis'].json.trace_id;\n\nlet decisions = null;\n\ntry {\n    // === 1. EXTRACT CONTENT FROM API RESPONSE ===\n    let content = '';\n    \n    // OpenRouter format: choices[0].message.content\n    if (agentResponse.choices?.[0]?.message?.content) {\n        content = agentResponse.choices[0].message.content;\n        console.log(`[${traceId}] Detected OpenRouter format`);\n    }\n    // Anthropic format: content[0].text\n    else if (agentResponse.content?.[0]?.text) {\n        content = agentResponse.content[0].text;\n        console.log(`[${traceId}] Detected Anthropic format`);\n    }\n    // Body wrapper (some API configs)\n    else if (agentResponse.body?.choices?.[0]?.message?.content) {\n        content = agentResponse.body.choices[0].message.content;\n        console.log(`[${traceId}] Detected wrapped OpenRouter format`);\n    }\n    // Anthropic body wrapper\n    else if (agentResponse.body?.content?.[0]?.text) {\n        content = agentResponse.body.content[0].text;\n        console.log(`[${traceId}] Detected wrapped Anthropic format`);\n    }\n    \n    if (!content) {\n        throw new Error('No content found in LLM response. Available keys: ' + Object.keys(agentResponse).join(', '));\n    }\n    \n    // === 2. CLEAN AND PARSE JSON ===\n    let cleanedContent = content.trim();\n    \n    // Remove markdown code blocks if present\n    cleanedContent = cleanedContent.replace(/```json\\s*/g, '').replace(/```\\s*/g, '');\n    \n    // Try to extract JSON object\n    const jsonMatch = cleanedContent.match(/\\{[\\s\\S]*\\}/);\n    if (jsonMatch) {\n        decisions = JSON.parse(jsonMatch[0]);\n    } else {\n        decisions = JSON.parse(cleanedContent);\n    }\n    \n    console.log(`[${traceId}] LLM3 Agent Harness parsed successfully`);\n    \n} catch (e) {\n    console.error(`[${traceId}] Agent parsing error: ${e.message}`);\n    console.error(`[${traceId}] Response structure: ${JSON.stringify(agentResponse, null, 2).substring(0, 500)}`);\n    \n    // Fallback: continue without modifications\n    decisions = {\n        all_tasks_complete: false,\n        judgment: 'Parse error - continuing with existing tasks',\n        actions: [],\n        missing_info: 'Unable to parse LLM3 response: ' + e.message\n    };\n}\n\n// === 3. EXTRACT DECISIONS ===\nconst allTasksComplete = decisions.all_tasks_complete === true;\nconst judgment = decisions.judgment || 'No judgment provided';\nconst actions = Array.isArray(decisions.actions) ? decisions.actions : [];\nconst missingInfo = decisions.missing_info || '';\n\n// === 4. LOGGING ===\nconsole.log(`[${traceId}] === LLM3 JUDGMENT ===`);\nconsole.log(`[${traceId}] all_tasks_complete: ${allTasksComplete}`);\nconsole.log(`[${traceId}] judgment: ${judgment}`);\nconsole.log(`[${traceId}] actions: ${actions.length}`);\n\nif (allTasksComplete) {\n    console.log(`[${traceId}] \u2705 LLM3 says: Responses are sufficient!`);\n} else {\n    console.log(`[${traceId}] \u23f3 LLM3 says: Missing info: ${missingInfo}`);\n}\n\nactions.forEach((action, idx) => {\n    console.log(`[${traceId}]   Action ${idx + 1}: ${action.action} task_id=${action.task_id} - ${action.reason || 'no reason'}`);\n});\n\n// === 5. OUTPUT ===\nreturn {\n    trace_id: traceId,\n    \n    // Main signal for Task Updater\n    all_tasks_complete: allTasksComplete,\n    judgment: judgment,\n    missing_info: missingInfo,\n    \n    // Actions array for Task Updater\n    actions: actions,\n    \n    // Compatibility with old format\n    plan_updated: actions.length > 0,\n    reasoning: judgment,\n    \n    // Debug info\n    _debug: {\n        actions_count: actions.length,\n        has_skip_actions: actions.some(a => a.action === 'SKIP'),\n        has_keep_actions: actions.some(a => a.action === 'KEEP'),\n        has_add_actions: actions.some(a => a.action === 'ADD')\n    }\n};"
        },
        "id": "4e969cfa-9585-4d55-b7dc-3809bd6b3284",
        "name": "\ud83d\udcca Agent Decision Parser",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          23104,
          22096
        ]
      },
      {
        "parameters": {
          "jsCode": "// ============================================\n// PATCH - Task Updater V10.6\n// FIX: Ne reboucle PAS quand all_tasks_complete=true\n// ============================================\n//\n// PROBL\u00c8ME R\u00c9SOLU:\n// Avant: Task Updater \u2192 Postgres: Apply Skips \u2192 Postgres: Get Current Tasks \u2192 Execution Engine\n// Cela causait une boucle m\u00eame apr\u00e8s que Response Builder ait fini!\n//\n// SOLUTION:\n// Quand all_tasks_complete=true, on NE FAIT PAS de skip dans la DB\n// car Execution Engine a d\u00e9j\u00e0 rout\u00e9 vers Response Builder.\n// Les t\u00e2ches pending seront ignor\u00e9es, pas besoin de les skipper.\n//\n// CHANGEMENT ARCHITECTURAL REQUIS:\n// Ajouter un IF node apr\u00e8s Task Updater:\n// - Si all_tasks_complete=true \u2192 NE PAS connecter \u00e0 Postgres: Apply Skips\n// - Si all_tasks_complete=false \u2192 Connecter normalement\n// ============================================\n\nconst parsed = $json;\nconst traceId = parsed.trace_id;\n\nconst allTasksComplete = parsed.all_tasks_complete === true;\nconst judgment = parsed.judgment || '';\nconst actions = parsed.actions || [];\n\nconsole.log(`[${traceId}] Task Updater V10.6`);\nconsole.log(`[${traceId}] all_tasks_complete: ${allTasksComplete}`);\n\n// === CAS 1: TERMINAISON - NE PAS REBOUCLER ===\nif (allTasksComplete) {\n    console.log(`[${traceId}] \u2705 TERMINAISON D\u00c9TECT\u00c9E`);\n    console.log(`[${traceId}] Judgment: ${judgment}`);\n    console.log(`[${traceId}] \u26a0\ufe0f NE PAS reboucler - Response Builder va g\u00e9rer`);\n    \n    // IMPORTANT: On ne fait PAS de skip_updates\n    // Car on ne veut PAS trigger Postgres: Apply Skips \u2192 Get Current Tasks \u2192 Execution Engine\n    // Execution Engine a d\u00e9j\u00e0 rout\u00e9 vers Response Builder via le IF node\n    \n    return {\n        trace_id: traceId,\n        all_tasks_complete: true,\n        should_loop: false,  // FLAG IMPORTANT pour le IF node\n        judgment: judgment,\n        skip_updates: [],    // VIDE - pas de reboucle\n        new_tasks: [],\n        total_skipped: 0,\n        total_added: 0,\n        has_pending_after: false\n    };\n}\n\n// === CAS 2: TRAVAIL RESTANT - Appliquer les actions ===\nconsole.log(`[${traceId}] \u23f3 Travail restant, ${actions.length} actions`);\n\n// R\u00e9cup\u00e9rer les t\u00e2ches pending\nlet pendingTasks = [];\nlet maxTaskId = 0;\ntry {\n    const dbResult = $('Postgres : Get Current Tasks').all();\n    const dbTasks = dbResult.map(item => item.json);\n    pendingTasks = dbTasks.filter(t => t.status === 'pending');\n    dbTasks.forEach(t => {\n        if (t.task_id > maxTaskId) maxTaskId = t.task_id;\n    });\n} catch (e) {\n    console.log(`[${traceId}] DB read error: ${e.message}`);\n}\n\nconst skips = [];\nconst newTasks = [];\n\nfor (const action of actions) {\n    if (action.action === 'SKIP') {\n        skips.push({\n            task_id: action.task_id,\n            trace_id: traceId,\n            reason: action.reason || 'LLM3 decision',\n            new_status: 'skipped'\n        });\n        console.log(`[${traceId}] SKIP task ${action.task_id}`);\n        \n    } else if (action.action === 'KEEP') {\n        console.log(`[${traceId}] KEEP task ${action.task_id}`);\n        \n    } else if (action.action === 'ADD' && action.new_task) {\n        const newTaskId = maxTaskId + newTasks.length + 1;\n        newTasks.push({\n            trace_id: traceId,\n            task_id: newTaskId,\n            intent_id: 'llm3_added',\n            status: 'pending',\n            rag_called: action.new_task.rag || 'STANDARD',\n            attempt: 1,\n            query: (action.new_task.query || '').replace(/'/g, \"''\"),\n            confidence: 0.8\n        });\n        console.log(`[${traceId}] ADD task ${newTaskId}`);\n    }\n}\n\nconst skippedIds = new Set(skips.map(s => s.task_id));\nconst remainingPending = pendingTasks.filter(t => !skippedIds.has(t.task_id));\nconst hasPendingAfter = remainingPending.length > 0 || newTasks.length > 0;\n\nconsole.log(`[${traceId}] Result: ${skips.length} skips, ${newTasks.length} adds, ${remainingPending.length} remaining`);\n\nreturn {\n    trace_id: traceId,\n    all_tasks_complete: false,\n    should_loop: true,  // FLAG pour le IF node - continuer la boucle\n    judgment: judgment,\n    skip_updates: skips,\n    new_tasks: newTasks,\n    total_skipped: skips.length,\n    total_added: newTasks.length,\n    has_pending_after: hasPendingAfter\n};\n"
        },
        "id": "04172aae-947d-4181-b3ca-cac2102249b3",
        "name": "\ud83d\udd04 Task Updater",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          23280,
          22080
        ]
      },
      {
        "parameters": {
          "operation": "executeQuery",
          "query": "={{ $json.skip_updates && $json.skip_updates.length > 0 ? \n  \"UPDATE rag_task_executions SET status = 'skipped', updated_at = NOW() WHERE \" +\n  $json.skip_updates.map(s => `(trace_id = '${s.trace_id}' AND task_id = ${s.task_id})`).join(' OR ')\n  : \"SELECT 1\" \n}}",
          "options": {}
        },
        "id": "ba3d7b7d-adfb-423f-a43c-ce2b670484a2",
        "name": "Postgres: Apply Skips",
        "type": "n8n-nodes-base.postgres",
        "typeVersion": 2.5,
        "position": [
          23696,
          22208
        ],
        "credentials": {
          "postgres": {
            "id": "zEr7jPswZNv6lWKu",
            "name": "Supabase PostgreSQL"
          }
        },
        "continueOnFail": true,
        "onError": "continueErrorOutput"
      },
      {
        "parameters": {
          "operation": "executeQuery",
          "query": "={{ $json.new_tasks && $json.new_tasks.length > 0 ? \"INSERT INTO rag_task_executions (trace_id, task_id, intent_id, status, rag_called, attempt, query, confidence) VALUES \" + $json.new_tasks.map(t => `('${t.trace_id}', ${t.task_id}, '${t.intent_id}', '${t.status}', '${t.rag_called}', ${t.attempt}, '${t.query}', ${t.confidence})`).join(', ') + \" ON CONFLICT (trace_id, task_id) DO NOTHING\" : \"SELECT 1\" }}",
          "options": {}
        },
        "id": "3501e6a9-d1e6-41c8-8298-1b310f2f05f0",
        "name": "Postgres: Insert New Tasks",
        "type": "n8n-nodes-base.postgres",
        "typeVersion": 2.5,
        "position": [
          23680,
          22416
        ],
        "credentials": {
          "postgres": {
            "id": "zEr7jPswZNv6lWKu",
            "name": "Supabase PostgreSQL"
          }
        },
        "continueOnFail": true,
        "onError": "continueErrorOutput"
      },
      {
        "parameters": {
          "jsCode": "// ============================================\n// PATCH - Task Status Aggregator V10.4\n// FIX: Accumulation robuste des r\u00e9sultats pour Response Builder\n// ============================================\n//\n// PROBL\u00c8ME R\u00c9SOLU:\n// Le Response Builder V9.3 lit depuis staticData[`results_${traceId}`]\n// mais le Task Status Aggregator ne stockait pas toujours les r\u00e9sultats.\n//\n// SOLUTION:\n// 1. Toujours lire le r\u00e9sultat depuis Task Result Handler\n// 2. Toujours stocker dans staticData m\u00eame si pas de fallback\n// 3. Ajouter des logs pour debug\n//\n// INSTRUCTIONS:\n// 1. Ouvrir workflow \"V10.1 orchestrator copy\" (FZxkpldDbgV8AD_cg7IWG)\n// 2. \u00c9diter le n\u0153ud \"\ud83d\udcca Task Status Aggregator\"\n// 3. Remplacer tout le code par celui-ci\n// 4. Sauvegarder et tester\n// ============================================\n\nconst traceId = $node['Init V8 Security & Analysis'].json.trace_id;\nconst inputData = $json; // Donn\u00e9es du Fallback Monitor\n\nconsole.log(`[${traceId}] Task Status Aggregator V10.4 starting...`);\n\n// === 1. \u00c9TAT GLOBAL POUR ACCUMULATION ===\nconst staticData = $getWorkflowStaticData('global');\n\nconst resultsKey = `results_${traceId}`;\nif (!staticData[resultsKey]) {\n  staticData[resultsKey] = {\n    completed_tasks: [],\n    error_tasks: [],\n    skipped_tasks: [],\n    all_responses: []\n  };\n  console.log(`[${traceId}] Initialized results storage`);\n}\n\nconst accumulated = staticData[resultsKey];\n\n// === 2. LIRE LE R\u00c9SULTAT ACTUEL ===\n// IMPORTANT: Toujours lire depuis Task Result Handler\nlet currentResult = null;\n\ntry {\n  // Priorit\u00e9 1: Lire directement depuis Task Result Handler\n  const taskHandlerData = $node['\ud83d\udce5 Task Result Handler']?.json;\n  if (taskHandlerData) {\n    currentResult = {\n      task: taskHandlerData.task || {},\n      success: taskHandlerData.success || false,\n      response: taskHandlerData.response || '',\n      sources: taskHandlerData.sources || [],\n      confidence: taskHandlerData.confidence || 0,\n      error_message: taskHandlerData.error_message || null,\n      format_detected: taskHandlerData.format_detected || 'unknown'\n    };\n    console.log(`[${traceId}] Read from Task Result Handler: success=${currentResult.success}, format=${currentResult.format_detected}, response_length=${currentResult.response.length}`);\n  }\n} catch (e) {\n  console.log(`[${traceId}] Could not read Task Result Handler: ${e.message}`);\n}\n\n// Priorit\u00e9 2: Fallback Monitor (si disponible dans input)\nif (!currentResult && inputData && inputData.success !== undefined) {\n  currentResult = {\n    task: inputData.task || { task_id: inputData.task_id },\n    success: inputData.success,\n    response: inputData.response || '',\n    sources: inputData.sources || [],\n    confidence: inputData.confidence || 0,\n    error_message: inputData.failure_reason || null\n  };\n  console.log(`[${traceId}] Read from Fallback Monitor input`);\n}\n\n// === 3. AJOUTER LE R\u00c9SULTAT \u00c0 L'ACCUMULATION ===\nif (currentResult && currentResult.task) {\n  const taskId = currentResult.task.task_id;\n  const ragCalled = currentResult.task.rag_called || 'UNKNOWN';\n  \n  // \u00c9viter les doublons\n  const existsCompleted = accumulated.completed_tasks.some(t => t.task_id === taskId);\n  const existsError = accumulated.error_tasks.some(t => t.task_id === taskId);\n  \n  if (!existsCompleted && !existsError) {\n    if (currentResult.success) {\n      const completedTask = {\n        task_id: taskId,\n        rag_called: ragCalled,\n        response: currentResult.response || '',\n        sources: currentResult.sources || [],\n        confidence: currentResult.confidence || 0.5\n      };\n      \n      accumulated.completed_tasks.push(completedTask);\n      \n      // Ajouter \u00e0 all_responses pour la fusion\n      if (currentResult.response && currentResult.response.length > 10) {\n        accumulated.all_responses.push({\n          task_id: taskId,\n          rag: ragCalled,\n          response: currentResult.response,\n          confidence: currentResult.confidence || 0.5\n        });\n      }\n      \n      console.log(`[${traceId}] \u2705 Accumulated completed task ${taskId} (${ragCalled}): ${currentResult.response.length} chars, confidence=${currentResult.confidence}`);\n    } else {\n      accumulated.error_tasks.push({\n        task_id: taskId,\n        rag_called: ragCalled,\n        error_message: currentResult.error_message || 'Unknown error'\n      });\n      \n      console.log(`[${traceId}] \u274c Accumulated error task ${taskId} (${ragCalled}): ${currentResult.error_message}`);\n    }\n  } else {\n    console.log(`[${traceId}] Task ${taskId} already accumulated, skipping`);\n  }\n} else {\n  console.log(`[${traceId}] No valid current result to accumulate`);\n}\n\n// === 4. LIRE LE PLAN ORIGINAL POUR LE TOTAL ===\nlet totalTasks = 1;\nlet pendingTasks = [];\n\ntry {\n  const planData = $node['\ud83d\udcdd Format & Dispatch (Plan\u2192DB)'].json;\n  totalTasks = planData.total_tasks || planData.tasks_to_insert?.length || 1;\n  \n  // Calculer les pending\n  const completedIds = accumulated.completed_tasks.map(t => t.task_id);\n  const errorIds = accumulated.error_tasks.map(t => t.task_id);\n  const processedIds = [...completedIds, ...errorIds];\n  \n  const allTaskIds = (planData.tasks_to_insert || []).map(t => t.task_id);\n  pendingTasks = allTaskIds\n    .filter(id => !processedIds.includes(id))\n    .map(id => {\n      const task = planData.tasks_to_insert.find(t => t.task_id === id);\n      return {\n        task_id: id,\n        query: task?.query || '',\n        rag_called: task?.rag_called || 'STANDARD'\n      };\n    });\n    \n} catch (e) {\n  console.log(`[${traceId}] Could not read plan: ${e.message}`);\n}\n\n// === 5. CALCULER LES M\u00c9TRIQUES ===\nconst completedCount = accumulated.completed_tasks.length;\nconst errorCount = accumulated.error_tasks.length;\nconst pendingCount = pendingTasks.length;\nconst processedCount = completedCount + errorCount;\n\nconst completionRate = totalTasks > 0 ? processedCount / totalTasks : 0;\nconst avgConfidence = completedCount > 0 \n  ? accumulated.completed_tasks.reduce((sum, t) => sum + (t.confidence || 0), 0) / completedCount\n  : 0;\n\nconsole.log(`[${traceId}] Aggregation summary:`);\nconsole.log(`[${traceId}]   Completed: ${completedCount}, Errors: ${errorCount}, Pending: ${pendingCount}`);\nconsole.log(`[${traceId}]   Total tasks: ${totalTasks}, Completion: ${Math.round(completionRate * 100)}%`);\nconsole.log(`[${traceId}]   Avg confidence: ${avgConfidence.toFixed(4)}`);\nconsole.log(`[${traceId}]   All responses count: ${accumulated.all_responses.length}`);\n\n// === 6. DEBUG: Afficher les r\u00e9ponses accumul\u00e9es ===\nif (accumulated.all_responses.length > 0) {\n  accumulated.all_responses.forEach((r, i) => {\n    console.log(`[${traceId}]   Response ${i+1} (${r.rag}): ${r.response.substring(0, 100)}...`);\n  });\n}\n\n// === 7. FLAG DE COMPL\u00c9TION ===\nconst isComplete = pendingCount === 0;\n\n// === 8. OUTPUT ===\nreturn {\n  trace_id: traceId,\n  \n  // T\u00e2ches par statut\n  completed_tasks: accumulated.completed_tasks,\n  pending_tasks: pendingTasks,\n  error_tasks: accumulated.error_tasks,\n  \n  // R\u00e9ponses pour fusion (crucial pour Response Builder!)\n  accumulated_results: accumulated.completed_tasks,\n  all_responses: accumulated.all_responses,\n  \n  // M\u00e9triques\n  total_tasks: totalTasks,\n  completion_rate: completionRate,\n  average_confidence: avgConfidence,\n  \n  // Flags\n  has_failures: errorCount > 0,\n  has_pending: pendingCount > 0,\n  is_complete: isComplete,\n  \n  // R\u00e9sum\u00e9\n  summary: {\n    completed: completedCount,\n    pending: pendingCount,\n    errors: errorCount,\n    total: totalTasks,\n    completion_percentage: Math.round(completionRate * 100)\n  },\n  \n  // Debug info\n  _debug: {\n    results_key: resultsKey,\n    staticData_has_key: !!staticData[resultsKey],\n    responses_accumulated: accumulated.all_responses.length\n  }\n};\n"
        },
        "id": "11209e3f-7603-46d2-be3a-995b47251435",
        "name": "\ud83d\udcca Task Status Aggregator",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          22784,
          22112
        ]
      },
      {
        "parameters": {
          "jsCode": "// ============================================\n// NODE: Redis Failure Handler V10.1\n// PURPOSE: Graceful degradation si Redis down\n// ============================================\n\nconst redisData = $json;\nconst redisError = redisData.error || null;\n\n// R\u00e9cup\u00e9rer trace_id depuis Init\nlet traceId = 'unknown';\ntry {\n  traceId = $node['Init V8 Security & Analysis'].json.trace_id;\n} catch(e) {\n  traceId = `fallback-${Date.now()}`;\n}\n\n// === CAS 1: REDIS ERROR (service down) ===\nif (redisError) {\n  console.error(`[${traceId}] REDIS_FAILURE:`, {\n    error: redisError.message || 'Unknown',\n    timestamp: new Date().toISOString(),\n    trace_id: traceId\n  });\n  \n  return {\n    conversation_history: [],\n    context_status: 'DEGRADED',\n    redis_available: false,\n    warning: 'Redis unavailable - running in stateless mode',\n    trace_id: traceId\n  };\n}\n\n// === CAS 2: REDIS OK - Parser les donn\u00e9es ===\ntry {\n  const rawData = redisData.data;\n  \n  // Si pas de data \u2192 conversation nouvelle\n  if (!rawData || rawData === null || rawData === 'null') {\n    console.log(`[${traceId}] New conversation - no Redis data`);\n    return {\n      conversation_history: [],\n      context_status: 'NEW',\n      redis_available: true,\n      trace_id: traceId\n    };\n  }\n  \n  // Parser le JSON\n  const parsedData = JSON.parse(rawData);\n  const history = parsedData.history || [];\n  \n  console.log(`[${traceId}] Redis OK: ${history.length} messages in history`);\n  \n  return {\n    conversation_history: history,\n    context_status: 'FULL',\n    redis_available: true,\n    trace_id: traceId\n  };\n  \n} catch (parseError) {\n  // === CAS 3: REDIS DATA CORRUPTED ===\n  console.error(`[${traceId}] REDIS_PARSE_ERROR:`, parseError.message);\n  \n  return {\n    conversation_history: [],\n    context_status: 'CORRUPTED',\n    redis_available: true,\n    warning: 'Redis data corrupted - starting fresh',\n    trace_id: traceId\n  };\n}"
        },
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          17408,
          22624
        ],
        "id": "c7ee4ae3-47e2-44d7-b012-f138a2ed80c3",
        "name": "\ud83d\udee1\ufe0f Redis Failure Handler V10.1"
      },
      {
        "parameters": {
          "jsCode": "// ============================================\n// NODE: Context Compression V10.1\n// ============================================\n\nconst mergedContext = $json;\nconst conversationHistory = mergedContext.recent_messages || [];\nconst traceId = mergedContext.trace_id;\n\n// 3 derniers messages seulement\nconst recentHistory = conversationHistory.slice(-3);\n\n// R\u00e9sum\u00e9 compress\u00e9 des anciens\nlet compressedSummary = '';\nif (conversationHistory.length > 3) {\n  const olderHistory = conversationHistory.slice(0, -3);\n  compressedSummary = olderHistory\n    .map(h => h.query || h.message || '')\n    .filter(q => q.length > 0)\n    .join(' | ')\n    .substring(0, 500);\n}\n\n// D\u00e9tecter changement d'intention\nconst lastIntent = mergedContext.last_intent;\nconst intentionShift = lastIntent && lastIntent !== 'UNKNOWN';\n\n// Tokens \u00e9conomis\u00e9s\nconst originalTokens = conversationHistory.reduce((sum, h) => \n  sum + (h.query?.length || 0) + (h.response?.length || 0), 0) / 4;\nconst compressedTokens = recentHistory.reduce((sum, h) => \n  sum + (h.query?.length || 0) + (h.response?.length || 0), 0) / 4;\nconst tokensSaved = Math.max(0, originalTokens - compressedTokens);\n\nconsole.log(`[${traceId}] Compressed: ${conversationHistory.length} \u2192 ${recentHistory.length} msgs, ~${Math.round(tokensSaved)} tokens saved`);\n\nreturn {\n  ...mergedContext,\n  compressed_history: recentHistory,\n  compressed_summary: compressedSummary,\n  full_history_length: conversationHistory.length,\n  intention_shift: intentionShift,\n  tokens_saved: Math.round(tokensSaved)\n};"
        },
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          17792,
          21728
        ],
        "id": "ee9b5dbc-f858-451d-bf3e-2dabf78bdffe",
        "name": "\ud83d\udce6 Context Compression V10.1"
      },
      {
        "parameters": {
          "jsCode": "// ============================================\n// NODE: \ud83d\udd0d Query Classifier V10.1 + Adaptive Retrieval Gate\n// ============================================\n\nconst context = $json;\nconst query = context.query || '';\nconst traceId = context.trace_id;\nconst recentMessages = context.compressed_history || context.recent_messages || [];\n\n// === 1. CONVERSATIONAL DETECTION ===\nconst CONVERSATIONAL_PATTERNS = [\n  /^(hi|hello|hey|bonjour|salut)/i,\n  /^(thanks|thank you|merci)/i,\n  /^(ok|okay|yes|no|oui|non)$/i,\n  /^(bye|goodbye|au revoir)/i,\n  /how are you|comment (vas-tu|allez-vous)/i,\n  /can you help me/i\n];\n\nconst isConversational = \n  CONVERSATIONAL_PATTERNS.some(p => p.test(query)) ||\n  query.length < 15 ||\n  (recentMessages.length > 0 && query.split(' ').length < 5);\n\n// === 2. CACHE CHECK ===\nconst shouldCheckCache = \n  !isConversational && \n  query.length > 10 && \n  query.length < 200;\n\n// === 3. ADAPTIVE RETRIEVAL GATE ===\nconst RETRIEVAL_REQUIRED = [\n  /combien|quel.*total|quelle.*somme/i,\n  /qui.*responsable|quelle.*relation/i,\n  /selon|d'apr\u00e8s|dans.*document|notre/i,\n  /proc\u00e9dure|process|\u00e9tape|comment faire/i,\n  /politique|r\u00e8gle|r\u00e8glement/i\n];\n\nconst DIRECT_ANSWER = [\n  /qu'est-ce qu'un|d\u00e9finition de|c'est quoi/i,\n  /explique.*concept|comment.*fonctionne/i\n];\n\nlet needsRetrieval = true;\nlet retrievalReason = 'DEFAULT';\n\nfor (const pattern of RETRIEVAL_REQUIRED) {\n  if (pattern.test(query)) {\n    needsRetrieval = true;\n    retrievalReason = 'DOMAIN_SPECIFIC';\n    break;\n  }\n}\n\nif (retrievalReason === 'DEFAULT') {\n  for (const pattern of DIRECT_ANSWER) {\n    if (pattern.test(query)) {\n      needsRetrieval = false;\n      retrievalReason = 'GENERAL_KNOWLEDGE';\n      break;\n    }\n  }\n}\n\n// === 4. ROUTE DECISION ===\nlet route = 'agent';\n\nif (isConversational) {\n  route = 'conversational';\n} else if (shouldCheckCache) {\n  route = 'cache_check';\n} else if (!needsRetrieval) {\n  route = 'direct_llm';\n}\n\nconsole.log(`[${traceId}] Route: ${route}, Retrieval: ${needsRetrieval} (${retrievalReason})`);\n\nreturn {\n  ...context,\n  query_route: route,\n  is_conversational: isConversational,\n  should_check_cache: shouldCheckCache,\n  needs_retrieval: needsRetrieval,\n  retrieval_reason: retrievalReason\n};\n"
        },
        "id": "9e99068a-a937-4369-99d4-b3b062c83ac4",
        "name": "\ud83d\udd0d Query Classifier V10.1",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          18256,
          21904
        ]
      },
      {
        "parameters": {
          "method": "POST",
          "url": "={{ $vars.OPENROUTER_BASE_URL || 'https://openrouter.ai/api/v1' }}/chat/completions",
          "authentication": "predefinedCredentialType",
          "nodeCredentialType": "openRouterApi",
          "sendBody": true,
          "specifyBody": "json",
          "jsonBody": "={\n  \"model\": \"{{ $vars.LLM_FAST_MODEL || 'google/gemini-2.5-flash' }}\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"Tu es l'INTENT ANALYZER d'un syst\u00e8me RAG multi-moteurs sophistiqu\u00e9.\\n\\n=== TA MISSION ===\\n1. Analyser la query utilisateur\\n2. Identifier TOUS les intents (explicites ET implicites)\\n3. D\u00e9terminer les D\u00c9PENDANCES entre intents\\n4. Assigner le moteur RAG optimal pour chaque intent\\n\\n=== MOTEURS RAG DISPONIBLES ===\\n\\n**STANDARD (Pinecone + BM25)**\\n- Forces: faits, proc\u00e9dures, d\u00e9finitions\\n\\n**GRAPH (Neo4j)**\\n- Forces: relations, hi\u00e9rarchies, impacts\\n\\n**QUANTITATIVE (PostgreSQL)**\\n- Forces: chiffres, totaux, moyennes, KPIs\\n\\n=== FORMAT JSON STRICT ===\\n{\\n  \\\"reasoning\\\": \\\"<ton analyse>\\\",\\n  \\\"intents\\\": [{\\\"id\\\": \\\"intent-1\\\", \\\"type\\\": \\\"FACTUAL|QUANTITATIVE|RELATIONAL\\\", \\\"suggested_rag\\\": \\\"STANDARD|GRAPH|QUANTITATIVE\\\", \\\"priority\\\": 1}],\\n  \\\"execution_order\\\": [\\\"intent-1\\\"],\\n  \\\"complexity\\\": \\\"SIMPLE|MODERATE|COMPLEX\\\"\\n}\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"=== QUERY TO ANALYZE ===\\n{{ $node['Init V8 Security & Analysis'].json.query }}\"\n    }\n  ],\n  \"temperature\": 0.1,\n  \"max_tokens\": 800,\n  \"response_format\": { \"type\": \"json_object\" }\n}",
          "options": {}
        },
        "type": "n8n-nodes-base.httpRequest",
        "typeVersion": 4.3,
        "position": [
          19056,
          22496
        ],
        "id": "6bfcc7d3-9915-43c4-abd9-4c299b5dd4b1",
        "name": "HTTP Request",
        "credentials": {
          "openRouterApi": {
            "id": "aTHBqnntMBApo0Dy",
            "name": "OpenRouter account"
          }
        }
      },
      {
        "parameters": {
          "operation": "executeQuery",
          "query": "SELECT task_id, intent_id, status, rag_called, attempt, query, response, confidence\nFROM rag_task_executions \nWHERE trace_id = '{{ $node[\"Init V8 Security & Analysis\"].json.trace_id }}'\nORDER BY task_id ASC",
          "options": {}
        },
        "type": "n8n-nodes-base.postgres",
        "typeVersion": 2.6,
        "position": [
          21216,
          22528
        ],
        "id": "7fa85861-eefe-48f9-a03c-7dad6fc40c94",
        "name": "Postgres : Get Current Tasks",
        "credentials": {
          "postgres": {
            "id": "zEr7jPswZNv6lWKu",
            "name": "Supabase PostgreSQL"
          }
        }
      },
      {
        "parameters": {
          "numberInputs": 4
        },
        "type": "n8n-nodes-base.merge",
        "typeVersion": 3.2,
        "position": [
          24864,
          22160
        ],
        "id": "713d6797-3083-4119-a1b3-a86bcf0b5c77",
        "name": "Merge",
        "onError": "continueRegularOutput"
      },
      {
        "parameters": {
          "conditions": {
            "options": {
              "caseSensitive": true,
              "leftValue": "",
              "typeValidation": "strict",
              "version": 3
            },
            "conditions": [
              {
                "id": "ebee2253-8093-451a-bf3b-5b00e78fdc69",
                "leftValue": "={{ $json.all_complete }}",
                "rightValue": true,
                "operator": {
                  "type": "boolean",
                  "operation": "equals"
                }
              }
            ],
            "combinator": "and"
          },
          "options": {}
        },
        "type": "n8n-nodes-base.if",
        "typeVersion": 2.3,
        "position": [
          21504,
          22816
        ],
        "id": "357e6360-0498-4633-b5f8-30061ecd941a",
        "name": "If"
      },
      {
        "parameters": {
          "conditions": {
            "options": {
              "caseSensitive": true,
              "leftValue": "",
              "typeValidation": "strict",
              "version": 3
            },
            "conditions": [
              {
                "id": "f64b093e-7578-418f-aa48-03ebc26d5a02",
                "leftValue": "={{$json.all_tasks_complete}}",
                "rightValue": false,
                "operator": {
                  "type": "boolean",
                  "operation": "equals"
                }
              }
            ],
            "combinator": "and"
          },
          "options": {}
        },
        "type": "n8n-nodes-base.if",
        "typeVersion": 2.3,
        "position": [
          23504,
          21984
        ],
        "id": "ea57ed6e-ec10-4c32-9600-d5859f56d625",
        "name": "If1"
      }
    ],
    "connections": {
      "Webhook V8": {
        "main": [
          [
            {
              "node": "Input Merger V8",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Chat Trigger V8": {
        "main": [
          [
            {
              "node": "Input Merger V8",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Input Merger V8": {
        "main": [
          [
            {
              "node": "Init V8 Security & Analysis",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Init V8 Security & Analysis": {
        "main": [
          [
            {
              "node": "Redis: Fetch Conversation",
              "type": "main",
              "index": 0
            },
            {
              "node": "Postgres L2/L3 Memory",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Redis: Fetch Conversation": {
        "main": [
          [
            {
              "node": "\ud83d\udee1\ufe0f Redis Failure Handler V10.1",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "\ud83d\udee1\ufe0f Rate Limit Guard": {
        "main": [
          [
            {
              "node": "IF: Rate Limited?",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "IF: Rate Limited?": {
        "main": [
          [
            {
              "node": "\ud83e\udde0 Memory Merger (Redis + Postgres)",
              "type": "main",
              "index": 0
            }
          ],
          [
            {
              "node": "Return: Rate Limited",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Postgres L2/L3 Memory": {
        "main": [
          [
            {
              "node": "\ud83e\udde0 Memory Merger (Redis + Postgres)",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "\ud83e\udde0 Memory Merger (Redis + Postgres)": {
        "main": [
          [
            {
              "node": "\ud83d\udce6 Context Compression V10.1",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "\ud83d\udee1\ufe0f Advanced Guardrails": {
        "main": [
          [
            {
              "node": "IF: Guardrail Passed?",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "IF: Guardrail Passed?": {
        "main": [
          [
            {
              "node": "\ud83d\udd0d Query Classifier V10.1",
              "type": "main",
              "index": 0
            }
          ],
          [
            {
              "node": "Return: Guardrail Blocked",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "\ud83d\udd00 Query Router": {
        "main": [
          [
            {
              "node": "\ud83d\udcac Conversational Handler",
              "type": "main",
              "index": 0
            }
          ],
          [
            {
              "node": "\ud83d\udd0e Cache Semantic Search",
              "type": "main",
              "index": 0
            }
          ],
          [
            {
              "node": "HTTP Request",
              "type": "main",
              "index": 0
            }
          ],
          [
            {
              "node": "\ud83e\udde0 LLM 1: Intent Analyzer",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "\ud83d\udcac Conversational Handler": {
        "main": [
          [
            {
              "node": "Return: Conversational",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "\ud83d\udd0e Cache Semantic Search": {
        "main": [
          [
            {
              "node": "Redis: Cache + Generator",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Redis: Cache + Generator": {
        "main": [
          [
            {
              "node": "Cache Parser",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Cache Parser": {
        "main": [
          [
            {
              "node": "IF: Cache Hit?",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "IF: Cache Hit?": {
        "main": [
          [
            {
              "node": "Return: Cached",
              "type": "main",
              "index": 0
            }
          ],
          [
            {
              "node": "\ud83e\udde0 LLM 1: Intent Analyzer",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "\ud83e\udde0 LLM 1: Intent Analyzer": {
        "main": [
          [
            {
              "node": "Intent Parser V9",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Intent Parser V9": {
        "main": [
          [
            {
              "node": "\ud83c\udfaf LLM 2: Task Planner",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "\ud83c\udfaf LLM 2: Task Planner": {
        "main": [
          [
            {
              "node": "Postgres: Init Tasks Table",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Postgres: Init Tasks Table": {
        "main": [
          [
            {
              "node": "\ud83d\udcdd Format & Dispatch (Plan\u2192DB)",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "\ud83d\udcdd Format & Dispatch (Plan\u2192DB)": {
        "main": [
          [
            {
              "node": "Postgres: Insert Tasks",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Postgres: Insert Tasks": {
        "main": [
          [
            {
              "node": "Postgres : Get Current Tasks",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "\u2699\ufe0f Execution Engine V10": {
        "main": [
          [
            {
              "node": "If",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "\ud83d\udd00 Dynamic Switch V10": {
        "main": [
          [
            {
              "node": "Invoke WF5: Standard",
              "type": "main",
              "index": 0
            }
          ],
          [
            {
              "node": "Invoke WF2: Graph",
              "type": "main",
              "index": 0
            }
          ],
          [
            {
              "node": "Invoke WF4: Quantitative",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Invoke WF5: Standard": {
        "main": [
          [
            {
              "node": "\ud83d\udce5 Task Result Handler",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Invoke WF2: Graph": {
        "main": [
          [
            {
              "node": "\ud83d\udce5 Task Result Handler",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Invoke WF4: Quantitative": {
        "main": [
          [
            {
              "node": "\ud83d\udce5 Task Result Handler",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "\ud83d\udce5 Task Result Handler": {
        "main": [
          [
            {
              "node": "Postgres: Update Task",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Postgres: Update Task": {
        "main": [
          [
            {
              "node": "\ud83d\udd04 Fallback Monitor V10",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "\ud83d\udd04 Fallback Monitor V10": {
        "main": [
          [
            {
              "node": "IF: Fallback Needed?",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "IF: Fallback Needed?": {
        "main": [
          [
            {
              "node": "\ud83d\udd04 Fallback Dispatch",
              "type": "main",
              "index": 0
            }
          ],
          [
            {
              "node": "\ud83d\udcca Task Status Aggregator",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "\ud83d\udd04 Fallback Dispatch": {
        "main": [
          [
            {
              "node": "Postgres: Update Fallback",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Postgres: Update Fallback": {
        "main": [
          [
            {
              "node": "Postgres : Get Current Tasks",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "\ud83d\udcca Task Status Aggregator": {
        "main": [
          [
            {
              "node": "\ud83c\udfaf LLM 3: Agent Harness (Opus 4.5)",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "\ud83c\udfaf LLM 3: Agent Harness (Opus 4.5)": {
        "main": [
          [
            {
              "node": "\ud83d\udcca Agent Decision Parser",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "\ud83d\udcca Agent Decision Parser": {
        "main": [
          [
            {
              "node": "\ud83d\udd04 Task Updater",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "\ud83d\udd04 Task Updater": {
        "main": [
          [
            {
              "node": "If1",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Postgres: Apply Skips": {
        "main": [
          [
            {
              "node": "Postgres : Get Current Tasks",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Postgres: Insert New Tasks": {
        "main": [
          [
            {
              "node": "Postgres : Get Current Tasks",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Response Builder V9": {
        "main": [
          [
            {
              "node": "\ud83d\udcbe Cache Storage",
              "type": "main",
              "index": 0
            },
            {
              "node": "Store RLHF Data V8",
              "type": "main",
              "index": 0
            },
            {
              "node": "Redis: Store Conv V8",
              "type": "main",
              "index": 0
            },
            {
              "node": "Postgres: Update Context V8",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "\ud83d\udcbe Cache Storage": {
        "main": [
          [
            {
              "node": "Redis: Set Cache",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Redis: Set Cache": {
        "main": [
          [
            {
              "node": "Merge",
              "type": "main",
              "index": 2
            }
          ]
        ]
      },
      "Store RLHF Data V8": {
        "main": [
          [
            {
              "node": "Merge",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Redis: Store Conv V8": {
        "main": [
          [
            {
              "node": "Merge",
              "type": "main",
              "index": 3
            }
          ]
        ]
      },
      "Postgres: Update Context V8": {
        "main": [
          [
            {
              "node": "Merge",
              "type": "main",
              "index": 1
            }
          ]
        ]
      },
      "Output Router (Final)": {
        "main": [
          [
            {
              "node": "Chat: Final V8",
              "type": "main",
              "index": 0
            }
          ],
          [
            {
              "node": "Return Response V8",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Error Handler V8": {
        "main": [
          [
            {
              "node": "Error Payload V8",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Error Payload V8": {
        "main": [
          [
            {
              "node": "Export Error V8",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Export Error V8": {
        "main": [
          [
            {
              "node": "Return: Error Response",
              "type": "main",
              "index": 0
            }
          ],
          [
            {
              "node": "Return: Error Response",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "\ud83d\udee1\ufe0f Redis Failure Handler V10.1": {
        "main": [
          [
            {
              "node": "\ud83d\udee1\ufe0f Rate Limit Guard",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "\ud83d\udce6 Context Compression V10.1": {
        "main": [
          [
            {
              "node": "\ud83d\udee1\ufe0f Advanced Guardrails",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "\ud83d\udd0d Query Classifier V10.1": {
        "main": [
          [
            {
              "node": "\ud83d\udd00 Query Router",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "HTTP Request": {
        "main": [
          [
            {
              "node": "Intent Parser V9",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Postgres : Get Current Tasks": {
        "main": [
          [
            {
              "node": "\u2699\ufe0f Execution Engine V10",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Merge": {
        "main": [
          [
            {
              "node": "Output Router (Final)",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "If": {
        "main": [
          [
            {
              "node": "Response Builder V9",
              "type": "main",
              "index": 0
            }
          ],
          [
            {
              "node": "\ud83d\udd00 Dynamic Switch V10",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "If1": {
        "main": [
          [
            {
              "node": "Postgres: Apply Skips",
              "type": "main",
              "index": 0
            },
            {
              "node": "Postgres: Insert New Tasks",
              "type": "main",
              "index": 0
            }
          ],
          [
            {
              "node": "Postgres : Get Current Tasks",
              "type": "main",
              "index": 0
            }
          ]
        ]
      }
    },
    "authors": "Alexis Moret",
    "name": null,
    "description": null,
    "autosaved": false,
    "workflowPublishHistory": [
      {
        "createdAt": "2026-02-07T10:32:05.827Z",
        "id": 616,
        "workflowId": "FZxkpldDbgV8AD_cg7IWG",
        "versionId": "a14aa943-38f0-4b6e-b06f-7562f21ceea4",
        "event": "activated",
        "userId": "215767e0-958a-4c74-a67a-e335807eba64"
      }
    ]
  }
}