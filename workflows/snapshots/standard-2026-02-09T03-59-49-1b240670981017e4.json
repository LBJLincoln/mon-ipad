{
  "updatedAt": "2026-02-09T03:54:23.243Z",
  "createdAt": "2026-01-30T16:51:51.530Z",
  "id": "LnTqRX4LZlI009Ks-3Jnp",
  "name": "TEST - SOTA 2026 - WF5 Standard RAG V3.4 - CORRECTED",
  "description": null,
  "active": true,
  "isArchived": true,
  "nodes": [
    {
      "parameters": {},
      "id": "d7dec400-09bd-4f08-8c55-cc966bfe142a",
      "name": "Sub-Workflow Trigger",
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1,
      "position": [
        2464,
        2816
      ]
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "rag-multi-index-v3",
        "responseMode": "lastNode",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2.1,
      "position": [
        2464,
        3152
      ],
      "id": "9839607f-defe-49f1-95f8-790a491557dc",
      "name": "Webhook",
      "webhookId": "rag-multi-index-v3"
    },
    {
      "parameters": {
        "jsCode": "// Init & ACL Pre-Filter V3.4 - With Adaptive TopK\nconst rawInput = $input.first().json;\nconst input = rawInput.body || rawInput;\n\n// Parse query robustement\nlet queryStr = '';\nif (typeof input.query === 'string') {\n  queryStr = input.query;\n} else if (input.query && typeof input.query === 'object') {\n  queryStr = JSON.stringify(input.query);\n} else {\n  queryStr = String(input.query || '');\n}\n\nconst userContext = input.user_context || {};\nconst tenantId = userContext.tenant_id || input.tenant_id || 'default';\nconst userGroups = Array.isArray(userContext.groups) ? userContext.groups : ['admin', 'guest'];\n\n// V3.4: Analyse de complexitÃ© pour adaptive top_k\nconst COMPLEXITY_INDICATORS = {\n  simple: /^(qu'est-ce que|dÃ©finition|c'est quoi)/i,\n  moderate: /(comment|pourquoi|expliquer)/i,\n  complex: /(comparer|analyser|impact|relation|entre.*et)/i,\n  multi_hop: /(quel.*puis|d'abord.*ensuite|en tenant compte)/i\n};\n\nlet complexity = 'moderate';\nlet adaptiveTopK = 15;\n\nif (COMPLEXITY_INDICATORS.simple.test(queryStr)) {\n  complexity = 'simple';\n  adaptiveTopK = 8;\n} else if (COMPLEXITY_INDICATORS.multi_hop.test(queryStr)) {\n  complexity = 'complex';\n  adaptiveTopK = 25;\n} else if (COMPLEXITY_INDICATORS.complex.test(queryStr)) {\n  complexity = 'complex';\n  adaptiveTopK = 20;\n}\n\n// V3.4: Detect if query needs decomposition\nconst needsDecomposition = queryStr.length > 100 || \n                          queryStr.includes(' et ') ||\n                          queryStr.includes(' ainsi que ') ||\n                          COMPLEXITY_INDICATORS.complex.test(queryStr);\n\n// ACL filter (dÃ©sactivÃ© par dÃ©faut pour compatibilitÃ©)\nconst disableAcl = (input.disable_acl === true);\nconst aclFilter = disableAcl ? {} : {\n  \"$or\": [\n    { \"tenant_id\": tenantId, \"allowed_groups\": { \"$in\": userGroups } },\n    { \"tenant_id\": { \"$exists\": false } }\n  ]\n};\n\nreturn [{\n  json: {\n    trace_id: input.trace_id || 'tr-' + Date.now(),\n    query: queryStr.trim(),\n    acl_filter: aclFilter,\n    acl_disabled: disableAcl,\n    user_context: { tenant_id: tenantId, groups: userGroups },\n    \n    // V3.4 Enhancements\n    complexity: complexity,\n    topK: Math.min(input.topK || adaptiveTopK, 50),\n    adaptive_topK: adaptiveTopK,\n    needs_decomposition: needsDecomposition\n  }\n}];"
      },
      "id": "9e9a1c50-0934-43a7-9185-5616ab227650",
      "name": "Init & ACL Pre-Filter V3.4",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2704,
        2960
      ],
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{ $vars.OPENROUTER_BASE_URL || 'https://openrouter.ai/api/v1/chat/completions' }}",
        "authentication": "none",
        "nodeCredentialType": "openRouterApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"{{ $vars.LLM_HYDE_MODEL || 'meta-llama/llama-3.3-70b-instruct:free' }}\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"Genere un document hypothetique de 150-200 mots qui repondrait parfaitement a la question.\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": {{ JSON.stringify($node['Init & ACL Pre-Filter V3.4'].json.query || '') }}\n    }\n  ],\n  \"temperature\": 0.7,\n  \"max_tokens\": 400\n}",
        "options": {
          "batching": {
            "batch": {
              "batchSize": 1
            }
          },
          "timeout": 20000,
          "retry": {
            "maxTries": 3,
            "waitBetweenTries": 2000
          }
        },
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "=Bearer {{ $vars.OPENROUTER_API_KEY }}"
            }
          ]
        }
      },
      "id": "2203b6fc-10ed-43f1-8814-134887ef30b3",
      "name": "HyDE Generator",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        3520,
        2480
      ],
      "credentials": {},
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{ $vars.EMBEDDING_API_URL || 'https://openrouter.ai/api/v1/embeddings' }}",
        "authentication": "none",
        "nodeCredentialType": "openRouterApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"{{ $vars.EMBEDDING_MODEL || 'text-embedding-3-small' }}\",\n  \"input\": {{ JSON.stringify($node['HyDE Generator'].json.choices?.[0]?.message?.content || $node['Init & ACL Pre-Filter V3.4'].json.query || '') }}\n}",
        "options": {
          "batching": {
            "batch": {
              "batchSize": 1
            }
          },
          "timeout": 10000,
          "retry": {
            "maxTries": 3,
            "waitBetweenTries": 2000
          }
        },
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "=Bearer {{ $vars.OPENROUTER_API_KEY }}"
            }
          ]
        }
      },
      "id": "89633b5e-e055-4431-a38b-2963e872fba3",
      "name": "HyDE Embedding",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        3728,
        2480
      ],
      "credentials": {},
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{ $vars.PINECONE_URL }}/query",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"vector\": {{ JSON.stringify($node['HyDE Embedding'].json.data?.[0]?.embedding || []) }},\n  \"topK\": {{ $node['Init & ACL Pre-Filter V3.4'].json.topK || 20 }},\n  \"includeMetadata\": true\n}",
        "options": {
          "batching": {
            "batch": {
              "batchSize": 1
            }
          },
          "timeout": 15000
        }
      },
      "id": "89900633-eadc-4623-8317-34bd140d3019",
      "name": "HTTP Pinecone Query HyDE",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        3936,
        2480
      ],
      "credentials": {
        "httpHeaderAuth": {
          "id": "3DEiHDwB09D65919",
          "name": "Pinecone API Key"
        }
      },
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{ $vars.EMBEDDING_API_URL || 'https://openrouter.ai/api/v1/embeddings' }}",
        "authentication": "none",
        "nodeCredentialType": "openRouterApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"{{ $vars.EMBEDDING_MODEL || 'text-embedding-3-small' }}\",\n  \"input\": {{ JSON.stringify($node['Init & ACL Pre-Filter V3.4'].json.query || '') }}\n}",
        "options": {
          "batching": {
            "batch": {
              "batchSize": 1
            }
          },
          "timeout": 10000,
          "retry": {
            "maxTries": 3,
            "waitBetweenTries": 2000
          }
        },
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "=Bearer {{ $vars.OPENROUTER_API_KEY }}"
            }
          ]
        }
      },
      "id": "845805cf-5935-4b94-b320-7cf6042c94e9",
      "name": "Original Embedding",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        3152,
        3424
      ],
      "credentials": {},
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{ $vars.PINECONE_URL }}/query",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"vector\": {{ JSON.stringify($node['Original Embedding'].json.data?.[0]?.embedding || []) }},\n  \"topK\": {{ $node['Init & ACL Pre-Filter V3.4'].json.topK || 20 }},\n  \"includeMetadata\": true\n}",
        "options": {
          "batching": {
            "batch": {
              "batchSize": 1
            }
          },
          "timeout": 15000
        }
      },
      "id": "cd9fa21b-05c1-4b06-8b9d-63aabae79a91",
      "name": "HTTP Pinecone Query Original",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        3392,
        3440
      ],
      "credentials": {
        "httpHeaderAuth": {
          "id": "3DEiHDwB09D65919",
          "name": "Pinecone API Key"
        }
      },
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT id, content, source, \n       ts_rank(to_tsvector('french', content), plainto_tsquery('french', $1)) as bm25_score\nFROM documents \nWHERE is_obsolete = false \n  AND tenant_id = $2\n  AND to_tsvector('french', content) @@ plainto_tsquery('french', $1)\nORDER BY bm25_score DESC LIMIT 20",
        "options": {
          "queryReplacement": "=={{ $node['Init & ACL Pre-Filter V3.4'].json.query }},{{ $node['Init & ACL Pre-Filter V3.4'].json.user_context.tenant_id }}"
        }
      },
      "id": "935d1864-4a23-4add-8697-621cb9880b38",
      "name": "BM25 Search Postgres",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.4,
      "position": [
        3696,
        3344
      ],
      "credentials": {
        "postgres": {
          "id": "zEr7jPswZNv6lWKu",
          "name": "Supabase PostgreSQL"
        }
      },
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineAll",
        "options": {}
      },
      "id": "a7b5a315-c936-473e-b030-8547a516ef3f",
      "name": "Wait All Branches",
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.1,
      "position": [
        3696,
        3040
      ],
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "jsCode": "// ============================================\n// PATCH 07 - RRF Merge & Rank V3.4.2\n// FIX: Lecture robuste des 3 sources (HyDE, Original, BM25)\n// ============================================\n//\n// PROBLÃˆME RÃ‰SOLU:\n// Le code prÃ©cÃ©dent Ã©chouait silencieusement sur BM25\n// car le nÅ“ud Merge ne passait pas les donnÃ©es correctement.\n//\n// SOLUTION:\n// Lire directement depuis chaque nÅ“ud source au lieu\n// de dÃ©pendre du Merge node.\n//\n// INSTRUCTIONS:\n// 1. Ouvrir le nÅ“ud \"RRF Merge & Rank V3.4\" dans le workflow RAG Standard\n// 2. Remplacer tout le code par celui-ci\n// 3. Sauvegarder\n// ============================================\n\n// RRF Merge & Rank V3.4.2 - Direct source reading\nconst k = 60; // ParamÃ¨tre RRF standard\nconst BOOSTS = { hyde: 1.5, bm25: 1.2, pinecone: 1.0 };\nlet scores = {};\nlet warnings = [];\nlet sourcesAvailable = 0;\n\n// RÃ©cupÃ©rer les mÃ©tadonnÃ©es\nconst initData = $node['Init & ACL Pre-Filter V3.4'].json;\nconst traceId = initData.trace_id;\n\n// V3.4: Check if queries were decomposed\nlet isDecomposed = false;\ntry {\n  const queryData = $node['Query Merger V3.4']?.json;\n  isDecomposed = queryData?.is_decomposed || false;\n} catch (e) {\n  // Query Merger pas dans le flux\n}\nconst decompositionBoost = isDecomposed ? 1.1 : 1.0;\n\n// === HELPER FUNCTIONS ===\nfunction extractContent(metadata) {\n  return metadata?.text || metadata?.content || metadata?.chunk_text || metadata?.page_content || '';\n}\n\nfunction safeReadNode(nodeName) {\n  try {\n    return $node[nodeName]?.json;\n  } catch (e) {\n    console.log(`[${traceId}] Cannot read ${nodeName}: ${e.message}`);\n    return null;\n  }\n}\n\n// === SOURCE 1: HyDE Pinecone ===\nconsole.log(`[${traceId}] Reading HyDE results...`);\ntry {\n  const hydeData = safeReadNode('HTTP Pinecone Query HyDE');\n  const hydeMatches = hydeData?.matches || [];\n  \n  if (hydeMatches.length > 0) {\n    sourcesAvailable++;\n    hydeMatches.forEach((item, index) => {\n      const id = item.id;\n      const rrfScore = (1 / (k + index + 1)) * BOOSTS.hyde * decompositionBoost;\n      \n      if (scores[id]) { \n        scores[id].score += rrfScore; \n        if (!scores[id].sources.includes('hyde')) {\n          scores[id].sources.push('hyde');\n        }\n      } else { \n        scores[id] = { \n          score: rrfScore, \n          data: item.metadata, \n          pineconeScore: item.score, \n          sources: ['hyde'] \n        }; \n      }\n    });\n    console.log(`[${traceId}] HyDE: ${hydeMatches.length} results added`);\n  } else { \n    warnings.push('HyDE: 0 results'); \n  }\n} catch(e) { \n  warnings.push('HyDE error: ' + e.message);\n  console.error(`[${traceId}] HyDE error:`, e.message);\n}\n\n// === SOURCE 2: Original Pinecone ===\nconsole.log(`[${traceId}] Reading Original Embedding results...`);\ntry {\n  const originalData = safeReadNode('HTTP Pinecone Query Original');\n  const originalMatches = originalData?.matches || [];\n  \n  if (originalMatches.length > 0) {\n    sourcesAvailable++;\n    originalMatches.forEach((item, index) => {\n      const id = item.id;\n      const rrfScore = (1 / (k + index + 1)) * BOOSTS.pinecone;\n      \n      if (scores[id]) { \n        scores[id].score += rrfScore; \n        if (!scores[id].sources.includes('original')) {\n          scores[id].sources.push('original'); \n        }\n      } else { \n        scores[id] = { \n          score: rrfScore, \n          data: item.metadata, \n          pineconeScore: item.score, \n          sources: ['original'] \n        }; \n      }\n    });\n    console.log(`[${traceId}] Original: ${originalMatches.length} results added`);\n  } else { \n    warnings.push('Original: 0 results'); \n  }\n} catch(e) { \n  warnings.push('Original error: ' + e.message);\n  console.error(`[${traceId}] Original error:`, e.message);\n}\n\n// === SOURCE 3: BM25 Postgres ===\nconsole.log(`[${traceId}] Reading BM25 results...`);\ntry {\n  const bm25Raw = safeReadNode('BM25 Search Postgres');\n  \n  // BM25 peut retourner diffÃ©rents formats:\n  // - Array de rÃ©sultats\n  // - Objet unique avec {id, content, bm25_score}\n  // - Null/undefined si erreur\n  \n  let bm25Data = [];\n  \n  if (Array.isArray(bm25Raw)) {\n    bm25Data = bm25Raw;\n  } else if (bm25Raw && typeof bm25Raw === 'object') {\n    if (bm25Raw.id) {\n      // Single result object\n      bm25Data = [bm25Raw];\n    } else if (bm25Raw.error) {\n      // Postgres error\n      throw new Error(bm25Raw.error.message || 'Postgres error');\n    }\n  }\n  \n  // Filtrer les rÃ©sultats valides\n  bm25Data = bm25Data.filter(item => item && item.id && item.content);\n  \n  if (bm25Data.length > 0) {\n    sourcesAvailable++;\n    bm25Data.forEach((item, index) => {\n      const id = 'bm25-' + String(item.id);\n      const rrfScore = (1 / (k + index + 1)) * BOOSTS.bm25;\n      \n      if (scores[id]) { \n        scores[id].score += rrfScore; \n        scores[id].sources.push('bm25'); \n      } else { \n        scores[id] = { \n          score: rrfScore, \n          data: { \n            content: item.content, \n            source: item.source || 'postgres', \n            text: item.content \n          }, \n          bm25Score: item.bm25_score, \n          sources: ['bm25'] \n        }; \n      }\n    });\n    console.log(`[${traceId}] BM25: ${bm25Data.length} results added`);\n  } else { \n    warnings.push('BM25: 0 results (may need tenant_id configuration)'); \n  }\n} catch(e) { \n  warnings.push('BM25 error: ' + e.message);\n  console.error(`[${traceId}] BM25 error:`, e.message);\n}\n\n// === RANKING FINAL ===\n// R03 SOTA 2026: Min-max normalization of RRF scores before final ranking\nconst allEntries = Object.entries(scores)\n  .map(([id, r]) => ({ id, ...r }));\n\nif (allEntries.length > 1) {\n  const rawScores = allEntries.map(e => e.score);\n  const minScore = Math.min(...rawScores);\n  const maxScore = Math.max(...rawScores);\n  const range = maxScore - minScore;\n  if (range > 0) {\n    allEntries.forEach(e => {\n      e.raw_rrf_score = e.score;\n      e.score = (e.score - minScore) / range;\n    });\n    console.log(`[${traceId}] RRF normalization applied: min=${minScore.toFixed(6)}, max=${maxScore.toFixed(6)}`);\n  }\n}\n\nconst ranked = allEntries.sort((a, b) => b.score - a.score);\n\nconst hasResults = ranked.length > 0;\n\nconsole.log(`[${traceId}] RRF complete: ${ranked.length} unique docs from ${sourcesAvailable} sources`);\nif (warnings.length > 0) {\n  console.log(`[${traceId}] Warnings: ${warnings.join(', ')}`);\n}\n\n// === OUTPUT ===\nreturn [{\n  json: {\n    results: ranked.slice(0, 15).map(r => ({\n      id: r.id,\n      content: extractContent(r.data),\n      source: r.data?.source || r.data?.dataset || 'unknown',\n      rrf_score: Math.round(r.score * 10000) / 10000,\n      raw_rrf_score: r.raw_rrf_score ? Math.round(r.raw_rrf_score * 10000) / 10000 : undefined,\n      pinecone_score: r.pineconeScore,\n      bm25_score: r.bm25Score,\n      sources_used: r.sources\n    })),\n    metadata: { \n      sources_available: sourcesAvailable,\n      total_unique_docs: ranked.length,\n      warnings: warnings,\n      is_decomposed: isDecomposed,\n      rrf_normalized: true,\n      version: '3.4.3',\n      trace_id: traceId\n    },\n    skip_reranker: !hasResults\n  }\n}];"
      },
      "id": "fc784fa1-20eb-4687-abb8-e260880099d4",
      "name": "RRF Merge & Rank V3.4",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3888,
        3040
      ],
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{ $vars.RERANKER_API_URL || 'https://api.cohere.ai/v1/rerank' }}",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"{{ $vars.RERANKER_MODEL || 'rerank-v3.5' }}\",\n  \"query\": {{ JSON.stringify($node['Init & ACL Pre-Filter V3.4'].json.query || '') }},\n  \"documents\": {{ $json.skip_reranker ? '[\"placeholder\"]' : JSON.stringify(($json.results || []).map(r => r.content || '').filter(c => c.length > 0).slice(0, 25)) }},\n  \"top_n\": 10\n}",
        "options": {
          "batching": {
            "batch": {
              "batchSize": 1
            }
          },
          "timeout": 15000
        }
      },
      "id": "dd352491-9109-477d-8c93-d8b4576d238d",
      "name": "Cohere Reranker",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        4080,
        3040
      ],
      "credentials": {
        "httpHeaderAuth": {
          "id": "7UPUQvFQVksMajPL",
          "name": "Cohere API Key"
        }
      },
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "jsCode": "// ============================================\n// PATCH 02-FIX - Rerank Merger V3.4.2\n// FIX: Gestion correcte du type d'erreur Cohere\n// ============================================\n// \n// PROBLÃˆME CORRIGÃ‰:\n// L'erreur \"cohereError.includes is not a function\" se produit\n// car cohereError est un OBJET (avec .message), pas une string.\n//\n// INSTRUCTIONS:\n// 1. Ouvrir le nÅ“ud \"Rerank Merger\" dans le workflow RAG Standard\n// 2. Remplacer tout le code par celui-ci\n// 3. Sauvegarder\n// ============================================\n\nconst rrfResults = $node['RRF Merge & Rank V3.4'].json.results || [];\nconst initData = $node['Init & ACL Pre-Filter V3.4'].json;\nconst metadata = $node['RRF Merge & Rank V3.4'].json.metadata || {};\nconst skipReranker = $node['RRF Merge & Rank V3.4'].json.skip_reranker;\nconst traceId = initData.trace_id;\n\n// === CAS 1: Aucun rÃ©sultat RRF ===\nif (rrfResults.length === 0 || skipReranker) {\n  console.log(`[${traceId}] No RRF results or skip_reranker - returning empty`);\n  return [{\n    json: {\n      results: [],\n      metadata: { ...metadata, reranked: false, empty_database: true },\n      skip_llm: false,\n      fallback_response: {\n        response: \"Je n'ai trouvÃ© aucun document pertinent dans la base de connaissances.\",\n        sources: [],\n        confidence: 0,\n        trace_id: traceId,\n        warning: \"NO_DOCUMENTS_FOUND\"\n      }\n    }\n  }];\n}\n\n// === CAS 2: Analyser la rÃ©ponse Cohere ===\nconst cohereResponse = $json;\nconst cohereResults = cohereResponse.results || [];\n\n// L'erreur peut Ãªtre un objet ou une string - extraire le message\nconst cohereErrorObj = cohereResponse.error;\nlet cohereErrorMsg = '';\nif (cohereErrorObj) {\n  if (typeof cohereErrorObj === 'string') {\n    cohereErrorMsg = cohereErrorObj;\n  } else if (typeof cohereErrorObj === 'object') {\n    cohereErrorMsg = cohereErrorObj.message || JSON.stringify(cohereErrorObj);\n  }\n}\n\nconst httpStatus = cohereResponse.statusCode || cohereResponse.status || cohereErrorObj?.status;\n\n// DÃ©tecter rate limit (429) ou autres erreurs\nconst isRateLimited = httpStatus === 429 || \n                      cohereErrorMsg.includes('429') ||\n                      cohereErrorMsg.toLowerCase().includes('rate');\nconst hasError = cohereErrorObj || cohereResults.length === 0;\n\nif (hasError) {\n  // === FALLBACK: Utiliser les scores RRF sans reranking ===\n  const reason = isRateLimited ? 'COHERE_RATE_LIMITED' : 'COHERE_ERROR';\n  console.log(`[${traceId}] Cohere ${reason}: ${cohereErrorMsg || 'No results'}`);\n  \n  // Trier par score RRF dÃ©croissant\n  const sortedByRRF = [...rrfResults].sort((a, b) => (b.rrf_score || 0) - (a.rrf_score || 0));\n  \n  return [{\n    json: {\n      results: sortedByRRF.slice(0, 10).map(r => ({\n        ...r,\n        combined_score: r.rrf_score, // Utiliser RRF comme score final\n        rerank_score: null\n      })),\n      metadata: { \n        ...metadata, \n        reranked: false, \n        cohere_skipped: true,\n        skip_reason: reason,\n        fallback_method: 'RRF_ONLY',\n        error_details: cohereErrorMsg\n      },\n      skip_llm: false\n    }\n  }];\n}\n\n// === CAS 3: Cohere OK - Fusionner les scores ===\nconsole.log(`[${traceId}] Cohere OK: ${cohereResults.length} reranked results`);\n\nconst reranked = cohereResults.map(cr => {\n  const original = rrfResults[cr.index];\n  if (!original) {\n    console.log(`[${traceId}] Warning: Cohere index ${cr.index} not found in RRF results`);\n    return null;\n  }\n  \n  // Score combinÃ©: 40% RRF + 60% Cohere\n  const combinedScore = (original.rrf_score || 0) * 0.4 + cr.relevance_score * 0.6;\n  \n  return { \n    ...original, \n    rerank_score: cr.relevance_score,\n    combined_score: combinedScore\n  };\n}).filter(r => r !== null);\n\n// Trier par score combinÃ©\nreranked.sort((a, b) => b.combined_score - a.combined_score);\n\nreturn [{ \n  json: { \n    results: reranked.slice(0, 10), \n    metadata: { \n      ...metadata, \n      reranked: true,\n      cohere_results_count: cohereResults.length\n    }, \n    skip_llm: false \n  } \n}];"
      },
      "id": "77891d1d-5a1e-410e-8e33-02f26429049c",
      "name": "Rerank Merger",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4272,
        3040
      ],
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{ $vars.OPENROUTER_BASE_URL || 'https://openrouter.ai/api/v1/chat/completions' }}",
        "authentication": "none",
        "nodeCredentialType": "openRouterApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"{{ $vars.LLM_FAST_MODEL || 'meta-llama/llama-3.3-70b-instruct:free' }}\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"Tu es un assistant expert. Reponds de maniere precise et factuelle en citant tes sources entre crochets [1], [2], etc.\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": {{ JSON.stringify('Question: ' + ($node['Init & ACL Pre-Filter V3.4'].json.query || '') + '\\n\\nContexte documentaire:\\n' + (($json.results || []).map((r, i) => '[' + (i+1) + '] ' + (r.source || 'source') + ': ' + (r.content || '')).join('\\n---\\n').substring(0, 6000))) }}\n    }\n  ],\n  \"temperature\": 0.3,\n  \"max_tokens\": 1500\n}",
        "options": {
          "batching": {
            "batch": {
              "batchSize": 1
            }
          },
          "timeout": 30000,
          "retry": {
            "maxTries": 3,
            "waitBetweenTries": 2000
          }
        },
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "=Bearer {{ $vars.OPENROUTER_API_KEY }}"
            }
          ]
        }
      },
      "id": "7dc20347-e74b-433b-84c3-6e41e2f5d041",
      "name": "LLM Generation",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        4560,
        3152
      ],
      "credentials": {},
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "jsCode": "\n// Response Formatter - Standard RAG\n// Fixed: removed undefined 'response' reference\ntry {\n  // Try to get LLM generation output\n  let llmContent = '';\n  try {\n    const llmData = $node['LLM Generation'].json;\n    if (llmData?.choices?.[0]?.message?.content) {\n      llmContent = llmData.choices[0].message.content;\n    }\n  } catch(e) {}\n\n  // Try to get reranked sources\n  let sources = [];\n  try {\n    const reranked = $node['Rerank Merger']?.json;\n    sources = reranked?.reranked_results || reranked?.results || [];\n  } catch(e) {}\n\n  // Try to get init data\n  let initData = {};\n  try {\n    initData = $node['Init & ACL Pre-Filter V3.4'].json;\n  } catch(e) {}\n\n  if (llmContent) {\n    return [{\n      json: {\n        response: llmContent,\n        trace_id: initData.trace_id || 'tr-' + Date.now(),\n        sources: sources.slice(0, 5),\n        model: $vars.LLM_STANDARD_MODEL || 'meta-llama/llama-3.3-70b-instruct:free',\n        embedding_fallback: sources.length === 0,\n        timestamp: new Date().toISOString()\n      }\n    }];\n  }\n\n  // No LLM answer - return fallback\n  return [{\n    json: {\n      response: 'Unable to generate answer - retrieval and LLM both unavailable',\n      trace_id: initData.trace_id || 'tr-' + Date.now(),\n      error: true,\n      embedding_fallback: true,\n      timestamp: new Date().toISOString()\n    }\n  }];\n} catch(e) {\n  return [{\n    json: {\n      response: 'Error in response formatting: ' + e.message,\n      error: true,\n      timestamp: new Date().toISOString()\n    }\n  }];\n}"
      },
      "id": "66bf2956-117a-4408-b218-cf96cb317529",
      "name": "Response Formatter",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4752,
        3040
      ],
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "skip-llm-check",
              "leftValue": "={{ false }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "780215fa-733a-45fd-a706-f6519e6c3146",
      "name": "Skip LLM?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        4416,
        3040
      ],
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "loose",
            "version": 1
          },
          "conditions": [
            {
              "id": "d45424c0-e258-4471-a0f1-ac1588322191",
              "leftValue": "=={{ $json.needs_decomposition }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {
          "looseTypeValidation": "={{ true }}"
        }
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        2896,
        2960
      ],
      "id": "7d4ea704-e270-458a-8e80-71f08f3d99f2",
      "name": "Needs Decomposition?",
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "jsCode": "// Query Merger V3.4 - Prepare queries for retrieval\nconst initData = $node['Init & ACL Pre-Filter V3.4'].json;\nconst needsDecomposition = initData.needs_decomposition;\n\nlet queriesToProcess = [];\n\nif (needsDecomposition) {\n  try {\n    const decomposed = JSON.parse($node['Query Decomposer (V.3.4)'].json?.choices?.[0]?.message?.content || '{}');\n    \n    if (decomposed.is_simple || !decomposed.sub_queries?.length) {\n      queriesToProcess = [initData.query];\n    } else {\n      // Add original + sub-queries for comprehensive retrieval\n      queriesToProcess = [initData.query, ...decomposed.sub_queries.slice(0, 3)];\n    }\n  } catch (e) {\n    queriesToProcess = [initData.query];\n  }\n} else {\n  queriesToProcess = [initData.query];\n}\n\nreturn [{\n  json: {\n    queries: queriesToProcess,\n    primary_query: initData.query,\n    is_decomposed: queriesToProcess.length > 1,\n    topK_per_query: Math.ceil(initData.topK / queriesToProcess.length),\n    trace_id: initData.trace_id,\n    user_context: initData.user_context,\n    acl_filter: initData.acl_filter\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3280,
        3024
      ],
      "id": "93998a6b-1ffd-4aaf-8a5f-2c97369d19e1",
      "name": "Query Merger V3.4",
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "content": "# ðŸ”§ VARIABLES D'ENVIRONNEMENT REQUISES (SOTA 2026)\n\n## LLM APIs\n- `OPENROUTER_BASE_URL` - https://openrouter.ai/api/v1/chat/completions\n- `LLM_HYDE_MODEL` - meta-llama/llama-3.3-70b-instruct:free\n- `LLM_FAST_MODEL` - meta-llama/llama-3.3-70b-instruct:free\n\n## Embedding\n- `EMBEDDING_API_URL` - URL embedding API\n- `EMBEDDING_MODEL` - text-embedding-3-small\n\n## Reranking\n- `RERANKER_API_URL` - https://api.cohere.ai/v1/rerank\n- `RERANKER_MODEL` - rerank-v3.5 (upgraded from rerank-multilingual-v3.0)\n\n## CORRECTIONS V3.4.1:\n- Fixed HyDE Generator JSON body (removed orphan JS code)\n- Fixed Embedding model string (removed extra quotes)\n- Fixed Query Decomposer model reference\n\n## ISSUE-SR-04 (P1) - PENDING ARCHITECTURE CHANGE:\n- An IF node must be added BEFORE the Cohere Reranker node\n- Condition: skip_reranker === true â†’ bypass Cohere entirely\n- Currently when skip_reranker=true, a placeholder document is sent to Cohere\n- This wastes API credits and may produce misleading rerank scores\n- Route: RRF â†’ [new IF: Has Results?] â†’ true: Cohere â†’ Rerank Merger\n-                                      â†’ false: Rerank Merger (directly)\n- STATUS: Requires manual structural change (add node + rewire connections)\n",
        "height": 500,
        "width": 400
      },
      "id": "5015f29c-6e31-4ddb-ae5f-51b766132726",
      "name": "ðŸ“‹ Configuration SOTA 2026",
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        2240,
        1552
      ]
    },
    {
      "parameters": {
        "public": true,
        "availableInChat": true,
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "typeVersion": 1.4,
      "position": [
        2496,
        2560
      ],
      "id": "64766023-f697-4f4b-ab8c-5a26dd166d76",
      "name": "When chat message received",
      "webhookId": "7c483bf3-3e68-4ac1-8812-eda6b2c28a5a"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{ $vars.OPENROUTER_BASE_URL || 'https://openrouter.ai/api/v1/chat/completions' }}",
        "authentication": "none",
        "nodeCredentialType": "openRouterApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"{{ $vars.LLM_FAST_MODEL || 'meta-llama/llama-3.3-70b-instruct:free' }}\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"Tu es un expert en decomposition de questions. Analyse la question et decompose-la en sous-questions independantes si necessaire.\\n\\nREGLES:\\n1. Si la question est simple et directe, retourne is_simple: true\\n2. Si la question contient plusieurs aspects, decompose en 2-4 sous-questions\\n3. Chaque sous-question doit etre auto-suffisante\\n4. Ordonne par dependance logique\\n\\nFormat JSON strict:\\n{\\n  \\\"is_simple\\\": boolean,\\n  \\\"original_query\\\": \\\"..\\\",\\n  \\\"sub_queries\\\": [\\\"q1\\\", \\\"q2\\\", ...],\\n  \\\"reasoning\\\": \\\"Pourquoi cette decomposition\\\"\\n}\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": {{ JSON.stringify($node['Init & ACL Pre-Filter V3.4'].json.query || '') }}\n    }\n  ],\n  \"temperature\": 0.1,\n  \"max_tokens\": 500\n}",
        "options": {
          "batching": {
            "batch": {
              "batchSize": 1
            }
          },
          "timeout": 20000,
          "retry": {
            "maxTries": 3,
            "waitBetweenTries": 2000
          }
        },
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "=Bearer {{ $vars.OPENROUTER_API_KEY }}"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        2736,
        3504
      ],
      "id": "92c737a5-8497-4242-894f-07966ccc6a13",
      "name": "Query Decomposer (V.3.4)",
      "credentials": {},
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "jsCode": "// GitHub Error Logger for standard\nconst errorData = $input.first().json;\nconst timestamp = new Date().toISOString();\nconst questionId = errorData.question_id || errorData.trace_id || 'q-' + Date.now();\nconst errorType = errorData.error_type || errorData.error_code || 'UNKNOWN';\nconst pipeline = 'standard';\n\nconst logEntry = {\n  timestamp: timestamp,\n  pipeline: pipeline,\n  question_id: questionId,\n  error_type: errorType,\n  error_message: (errorData.error || errorData.message || 'No message').slice(0, 500),\n  input: {\n    query: (errorData.query || errorData.original_query || '').slice(0, 300),\n    tenant_id: errorData.tenant_id || 'benchmark'\n  },\n  partial_response: errorData.partial_response || errorData.response || null,\n  n8n_context: {\n    workflow_id: $workflow.id,\n    workflow_name: $workflow.name,\n    execution_id: $execution.id\n  },\n  performance: {\n    latency_ms: errorData.latency_ms || 0,\n    http_status: errorData.http_status || null\n  }\n};\n\nreturn [{ json: logEntry }];"
      },
      "id": "ae5ed52c-d7db-4463-a80d-374c0f35163f",
      "name": "GitHub Error Logger (standard)",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        5052,
        0
      ],
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "jsCode": "// Execution Summary Logger for standard\nconst input = $input.first().json;\nconst timestamp = new Date().toISOString();\n\nconst summary = {\n  timestamp: timestamp,\n  pipeline: 'standard',\n  question_id: input.trace_id || input.question_id || 'q-' + Date.now(),\n  query: (input.query || input.original_query || '').slice(0, 300),\n  success: !!(input.response || input.final_response || input.answer),\n  response_length: (input.response || input.final_response || input.answer || '').length,\n  confidence: input.confidence || 0,\n  latency_ms: input.latency_ms || 0,\n  engine: input.engine || input.selected_engine || 'standard',\n  n8n_context: {\n    workflow_id: $workflow.id,\n    execution_id: $execution.id\n  }\n};\n\nreturn [{ json: summary }];"
      },
      "id": "39e4ddaa-1665-429f-805c-5945d1beca40",
      "name": "Execution Summary (standard)",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        5052,
        200
      ],
      "onError": "continueRegularOutput"
    }
  ],
  "connections": {
    "Sub-Workflow Trigger": {
      "main": [
        [
          {
            "node": "Init & ACL Pre-Filter V3.4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Webhook": {
      "main": [
        [
          {
            "node": "Init & ACL Pre-Filter V3.4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Init & ACL Pre-Filter V3.4": {
      "main": [
        [
          {
            "node": "Needs Decomposition?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HyDE Generator": {
      "main": [
        [
          {
            "node": "HyDE Embedding",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HyDE Embedding": {
      "main": [
        [
          {
            "node": "HTTP Pinecone Query HyDE",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HTTP Pinecone Query HyDE": {
      "main": [
        [
          {
            "node": "Wait All Branches",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Original Embedding": {
      "main": [
        [
          {
            "node": "HTTP Pinecone Query Original",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HTTP Pinecone Query Original": {
      "main": [
        [
          {
            "node": "Wait All Branches",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Wait All Branches": {
      "main": [
        [
          {
            "node": "RRF Merge & Rank V3.4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "RRF Merge & Rank V3.4": {
      "main": [
        [
          {
            "node": "Cohere Reranker",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Cohere Reranker": {
      "main": [
        [
          {
            "node": "Rerank Merger",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Rerank Merger",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Rerank Merger": {
      "main": [
        [
          {
            "node": "Skip LLM?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "LLM Generation": {
      "main": [
        [
          {
            "node": "Response Formatter",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Skip LLM?": {
      "main": [
        [
          {
            "node": "Response Formatter",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "LLM Generation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Needs Decomposition?": {
      "main": [
        [
          {
            "node": "Query Decomposer (V.3.4)",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "HyDE Generator",
            "type": "main",
            "index": 0
          },
          {
            "node": "Original Embedding",
            "type": "main",
            "index": 0
          },
          {
            "node": "BM25 Search Postgres",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Query Merger V3.4": {
      "main": [
        [
          {
            "node": "HyDE Generator",
            "type": "main",
            "index": 0
          },
          {
            "node": "Original Embedding",
            "type": "main",
            "index": 0
          },
          {
            "node": "BM25 Search Postgres",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "When chat message received": {
      "main": [
        [
          {
            "node": "Init & ACL Pre-Filter V3.4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Query Decomposer (V.3.4)": {
      "main": [
        [
          {
            "node": "Query Merger V3.4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "BM25 Search Postgres": {
      "main": [
        [
          {
            "node": "Wait All Branches",
            "type": "main",
            "index": 1
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1",
    "availableInMCP": false,
    "timeSavedMode": "fixed",
    "callerPolicy": "workflowsFromSameOwner",
    "executionTimeout": 90
  },
  "staticData": null,
  "meta": {
    "templateCredsSetupCompleted": true
  },
  "pinData": {},
  "versionId": "7d5ff7e8-d1de-47b0-8b5e-27e2a76acc1e",
  "activeVersionId": "7d5ff7e8-d1de-47b0-8b5e-27e2a76acc1e",
  "versionCounter": 124,
  "triggerCount": 2,
  "shared": [
    {
      "updatedAt": "2026-01-30T16:51:51.532Z",
      "createdAt": "2026-01-30T16:51:51.532Z",
      "role": "workflow:owner",
      "workflowId": "LnTqRX4LZlI009Ks-3Jnp",
      "projectId": "JV7MbqBbWPTstXIo",
      "project": {
        "updatedAt": "2026-01-07T13:20:26.996Z",
        "createdAt": "2026-01-07T13:20:21.870Z",
        "id": "JV7MbqBbWPTstXIo",
        "name": "Alexis Moret <alexis.moret6@outlook.fr>",
        "type": "personal",
        "icon": null,
        "description": null,
        "creatorId": "215767e0-958a-4c74-a67a-e335807eba64",
        "projectRelations": [
          {
            "updatedAt": "2026-01-07T13:20:21.870Z",
            "createdAt": "2026-01-07T13:20:21.870Z",
            "userId": "215767e0-958a-4c74-a67a-e335807eba64",
            "projectId": "JV7MbqBbWPTstXIo",
            "user": {
              "updatedAt": "2026-02-08T23:36:29.000Z",
              "createdAt": "2026-01-07T13:20:20.003Z",
              "id": "215767e0-958a-4c74-a67a-e335807eba64",
              "email": "alexis.moret6@outlook.fr",
              "firstName": "Alexis",
              "lastName": "Moret",
              "personalizationAnswers": null,
              "settings": {
                "userActivated": true,
                "userClaimedAiCredits": true,
                "easyAIWorkflowOnboarded": true,
                "firstSuccessfulWorkflowId": "e3_89vptJG7PPA-OHyAg3",
                "userActivatedAt": 1767837780144,
                "npsSurvey": {
                  "responded": true,
                  "lastShownAt": 1768407850905
                }
              },
              "disabled": false,
              "mfaEnabled": false,
              "lastActiveAt": "2026-02-08",
              "isPending": false
            }
          }
        ]
      }
    }
  ],
  "tags": [],
  "activeVersion": {
    "updatedAt": "2026-02-09T03:43:44.993Z",
    "createdAt": "2026-02-09T03:43:44.993Z",
    "versionId": "7d5ff7e8-d1de-47b0-8b5e-27e2a76acc1e",
    "workflowId": "LnTqRX4LZlI009Ks-3Jnp",
    "nodes": [
      {
        "parameters": {},
        "id": "d7dec400-09bd-4f08-8c55-cc966bfe142a",
        "name": "Sub-Workflow Trigger",
        "type": "n8n-nodes-base.executeWorkflowTrigger",
        "typeVersion": 1,
        "position": [
          2464,
          2816
        ]
      },
      {
        "parameters": {
          "httpMethod": "POST",
          "path": "rag-multi-index-v3",
          "responseMode": "lastNode",
          "options": {}
        },
        "type": "n8n-nodes-base.webhook",
        "typeVersion": 2.1,
        "position": [
          2464,
          3152
        ],
        "id": "9839607f-defe-49f1-95f8-790a491557dc",
        "name": "Webhook",
        "webhookId": "rag-multi-index-v3"
      },
      {
        "parameters": {
          "jsCode": "// Init & ACL Pre-Filter V3.4 - With Adaptive TopK\nconst rawInput = $input.first().json;\nconst input = rawInput.body || rawInput;\n\n// Parse query robustement\nlet queryStr = '';\nif (typeof input.query === 'string') {\n  queryStr = input.query;\n} else if (input.query && typeof input.query === 'object') {\n  queryStr = JSON.stringify(input.query);\n} else {\n  queryStr = String(input.query || '');\n}\n\nconst userContext = input.user_context || {};\nconst tenantId = userContext.tenant_id || input.tenant_id || 'default';\nconst userGroups = Array.isArray(userContext.groups) ? userContext.groups : ['admin', 'guest'];\n\n// V3.4: Analyse de complexitÃ© pour adaptive top_k\nconst COMPLEXITY_INDICATORS = {\n  simple: /^(qu'est-ce que|dÃ©finition|c'est quoi)/i,\n  moderate: /(comment|pourquoi|expliquer)/i,\n  complex: /(comparer|analyser|impact|relation|entre.*et)/i,\n  multi_hop: /(quel.*puis|d'abord.*ensuite|en tenant compte)/i\n};\n\nlet complexity = 'moderate';\nlet adaptiveTopK = 15;\n\nif (COMPLEXITY_INDICATORS.simple.test(queryStr)) {\n  complexity = 'simple';\n  adaptiveTopK = 8;\n} else if (COMPLEXITY_INDICATORS.multi_hop.test(queryStr)) {\n  complexity = 'complex';\n  adaptiveTopK = 25;\n} else if (COMPLEXITY_INDICATORS.complex.test(queryStr)) {\n  complexity = 'complex';\n  adaptiveTopK = 20;\n}\n\n// V3.4: Detect if query needs decomposition\nconst needsDecomposition = queryStr.length > 100 || \n                          queryStr.includes(' et ') ||\n                          queryStr.includes(' ainsi que ') ||\n                          COMPLEXITY_INDICATORS.complex.test(queryStr);\n\n// ACL filter (dÃ©sactivÃ© par dÃ©faut pour compatibilitÃ©)\nconst disableAcl = (input.disable_acl === true);\nconst aclFilter = disableAcl ? {} : {\n  \"$or\": [\n    { \"tenant_id\": tenantId, \"allowed_groups\": { \"$in\": userGroups } },\n    { \"tenant_id\": { \"$exists\": false } }\n  ]\n};\n\nreturn [{\n  json: {\n    trace_id: input.trace_id || 'tr-' + Date.now(),\n    query: queryStr.trim(),\n    acl_filter: aclFilter,\n    acl_disabled: disableAcl,\n    user_context: { tenant_id: tenantId, groups: userGroups },\n    \n    // V3.4 Enhancements\n    complexity: complexity,\n    topK: Math.min(input.topK || adaptiveTopK, 50),\n    adaptive_topK: adaptiveTopK,\n    needs_decomposition: needsDecomposition\n  }\n}];"
        },
        "id": "9e9a1c50-0934-43a7-9185-5616ab227650",
        "name": "Init & ACL Pre-Filter V3.4",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          2704,
          2960
        ],
        "onError": "continueRegularOutput"
      },
      {
        "parameters": {
          "method": "POST",
          "url": "={{ $vars.OPENROUTER_BASE_URL || 'https://openrouter.ai/api/v1/chat/completions' }}",
          "authentication": "none",
          "nodeCredentialType": "openRouterApi",
          "sendBody": true,
          "specifyBody": "json",
          "jsonBody": "={\n  \"model\": \"{{ $vars.LLM_HYDE_MODEL || 'meta-llama/llama-3.3-70b-instruct:free' }}\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"Genere un document hypothetique de 150-200 mots qui repondrait parfaitement a la question.\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": {{ JSON.stringify($node['Init & ACL Pre-Filter V3.4'].json.query || '') }}\n    }\n  ],\n  \"temperature\": 0.7,\n  \"max_tokens\": 400\n}",
          "options": {
            "batching": {
              "batch": {
                "batchSize": 1
              }
            },
            "timeout": 20000,
            "retry": {
              "maxTries": 3,
              "waitBetweenTries": 2000
            }
          },
          "sendHeaders": true,
          "headerParameters": {
            "parameters": [
              {
                "name": "Authorization",
                "value": "=Bearer {{ $vars.OPENROUTER_API_KEY }}"
              }
            ]
          }
        },
        "id": "2203b6fc-10ed-43f1-8814-134887ef30b3",
        "name": "HyDE Generator",
        "type": "n8n-nodes-base.httpRequest",
        "typeVersion": 4.3,
        "position": [
          3520,
          2480
        ],
        "credentials": {},
        "onError": "continueRegularOutput"
      },
      {
        "parameters": {
          "method": "POST",
          "url": "={{ $vars.EMBEDDING_API_URL || 'https://openrouter.ai/api/v1/embeddings' }}",
          "authentication": "none",
          "nodeCredentialType": "openRouterApi",
          "sendBody": true,
          "specifyBody": "json",
          "jsonBody": "={\n  \"model\": \"{{ $vars.EMBEDDING_MODEL || 'text-embedding-3-small' }}\",\n  \"input\": {{ JSON.stringify($node['HyDE Generator'].json.choices?.[0]?.message?.content || $node['Init & ACL Pre-Filter V3.4'].json.query || '') }}\n}",
          "options": {
            "batching": {
              "batch": {
                "batchSize": 1
              }
            },
            "timeout": 10000,
            "retry": {
              "maxTries": 3,
              "waitBetweenTries": 2000
            }
          },
          "sendHeaders": true,
          "headerParameters": {
            "parameters": [
              {
                "name": "Authorization",
                "value": "=Bearer {{ $vars.OPENROUTER_API_KEY }}"
              }
            ]
          }
        },
        "id": "89633b5e-e055-4431-a38b-2963e872fba3",
        "name": "HyDE Embedding",
        "type": "n8n-nodes-base.httpRequest",
        "typeVersion": 4.3,
        "position": [
          3728,
          2480
        ],
        "credentials": {},
        "onError": "continueRegularOutput"
      },
      {
        "parameters": {
          "method": "POST",
          "url": "={{ $vars.PINECONE_URL }}/query",
          "authentication": "genericCredentialType",
          "genericAuthType": "httpHeaderAuth",
          "sendBody": true,
          "specifyBody": "json",
          "jsonBody": "={\n  \"vector\": {{ JSON.stringify($node['HyDE Embedding'].json.data?.[0]?.embedding || []) }},\n  \"topK\": {{ $node['Init & ACL Pre-Filter V3.4'].json.topK || 20 }},\n  \"includeMetadata\": true\n}",
          "options": {
            "batching": {
              "batch": {
                "batchSize": 1
              }
            },
            "timeout": 15000
          }
        },
        "id": "89900633-eadc-4623-8317-34bd140d3019",
        "name": "HTTP Pinecone Query HyDE",
        "type": "n8n-nodes-base.httpRequest",
        "typeVersion": 4.3,
        "position": [
          3936,
          2480
        ],
        "credentials": {
          "httpHeaderAuth": {
            "id": "3DEiHDwB09D65919",
            "name": "Pinecone API Key"
          }
        },
        "onError": "continueRegularOutput"
      },
      {
        "parameters": {
          "method": "POST",
          "url": "={{ $vars.EMBEDDING_API_URL || 'https://openrouter.ai/api/v1/embeddings' }}",
          "authentication": "none",
          "nodeCredentialType": "openRouterApi",
          "sendBody": true,
          "specifyBody": "json",
          "jsonBody": "={\n  \"model\": \"{{ $vars.EMBEDDING_MODEL || 'text-embedding-3-small' }}\",\n  \"input\": {{ JSON.stringify($node['Init & ACL Pre-Filter V3.4'].json.query || '') }}\n}",
          "options": {
            "batching": {
              "batch": {
                "batchSize": 1
              }
            },
            "timeout": 10000,
            "retry": {
              "maxTries": 3,
              "waitBetweenTries": 2000
            }
          },
          "sendHeaders": true,
          "headerParameters": {
            "parameters": [
              {
                "name": "Authorization",
                "value": "=Bearer {{ $vars.OPENROUTER_API_KEY }}"
              }
            ]
          }
        },
        "id": "845805cf-5935-4b94-b320-7cf6042c94e9",
        "name": "Original Embedding",
        "type": "n8n-nodes-base.httpRequest",
        "typeVersion": 4.3,
        "position": [
          3152,
          3424
        ],
        "credentials": {},
        "onError": "continueRegularOutput"
      },
      {
        "parameters": {
          "method": "POST",
          "url": "={{ $vars.PINECONE_URL }}/query",
          "authentication": "genericCredentialType",
          "genericAuthType": "httpHeaderAuth",
          "sendBody": true,
          "specifyBody": "json",
          "jsonBody": "={\n  \"vector\": {{ JSON.stringify($node['Original Embedding'].json.data?.[0]?.embedding || []) }},\n  \"topK\": {{ $node['Init & ACL Pre-Filter V3.4'].json.topK || 20 }},\n  \"includeMetadata\": true\n}",
          "options": {
            "batching": {
              "batch": {
                "batchSize": 1
              }
            },
            "timeout": 15000
          }
        },
        "id": "cd9fa21b-05c1-4b06-8b9d-63aabae79a91",
        "name": "HTTP Pinecone Query Original",
        "type": "n8n-nodes-base.httpRequest",
        "typeVersion": 4.3,
        "position": [
          3392,
          3440
        ],
        "credentials": {
          "httpHeaderAuth": {
            "id": "3DEiHDwB09D65919",
            "name": "Pinecone API Key"
          }
        },
        "onError": "continueRegularOutput"
      },
      {
        "parameters": {
          "operation": "executeQuery",
          "query": "SELECT id, content, source, \n       ts_rank(to_tsvector('french', content), plainto_tsquery('french', $1)) as bm25_score\nFROM documents \nWHERE is_obsolete = false \n  AND tenant_id = $2\n  AND to_tsvector('french', content) @@ plainto_tsquery('french', $1)\nORDER BY bm25_score DESC LIMIT 20",
          "options": {
            "queryReplacement": "=={{ $node['Init & ACL Pre-Filter V3.4'].json.query }},{{ $node['Init & ACL Pre-Filter V3.4'].json.user_context.tenant_id }}"
          }
        },
        "id": "935d1864-4a23-4add-8697-621cb9880b38",
        "name": "BM25 Search Postgres",
        "type": "n8n-nodes-base.postgres",
        "typeVersion": 2.4,
        "position": [
          3696,
          3344
        ],
        "credentials": {
          "postgres": {
            "id": "zEr7jPswZNv6lWKu",
            "name": "Supabase PostgreSQL"
          }
        },
        "onError": "continueRegularOutput"
      },
      {
        "parameters": {
          "mode": "combine",
          "combineBy": "combineAll",
          "options": {}
        },
        "id": "a7b5a315-c936-473e-b030-8547a516ef3f",
        "name": "Wait All Branches",
        "type": "n8n-nodes-base.merge",
        "typeVersion": 3.1,
        "position": [
          3696,
          3040
        ],
        "onError": "continueRegularOutput"
      },
      {
        "parameters": {
          "jsCode": "// ============================================\n// PATCH 07 - RRF Merge & Rank V3.4.2\n// FIX: Lecture robuste des 3 sources (HyDE, Original, BM25)\n// ============================================\n//\n// PROBLÃˆME RÃ‰SOLU:\n// Le code prÃ©cÃ©dent Ã©chouait silencieusement sur BM25\n// car le nÅ“ud Merge ne passait pas les donnÃ©es correctement.\n//\n// SOLUTION:\n// Lire directement depuis chaque nÅ“ud source au lieu\n// de dÃ©pendre du Merge node.\n//\n// INSTRUCTIONS:\n// 1. Ouvrir le nÅ“ud \"RRF Merge & Rank V3.4\" dans le workflow RAG Standard\n// 2. Remplacer tout le code par celui-ci\n// 3. Sauvegarder\n// ============================================\n\n// RRF Merge & Rank V3.4.2 - Direct source reading\nconst k = 60; // ParamÃ¨tre RRF standard\nconst BOOSTS = { hyde: 1.5, bm25: 1.2, pinecone: 1.0 };\nlet scores = {};\nlet warnings = [];\nlet sourcesAvailable = 0;\n\n// RÃ©cupÃ©rer les mÃ©tadonnÃ©es\nconst initData = $node['Init & ACL Pre-Filter V3.4'].json;\nconst traceId = initData.trace_id;\n\n// V3.4: Check if queries were decomposed\nlet isDecomposed = false;\ntry {\n  const queryData = $node['Query Merger V3.4']?.json;\n  isDecomposed = queryData?.is_decomposed || false;\n} catch (e) {\n  // Query Merger pas dans le flux\n}\nconst decompositionBoost = isDecomposed ? 1.1 : 1.0;\n\n// === HELPER FUNCTIONS ===\nfunction extractContent(metadata) {\n  return metadata?.text || metadata?.content || metadata?.chunk_text || metadata?.page_content || '';\n}\n\nfunction safeReadNode(nodeName) {\n  try {\n    return $node[nodeName]?.json;\n  } catch (e) {\n    console.log(`[${traceId}] Cannot read ${nodeName}: ${e.message}`);\n    return null;\n  }\n}\n\n// === SOURCE 1: HyDE Pinecone ===\nconsole.log(`[${traceId}] Reading HyDE results...`);\ntry {\n  const hydeData = safeReadNode('HTTP Pinecone Query HyDE');\n  const hydeMatches = hydeData?.matches || [];\n  \n  if (hydeMatches.length > 0) {\n    sourcesAvailable++;\n    hydeMatches.forEach((item, index) => {\n      const id = item.id;\n      const rrfScore = (1 / (k + index + 1)) * BOOSTS.hyde * decompositionBoost;\n      \n      if (scores[id]) { \n        scores[id].score += rrfScore; \n        if (!scores[id].sources.includes('hyde')) {\n          scores[id].sources.push('hyde');\n        }\n      } else { \n        scores[id] = { \n          score: rrfScore, \n          data: item.metadata, \n          pineconeScore: item.score, \n          sources: ['hyde'] \n        }; \n      }\n    });\n    console.log(`[${traceId}] HyDE: ${hydeMatches.length} results added`);\n  } else { \n    warnings.push('HyDE: 0 results'); \n  }\n} catch(e) { \n  warnings.push('HyDE error: ' + e.message);\n  console.error(`[${traceId}] HyDE error:`, e.message);\n}\n\n// === SOURCE 2: Original Pinecone ===\nconsole.log(`[${traceId}] Reading Original Embedding results...`);\ntry {\n  const originalData = safeReadNode('HTTP Pinecone Query Original');\n  const originalMatches = originalData?.matches || [];\n  \n  if (originalMatches.length > 0) {\n    sourcesAvailable++;\n    originalMatches.forEach((item, index) => {\n      const id = item.id;\n      const rrfScore = (1 / (k + index + 1)) * BOOSTS.pinecone;\n      \n      if (scores[id]) { \n        scores[id].score += rrfScore; \n        if (!scores[id].sources.includes('original')) {\n          scores[id].sources.push('original'); \n        }\n      } else { \n        scores[id] = { \n          score: rrfScore, \n          data: item.metadata, \n          pineconeScore: item.score, \n          sources: ['original'] \n        }; \n      }\n    });\n    console.log(`[${traceId}] Original: ${originalMatches.length} results added`);\n  } else { \n    warnings.push('Original: 0 results'); \n  }\n} catch(e) { \n  warnings.push('Original error: ' + e.message);\n  console.error(`[${traceId}] Original error:`, e.message);\n}\n\n// === SOURCE 3: BM25 Postgres ===\nconsole.log(`[${traceId}] Reading BM25 results...`);\ntry {\n  const bm25Raw = safeReadNode('BM25 Search Postgres');\n  \n  // BM25 peut retourner diffÃ©rents formats:\n  // - Array de rÃ©sultats\n  // - Objet unique avec {id, content, bm25_score}\n  // - Null/undefined si erreur\n  \n  let bm25Data = [];\n  \n  if (Array.isArray(bm25Raw)) {\n    bm25Data = bm25Raw;\n  } else if (bm25Raw && typeof bm25Raw === 'object') {\n    if (bm25Raw.id) {\n      // Single result object\n      bm25Data = [bm25Raw];\n    } else if (bm25Raw.error) {\n      // Postgres error\n      throw new Error(bm25Raw.error.message || 'Postgres error');\n    }\n  }\n  \n  // Filtrer les rÃ©sultats valides\n  bm25Data = bm25Data.filter(item => item && item.id && item.content);\n  \n  if (bm25Data.length > 0) {\n    sourcesAvailable++;\n    bm25Data.forEach((item, index) => {\n      const id = 'bm25-' + String(item.id);\n      const rrfScore = (1 / (k + index + 1)) * BOOSTS.bm25;\n      \n      if (scores[id]) { \n        scores[id].score += rrfScore; \n        scores[id].sources.push('bm25'); \n      } else { \n        scores[id] = { \n          score: rrfScore, \n          data: { \n            content: item.content, \n            source: item.source || 'postgres', \n            text: item.content \n          }, \n          bm25Score: item.bm25_score, \n          sources: ['bm25'] \n        }; \n      }\n    });\n    console.log(`[${traceId}] BM25: ${bm25Data.length} results added`);\n  } else { \n    warnings.push('BM25: 0 results (may need tenant_id configuration)'); \n  }\n} catch(e) { \n  warnings.push('BM25 error: ' + e.message);\n  console.error(`[${traceId}] BM25 error:`, e.message);\n}\n\n// === RANKING FINAL ===\n// R03 SOTA 2026: Min-max normalization of RRF scores before final ranking\nconst allEntries = Object.entries(scores)\n  .map(([id, r]) => ({ id, ...r }));\n\nif (allEntries.length > 1) {\n  const rawScores = allEntries.map(e => e.score);\n  const minScore = Math.min(...rawScores);\n  const maxScore = Math.max(...rawScores);\n  const range = maxScore - minScore;\n  if (range > 0) {\n    allEntries.forEach(e => {\n      e.raw_rrf_score = e.score;\n      e.score = (e.score - minScore) / range;\n    });\n    console.log(`[${traceId}] RRF normalization applied: min=${minScore.toFixed(6)}, max=${maxScore.toFixed(6)}`);\n  }\n}\n\nconst ranked = allEntries.sort((a, b) => b.score - a.score);\n\nconst hasResults = ranked.length > 0;\n\nconsole.log(`[${traceId}] RRF complete: ${ranked.length} unique docs from ${sourcesAvailable} sources`);\nif (warnings.length > 0) {\n  console.log(`[${traceId}] Warnings: ${warnings.join(', ')}`);\n}\n\n// === OUTPUT ===\nreturn [{\n  json: {\n    results: ranked.slice(0, 15).map(r => ({\n      id: r.id,\n      content: extractContent(r.data),\n      source: r.data?.source || r.data?.dataset || 'unknown',\n      rrf_score: Math.round(r.score * 10000) / 10000,\n      raw_rrf_score: r.raw_rrf_score ? Math.round(r.raw_rrf_score * 10000) / 10000 : undefined,\n      pinecone_score: r.pineconeScore,\n      bm25_score: r.bm25Score,\n      sources_used: r.sources\n    })),\n    metadata: { \n      sources_available: sourcesAvailable,\n      total_unique_docs: ranked.length,\n      warnings: warnings,\n      is_decomposed: isDecomposed,\n      rrf_normalized: true,\n      version: '3.4.3',\n      trace_id: traceId\n    },\n    skip_reranker: !hasResults\n  }\n}];"
        },
        "id": "fc784fa1-20eb-4687-abb8-e260880099d4",
        "name": "RRF Merge & Rank V3.4",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          3888,
          3040
        ],
        "onError": "continueRegularOutput"
      },
      {
        "parameters": {
          "method": "POST",
          "url": "={{ $vars.RERANKER_API_URL || 'https://api.cohere.ai/v1/rerank' }}",
          "authentication": "genericCredentialType",
          "genericAuthType": "httpHeaderAuth",
          "sendBody": true,
          "specifyBody": "json",
          "jsonBody": "={\n  \"model\": \"{{ $vars.RERANKER_MODEL || 'rerank-v3.5' }}\",\n  \"query\": {{ JSON.stringify($node['Init & ACL Pre-Filter V3.4'].json.query || '') }},\n  \"documents\": {{ $json.skip_reranker ? '[\"placeholder\"]' : JSON.stringify(($json.results || []).map(r => r.content || '').filter(c => c.length > 0).slice(0, 25)) }},\n  \"top_n\": 10\n}",
          "options": {
            "batching": {
              "batch": {
                "batchSize": 1
              }
            },
            "timeout": 15000
          }
        },
        "id": "dd352491-9109-477d-8c93-d8b4576d238d",
        "name": "Cohere Reranker",
        "type": "n8n-nodes-base.httpRequest",
        "typeVersion": 4.3,
        "position": [
          4080,
          3040
        ],
        "credentials": {
          "httpHeaderAuth": {
            "id": "7UPUQvFQVksMajPL",
            "name": "Cohere API Key"
          }
        },
        "onError": "continueRegularOutput"
      },
      {
        "parameters": {
          "jsCode": "// ============================================\n// PATCH 02-FIX - Rerank Merger V3.4.2\n// FIX: Gestion correcte du type d'erreur Cohere\n// ============================================\n// \n// PROBLÃˆME CORRIGÃ‰:\n// L'erreur \"cohereError.includes is not a function\" se produit\n// car cohereError est un OBJET (avec .message), pas une string.\n//\n// INSTRUCTIONS:\n// 1. Ouvrir le nÅ“ud \"Rerank Merger\" dans le workflow RAG Standard\n// 2. Remplacer tout le code par celui-ci\n// 3. Sauvegarder\n// ============================================\n\nconst rrfResults = $node['RRF Merge & Rank V3.4'].json.results || [];\nconst initData = $node['Init & ACL Pre-Filter V3.4'].json;\nconst metadata = $node['RRF Merge & Rank V3.4'].json.metadata || {};\nconst skipReranker = $node['RRF Merge & Rank V3.4'].json.skip_reranker;\nconst traceId = initData.trace_id;\n\n// === CAS 1: Aucun rÃ©sultat RRF ===\nif (rrfResults.length === 0 || skipReranker) {\n  console.log(`[${traceId}] No RRF results or skip_reranker - returning empty`);\n  return [{\n    json: {\n      results: [],\n      metadata: { ...metadata, reranked: false, empty_database: true },\n      skip_llm: false,\n      fallback_response: {\n        response: \"Je n'ai trouvÃ© aucun document pertinent dans la base de connaissances.\",\n        sources: [],\n        confidence: 0,\n        trace_id: traceId,\n        warning: \"NO_DOCUMENTS_FOUND\"\n      }\n    }\n  }];\n}\n\n// === CAS 2: Analyser la rÃ©ponse Cohere ===\nconst cohereResponse = $json;\nconst cohereResults = cohereResponse.results || [];\n\n// L'erreur peut Ãªtre un objet ou une string - extraire le message\nconst cohereErrorObj = cohereResponse.error;\nlet cohereErrorMsg = '';\nif (cohereErrorObj) {\n  if (typeof cohereErrorObj === 'string') {\n    cohereErrorMsg = cohereErrorObj;\n  } else if (typeof cohereErrorObj === 'object') {\n    cohereErrorMsg = cohereErrorObj.message || JSON.stringify(cohereErrorObj);\n  }\n}\n\nconst httpStatus = cohereResponse.statusCode || cohereResponse.status || cohereErrorObj?.status;\n\n// DÃ©tecter rate limit (429) ou autres erreurs\nconst isRateLimited = httpStatus === 429 || \n                      cohereErrorMsg.includes('429') ||\n                      cohereErrorMsg.toLowerCase().includes('rate');\nconst hasError = cohereErrorObj || cohereResults.length === 0;\n\nif (hasError) {\n  // === FALLBACK: Utiliser les scores RRF sans reranking ===\n  const reason = isRateLimited ? 'COHERE_RATE_LIMITED' : 'COHERE_ERROR';\n  console.log(`[${traceId}] Cohere ${reason}: ${cohereErrorMsg || 'No results'}`);\n  \n  // Trier par score RRF dÃ©croissant\n  const sortedByRRF = [...rrfResults].sort((a, b) => (b.rrf_score || 0) - (a.rrf_score || 0));\n  \n  return [{\n    json: {\n      results: sortedByRRF.slice(0, 10).map(r => ({\n        ...r,\n        combined_score: r.rrf_score, // Utiliser RRF comme score final\n        rerank_score: null\n      })),\n      metadata: { \n        ...metadata, \n        reranked: false, \n        cohere_skipped: true,\n        skip_reason: reason,\n        fallback_method: 'RRF_ONLY',\n        error_details: cohereErrorMsg\n      },\n      skip_llm: false\n    }\n  }];\n}\n\n// === CAS 3: Cohere OK - Fusionner les scores ===\nconsole.log(`[${traceId}] Cohere OK: ${cohereResults.length} reranked results`);\n\nconst reranked = cohereResults.map(cr => {\n  const original = rrfResults[cr.index];\n  if (!original) {\n    console.log(`[${traceId}] Warning: Cohere index ${cr.index} not found in RRF results`);\n    return null;\n  }\n  \n  // Score combinÃ©: 40% RRF + 60% Cohere\n  const combinedScore = (original.rrf_score || 0) * 0.4 + cr.relevance_score * 0.6;\n  \n  return { \n    ...original, \n    rerank_score: cr.relevance_score,\n    combined_score: combinedScore\n  };\n}).filter(r => r !== null);\n\n// Trier par score combinÃ©\nreranked.sort((a, b) => b.combined_score - a.combined_score);\n\nreturn [{ \n  json: { \n    results: reranked.slice(0, 10), \n    metadata: { \n      ...metadata, \n      reranked: true,\n      cohere_results_count: cohereResults.length\n    }, \n    skip_llm: false \n  } \n}];"
        },
        "id": "77891d1d-5a1e-410e-8e33-02f26429049c",
        "name": "Rerank Merger",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          4272,
          3040
        ],
        "onError": "continueRegularOutput"
      },
      {
        "parameters": {
          "method": "POST",
          "url": "={{ $vars.OPENROUTER_BASE_URL || 'https://openrouter.ai/api/v1/chat/completions' }}",
          "authentication": "none",
          "nodeCredentialType": "openRouterApi",
          "sendBody": true,
          "specifyBody": "json",
          "jsonBody": "={\n  \"model\": \"{{ $vars.LLM_FAST_MODEL || 'meta-llama/llama-3.3-70b-instruct:free' }}\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"Tu es un assistant expert. Reponds de maniere precise et factuelle en citant tes sources entre crochets [1], [2], etc.\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": {{ JSON.stringify('Question: ' + ($node['Init & ACL Pre-Filter V3.4'].json.query || '') + '\\n\\nContexte documentaire:\\n' + (($json.results || []).map((r, i) => '[' + (i+1) + '] ' + (r.source || 'source') + ': ' + (r.content || '')).join('\\n---\\n').substring(0, 6000))) }}\n    }\n  ],\n  \"temperature\": 0.3,\n  \"max_tokens\": 1500\n}",
          "options": {
            "batching": {
              "batch": {
                "batchSize": 1
              }
            },
            "timeout": 30000,
            "retry": {
              "maxTries": 3,
              "waitBetweenTries": 2000
            }
          },
          "sendHeaders": true,
          "headerParameters": {
            "parameters": [
              {
                "name": "Authorization",
                "value": "=Bearer {{ $vars.OPENROUTER_API_KEY }}"
              }
            ]
          }
        },
        "id": "7dc20347-e74b-433b-84c3-6e41e2f5d041",
        "name": "LLM Generation",
        "type": "n8n-nodes-base.httpRequest",
        "typeVersion": 4.3,
        "position": [
          4560,
          3152
        ],
        "credentials": {},
        "onError": "continueRegularOutput"
      },
      {
        "parameters": {
          "jsCode": "\n// Response Formatter - Standard RAG\n// Fixed: removed undefined 'response' reference\ntry {\n  // Try to get LLM generation output\n  let llmContent = '';\n  try {\n    const llmData = $node['LLM Generation'].json;\n    if (llmData?.choices?.[0]?.message?.content) {\n      llmContent = llmData.choices[0].message.content;\n    }\n  } catch(e) {}\n\n  // Try to get reranked sources\n  let sources = [];\n  try {\n    const reranked = $node['Rerank Merger']?.json;\n    sources = reranked?.reranked_results || reranked?.results || [];\n  } catch(e) {}\n\n  // Try to get init data\n  let initData = {};\n  try {\n    initData = $node['Init & ACL Pre-Filter V3.4'].json;\n  } catch(e) {}\n\n  if (llmContent) {\n    return [{\n      json: {\n        response: llmContent,\n        trace_id: initData.trace_id || 'tr-' + Date.now(),\n        sources: sources.slice(0, 5),\n        model: $vars.LLM_STANDARD_MODEL || 'meta-llama/llama-3.3-70b-instruct:free',\n        embedding_fallback: sources.length === 0,\n        timestamp: new Date().toISOString()\n      }\n    }];\n  }\n\n  // No LLM answer - return fallback\n  return [{\n    json: {\n      response: 'Unable to generate answer - retrieval and LLM both unavailable',\n      trace_id: initData.trace_id || 'tr-' + Date.now(),\n      error: true,\n      embedding_fallback: true,\n      timestamp: new Date().toISOString()\n    }\n  }];\n} catch(e) {\n  return [{\n    json: {\n      response: 'Error in response formatting: ' + e.message,\n      error: true,\n      timestamp: new Date().toISOString()\n    }\n  }];\n}"
        },
        "id": "66bf2956-117a-4408-b218-cf96cb317529",
        "name": "Response Formatter",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          4752,
          3040
        ],
        "onError": "continueRegularOutput"
      },
      {
        "parameters": {
          "conditions": {
            "options": {
              "caseSensitive": true,
              "leftValue": "",
              "typeValidation": "strict",
              "version": 1
            },
            "conditions": [
              {
                "id": "skip-llm-check",
                "leftValue": "={{ false }}",
                "rightValue": true,
                "operator": {
                  "type": "boolean",
                  "operation": "equals"
                }
              }
            ],
            "combinator": "and"
          },
          "options": {}
        },
        "id": "780215fa-733a-45fd-a706-f6519e6c3146",
        "name": "Skip LLM?",
        "type": "n8n-nodes-base.if",
        "typeVersion": 2,
        "position": [
          4416,
          3040
        ],
        "onError": "continueRegularOutput"
      },
      {
        "parameters": {
          "conditions": {
            "options": {
              "caseSensitive": true,
              "leftValue": "",
              "typeValidation": "loose",
              "version": 1
            },
            "conditions": [
              {
                "id": "d45424c0-e258-4471-a0f1-ac1588322191",
                "leftValue": "=={{ $json.needs_decomposition }}",
                "rightValue": true,
                "operator": {
                  "type": "boolean",
                  "operation": "true",
                  "singleValue": true
                }
              }
            ],
            "combinator": "and"
          },
          "options": {
            "looseTypeValidation": "={{ true }}"
          }
        },
        "type": "n8n-nodes-base.if",
        "typeVersion": 2,
        "position": [
          2896,
          2960
        ],
        "id": "7d4ea704-e270-458a-8e80-71f08f3d99f2",
        "name": "Needs Decomposition?",
        "onError": "continueRegularOutput"
      },
      {
        "parameters": {
          "jsCode": "// Query Merger V3.4 - Prepare queries for retrieval\nconst initData = $node['Init & ACL Pre-Filter V3.4'].json;\nconst needsDecomposition = initData.needs_decomposition;\n\nlet queriesToProcess = [];\n\nif (needsDecomposition) {\n  try {\n    const decomposed = JSON.parse($node['Query Decomposer (V.3.4)'].json?.choices?.[0]?.message?.content || '{}');\n    \n    if (decomposed.is_simple || !decomposed.sub_queries?.length) {\n      queriesToProcess = [initData.query];\n    } else {\n      // Add original + sub-queries for comprehensive retrieval\n      queriesToProcess = [initData.query, ...decomposed.sub_queries.slice(0, 3)];\n    }\n  } catch (e) {\n    queriesToProcess = [initData.query];\n  }\n} else {\n  queriesToProcess = [initData.query];\n}\n\nreturn [{\n  json: {\n    queries: queriesToProcess,\n    primary_query: initData.query,\n    is_decomposed: queriesToProcess.length > 1,\n    topK_per_query: Math.ceil(initData.topK / queriesToProcess.length),\n    trace_id: initData.trace_id,\n    user_context: initData.user_context,\n    acl_filter: initData.acl_filter\n  }\n}];"
        },
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          3280,
          3024
        ],
        "id": "93998a6b-1ffd-4aaf-8a5f-2c97369d19e1",
        "name": "Query Merger V3.4",
        "onError": "continueRegularOutput"
      },
      {
        "parameters": {
          "content": "# ðŸ”§ VARIABLES D'ENVIRONNEMENT REQUISES (SOTA 2026)\n\n## LLM APIs\n- `OPENROUTER_BASE_URL` - https://openrouter.ai/api/v1/chat/completions\n- `LLM_HYDE_MODEL` - meta-llama/llama-3.3-70b-instruct:free\n- `LLM_FAST_MODEL` - meta-llama/llama-3.3-70b-instruct:free\n\n## Embedding\n- `EMBEDDING_API_URL` - URL embedding API\n- `EMBEDDING_MODEL` - text-embedding-3-small\n\n## Reranking\n- `RERANKER_API_URL` - https://api.cohere.ai/v1/rerank\n- `RERANKER_MODEL` - rerank-v3.5 (upgraded from rerank-multilingual-v3.0)\n\n## CORRECTIONS V3.4.1:\n- Fixed HyDE Generator JSON body (removed orphan JS code)\n- Fixed Embedding model string (removed extra quotes)\n- Fixed Query Decomposer model reference\n\n## ISSUE-SR-04 (P1) - PENDING ARCHITECTURE CHANGE:\n- An IF node must be added BEFORE the Cohere Reranker node\n- Condition: skip_reranker === true â†’ bypass Cohere entirely\n- Currently when skip_reranker=true, a placeholder document is sent to Cohere\n- This wastes API credits and may produce misleading rerank scores\n- Route: RRF â†’ [new IF: Has Results?] â†’ true: Cohere â†’ Rerank Merger\n-                                      â†’ false: Rerank Merger (directly)\n- STATUS: Requires manual structural change (add node + rewire connections)\n",
          "height": 500,
          "width": 400
        },
        "id": "5015f29c-6e31-4ddb-ae5f-51b766132726",
        "name": "ðŸ“‹ Configuration SOTA 2026",
        "type": "n8n-nodes-base.stickyNote",
        "typeVersion": 1,
        "position": [
          2240,
          1552
        ]
      },
      {
        "parameters": {
          "public": true,
          "availableInChat": true,
          "options": {}
        },
        "type": "@n8n/n8n-nodes-langchain.chatTrigger",
        "typeVersion": 1.4,
        "position": [
          2496,
          2560
        ],
        "id": "64766023-f697-4f4b-ab8c-5a26dd166d76",
        "name": "When chat message received",
        "webhookId": "7c483bf3-3e68-4ac1-8812-eda6b2c28a5a"
      },
      {
        "parameters": {
          "method": "POST",
          "url": "={{ $vars.OPENROUTER_BASE_URL || 'https://openrouter.ai/api/v1/chat/completions' }}",
          "authentication": "none",
          "nodeCredentialType": "openRouterApi",
          "sendBody": true,
          "specifyBody": "json",
          "jsonBody": "={\n  \"model\": \"{{ $vars.LLM_FAST_MODEL || 'meta-llama/llama-3.3-70b-instruct:free' }}\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"Tu es un expert en decomposition de questions. Analyse la question et decompose-la en sous-questions independantes si necessaire.\\n\\nREGLES:\\n1. Si la question est simple et directe, retourne is_simple: true\\n2. Si la question contient plusieurs aspects, decompose en 2-4 sous-questions\\n3. Chaque sous-question doit etre auto-suffisante\\n4. Ordonne par dependance logique\\n\\nFormat JSON strict:\\n{\\n  \\\"is_simple\\\": boolean,\\n  \\\"original_query\\\": \\\"..\\\",\\n  \\\"sub_queries\\\": [\\\"q1\\\", \\\"q2\\\", ...],\\n  \\\"reasoning\\\": \\\"Pourquoi cette decomposition\\\"\\n}\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": {{ JSON.stringify($node['Init & ACL Pre-Filter V3.4'].json.query || '') }}\n    }\n  ],\n  \"temperature\": 0.1,\n  \"max_tokens\": 500\n}",
          "options": {
            "batching": {
              "batch": {
                "batchSize": 1
              }
            },
            "timeout": 20000,
            "retry": {
              "maxTries": 3,
              "waitBetweenTries": 2000
            }
          },
          "sendHeaders": true,
          "headerParameters": {
            "parameters": [
              {
                "name": "Authorization",
                "value": "=Bearer {{ $vars.OPENROUTER_API_KEY }}"
              }
            ]
          }
        },
        "type": "n8n-nodes-base.httpRequest",
        "typeVersion": 4.3,
        "position": [
          2736,
          3504
        ],
        "id": "92c737a5-8497-4242-894f-07966ccc6a13",
        "name": "Query Decomposer (V.3.4)",
        "credentials": {},
        "onError": "continueRegularOutput"
      },
      {
        "parameters": {
          "jsCode": "// GitHub Error Logger for standard\nconst errorData = $input.first().json;\nconst timestamp = new Date().toISOString();\nconst questionId = errorData.question_id || errorData.trace_id || 'q-' + Date.now();\nconst errorType = errorData.error_type || errorData.error_code || 'UNKNOWN';\nconst pipeline = 'standard';\n\nconst logEntry = {\n  timestamp: timestamp,\n  pipeline: pipeline,\n  question_id: questionId,\n  error_type: errorType,\n  error_message: (errorData.error || errorData.message || 'No message').slice(0, 500),\n  input: {\n    query: (errorData.query || errorData.original_query || '').slice(0, 300),\n    tenant_id: errorData.tenant_id || 'benchmark'\n  },\n  partial_response: errorData.partial_response || errorData.response || null,\n  n8n_context: {\n    workflow_id: $workflow.id,\n    workflow_name: $workflow.name,\n    execution_id: $execution.id\n  },\n  performance: {\n    latency_ms: errorData.latency_ms || 0,\n    http_status: errorData.http_status || null\n  }\n};\n\nreturn [{ json: logEntry }];"
        },
        "id": "ae5ed52c-d7db-4463-a80d-374c0f35163f",
        "name": "GitHub Error Logger (standard)",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          5052,
          0
        ],
        "onError": "continueRegularOutput"
      },
      {
        "parameters": {
          "jsCode": "// Execution Summary Logger for standard\nconst input = $input.first().json;\nconst timestamp = new Date().toISOString();\n\nconst summary = {\n  timestamp: timestamp,\n  pipeline: 'standard',\n  question_id: input.trace_id || input.question_id || 'q-' + Date.now(),\n  query: (input.query || input.original_query || '').slice(0, 300),\n  success: !!(input.response || input.final_response || input.answer),\n  response_length: (input.response || input.final_response || input.answer || '').length,\n  confidence: input.confidence || 0,\n  latency_ms: input.latency_ms || 0,\n  engine: input.engine || input.selected_engine || 'standard',\n  n8n_context: {\n    workflow_id: $workflow.id,\n    execution_id: $execution.id\n  }\n};\n\nreturn [{ json: summary }];"
        },
        "id": "39e4ddaa-1665-429f-805c-5945d1beca40",
        "name": "Execution Summary (standard)",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [
          5052,
          200
        ],
        "onError": "continueRegularOutput"
      }
    ],
    "connections": {
      "Sub-Workflow Trigger": {
        "main": [
          [
            {
              "node": "Init & ACL Pre-Filter V3.4",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Webhook": {
        "main": [
          [
            {
              "node": "Init & ACL Pre-Filter V3.4",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Init & ACL Pre-Filter V3.4": {
        "main": [
          [
            {
              "node": "Needs Decomposition?",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "HyDE Generator": {
        "main": [
          [
            {
              "node": "HyDE Embedding",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "HyDE Embedding": {
        "main": [
          [
            {
              "node": "HTTP Pinecone Query HyDE",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "HTTP Pinecone Query HyDE": {
        "main": [
          [
            {
              "node": "Wait All Branches",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Original Embedding": {
        "main": [
          [
            {
              "node": "HTTP Pinecone Query Original",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "HTTP Pinecone Query Original": {
        "main": [
          [
            {
              "node": "Wait All Branches",
              "type": "main",
              "index": 1
            }
          ]
        ]
      },
      "Wait All Branches": {
        "main": [
          [
            {
              "node": "RRF Merge & Rank V3.4",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "RRF Merge & Rank V3.4": {
        "main": [
          [
            {
              "node": "Cohere Reranker",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Cohere Reranker": {
        "main": [
          [
            {
              "node": "Rerank Merger",
              "type": "main",
              "index": 0
            }
          ],
          [
            {
              "node": "Rerank Merger",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Rerank Merger": {
        "main": [
          [
            {
              "node": "Skip LLM?",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "LLM Generation": {
        "main": [
          [
            {
              "node": "Response Formatter",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Skip LLM?": {
        "main": [
          [
            {
              "node": "Response Formatter",
              "type": "main",
              "index": 0
            }
          ],
          [
            {
              "node": "LLM Generation",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Needs Decomposition?": {
        "main": [
          [
            {
              "node": "Query Decomposer (V.3.4)",
              "type": "main",
              "index": 0
            }
          ],
          [
            {
              "node": "HyDE Generator",
              "type": "main",
              "index": 0
            },
            {
              "node": "Original Embedding",
              "type": "main",
              "index": 0
            },
            {
              "node": "BM25 Search Postgres",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Query Merger V3.4": {
        "main": [
          [
            {
              "node": "HyDE Generator",
              "type": "main",
              "index": 0
            },
            {
              "node": "Original Embedding",
              "type": "main",
              "index": 0
            },
            {
              "node": "BM25 Search Postgres",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "When chat message received": {
        "main": [
          [
            {
              "node": "Init & ACL Pre-Filter V3.4",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Query Decomposer (V.3.4)": {
        "main": [
          [
            {
              "node": "Query Merger V3.4",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "BM25 Search Postgres": {
        "main": [
          [
            {
              "node": "Wait All Branches",
              "type": "main",
              "index": 1
            }
          ]
        ]
      }
    },
    "authors": "Alexis Moret",
    "name": null,
    "description": null,
    "autosaved": false,
    "workflowPublishHistory": [
      {
        "createdAt": "2026-02-09T03:43:46.262Z",
        "id": 761,
        "workflowId": "LnTqRX4LZlI009Ks-3Jnp",
        "versionId": "7d5ff7e8-d1de-47b0-8b5e-27e2a76acc1e",
        "event": "activated",
        "userId": "215767e0-958a-4c74-a67a-e335807eba64"
      },
      {
        "createdAt": "2026-02-09T03:44:02.868Z",
        "id": 763,
        "workflowId": "LnTqRX4LZlI009Ks-3Jnp",
        "versionId": "7d5ff7e8-d1de-47b0-8b5e-27e2a76acc1e",
        "event": "activated",
        "userId": "215767e0-958a-4c74-a67a-e335807eba64"
      },
      {
        "createdAt": "2026-02-09T03:53:25.868Z",
        "id": 776,
        "workflowId": "LnTqRX4LZlI009Ks-3Jnp",
        "versionId": "7d5ff7e8-d1de-47b0-8b5e-27e2a76acc1e",
        "event": "activated",
        "userId": "215767e0-958a-4c74-a67a-e335807eba64"
      },
      {
        "createdAt": "2026-02-09T03:54:11.086Z",
        "id": 780,
        "workflowId": "LnTqRX4LZlI009Ks-3Jnp",
        "versionId": "7d5ff7e8-d1de-47b0-8b5e-27e2a76acc1e",
        "event": "activated",
        "userId": "215767e0-958a-4c74-a67a-e335807eba64"
      },
      {
        "createdAt": "2026-02-09T03:54:24.515Z",
        "id": 785,
        "workflowId": "LnTqRX4LZlI009Ks-3Jnp",
        "versionId": "7d5ff7e8-d1de-47b0-8b5e-27e2a76acc1e",
        "event": "activated",
        "userId": "215767e0-958a-4c74-a67a-e335807eba64"
      },
      {
        "createdAt": "2026-02-09T03:55:16.975Z",
        "id": 796,
        "workflowId": "LnTqRX4LZlI009Ks-3Jnp",
        "versionId": "7d5ff7e8-d1de-47b0-8b5e-27e2a76acc1e",
        "event": "activated",
        "userId": "215767e0-958a-4c74-a67a-e335807eba64"
      },
      {
        "createdAt": "2026-02-09T03:43:59.578Z",
        "id": 762,
        "workflowId": "LnTqRX4LZlI009Ks-3Jnp",
        "versionId": "7d5ff7e8-d1de-47b0-8b5e-27e2a76acc1e",
        "event": "deactivated",
        "userId": "215767e0-958a-4c74-a67a-e335807eba64"
      },
      {
        "createdAt": "2026-02-09T03:53:08.029Z",
        "id": 772,
        "workflowId": "LnTqRX4LZlI009Ks-3Jnp",
        "versionId": "7d5ff7e8-d1de-47b0-8b5e-27e2a76acc1e",
        "event": "deactivated",
        "userId": "215767e0-958a-4c74-a67a-e335807eba64"
      },
      {
        "createdAt": "2026-02-09T03:54:21.831Z",
        "id": 784,
        "workflowId": "LnTqRX4LZlI009Ks-3Jnp",
        "versionId": "7d5ff7e8-d1de-47b0-8b5e-27e2a76acc1e",
        "event": "deactivated",
        "userId": "215767e0-958a-4c74-a67a-e335807eba64"
      },
      {
        "createdAt": "2026-02-09T03:54:51.672Z",
        "id": 792,
        "workflowId": "LnTqRX4LZlI009Ks-3Jnp",
        "versionId": "7d5ff7e8-d1de-47b0-8b5e-27e2a76acc1e",
        "event": "deactivated",
        "userId": "215767e0-958a-4c74-a67a-e335807eba64"
      }
    ]
  }
}