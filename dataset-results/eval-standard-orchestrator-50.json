{
  "dataset_name": "eval-standard-orchestrator-50",
  "rag_targets": ["standard", "orchestrator"],
  "category": "benchmark_evaluation",
  "source": "manual_evaluation_suite",
  "generated_at": "2026-02-07T00:00:00.000000",
  "purpose": "Evaluation du pipeline Standard RAG (WF5 V3.4 - vector search Pinecone + HyDE + dual retrieval) et du Orchestrator (V10.1 - intent routing + multi-pipeline synthesis). Teste: HyDE quality, retrieval precision, answer extraction, intent classification, cross-pipeline routing, conversation context, fallback mechanisms.",
  "total_questions": 50,
  "breakdown": {
    "standard_rag": 25,
    "orchestrator_routing": 15,
    "orchestrator_synthesis": 10
  },
  "workflows_tested": {
    "WF5": "Standard RAG V3.4 - CORRECTED (HyDE + dual retrieval + Pinecone)",
    "V10.1": "Orchestrator (intent classification + 3-pipeline routing + synthesis)"
  },
  "summary": {
    "total_tested": 0,
    "total_answered": 0,
    "total_correct": 0,
    "avg_f1": 0.0,
    "avg_latency_ms": 0,
    "routing_accuracy": 0.0,
    "status": "NOT_STARTED"
  },
  "questions": [
    {
      "id": "std-eval-01",
      "rag_target": "standard",
      "category": "factual_retrieval",
      "question": "What is semantic chunking and how does it differ from fixed-size chunking for document processing?",
      "expected_answer": "Semantic chunking splits documents at natural topic boundaries using NLP/embeddings to maintain coherent meaning within each chunk, while fixed-size chunking splits at arbitrary character/token counts regardless of content. Semantic chunking improves retrieval accuracy by keeping related information together.",
      "difficulty": "medium",
      "tests_feature": "HyDE generation + vector retrieval",
      "actual_answer": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "std-eval-02",
      "rag_target": "standard",
      "category": "factual_retrieval",
      "question": "What are the key advantages of using a knowledge graph for multi-hop question answering?",
      "expected_answer": "Knowledge graphs enable traversal of entity relationships across multiple documents, support reasoning about indirect connections, provide structured representation of entities and relationships, and allow community detection for contextual understanding of related concepts.",
      "difficulty": "medium",
      "tests_feature": "Document retrieval from architecture docs",
      "actual_answer": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "std-eval-03",
      "rag_target": "standard",
      "category": "technical_retrieval",
      "question": "Explain the HyDE (Hypothetical Document Embedding) technique used in RAG pipelines.",
      "expected_answer": "HyDE generates a hypothetical answer document using an LLM before embedding. This hypothetical document is embedded and used for vector similarity search instead of the raw query. It bridges the gap between question-style queries and document-style passages, improving retrieval recall by 10-15%.",
      "difficulty": "hard",
      "tests_feature": "HyDE understanding from SOTA docs",
      "actual_answer": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "std-eval-04",
      "rag_target": "standard",
      "category": "factual_simple",
      "question": "What embedding model is used in the SOTA 2026 standard RAG pipeline?",
      "expected_answer": "text-embedding-3-small (1536 dimensions), with planned upgrade to Qwen3-Embedding-8B (4096 dimensions)",
      "difficulty": "easy",
      "tests_feature": "Direct fact retrieval",
      "actual_answer": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "std-eval-05",
      "rag_target": "standard",
      "category": "technical_retrieval",
      "question": "What is contextual retrieval and how is it implemented in the ingestion pipeline?",
      "expected_answer": "Contextual retrieval adds 1-2 contextual sentences to each chunk before embedding. An LLM generates context that situates the chunk within the broader document, improving retrieval precision by helping the vector search understand what each chunk is about in context.",
      "difficulty": "hard",
      "tests_feature": "SOTA 2026 ingestion pattern retrieval",
      "actual_answer": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "std-eval-06",
      "rag_target": "standard",
      "category": "process_retrieval",
      "question": "Describe the document ingestion pipeline steps from file upload to vector storage.",
      "expected_answer": "1. S3 webhook triggers arrival, 2. Redis lock prevents concurrent processing, 3. MIME type detection, 4. OCR extraction, 5. PII masking, 6. Semantic chunking with LLM validation, 7. Contextual retrieval per chunk, 8. Q&A pair generation, 9. Embedding generation, 10. BM25 sparse vectors, 11. Upsert to Pinecone",
      "difficulty": "hard",
      "tests_feature": "Multi-step process retrieval",
      "actual_answer": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "std-eval-07",
      "rag_target": "standard",
      "category": "factual_comparison",
      "question": "What is the difference between dense vector search and hybrid search with BM25?",
      "expected_answer": "Dense vector search uses neural embeddings for semantic similarity, capturing meaning even with different wording. BM25 uses sparse vectors based on term frequency for exact keyword matching. Hybrid search combines both, using dense for semantic understanding and sparse for precise term matching, improving both recall and precision.",
      "difficulty": "medium",
      "tests_feature": "Technical concept retrieval",
      "actual_answer": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "std-eval-08",
      "rag_target": "standard",
      "category": "factual_simple",
      "question": "What vector database is used for document storage in this system?",
      "expected_answer": "Pinecone",
      "difficulty": "easy",
      "tests_feature": "Simple fact retrieval",
      "actual_answer": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "std-eval-09",
      "rag_target": "standard",
      "category": "security_retrieval",
      "question": "How is multi-tenant data isolation implemented in the RAG system?",
      "expected_answer": "Multi-tenant isolation uses tenant_id metadata on all Pinecone vectors, ACL pre-filtering at query time with group-based access control, tenant_id columns in all PostgreSQL tables, and namespace isolation per tenant in Pinecone.",
      "difficulty": "hard",
      "tests_feature": "Cross-document security concept retrieval",
      "actual_answer": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "std-eval-10",
      "rag_target": "standard",
      "category": "factual_simple",
      "question": "What LLM is used for response generation in the standard RAG pipeline?",
      "expected_answer": "Google Gemini 2.0 Flash (via OpenRouter)",
      "difficulty": "easy",
      "tests_feature": "Config fact retrieval",
      "actual_answer": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "std-eval-11",
      "rag_target": "standard",
      "category": "technical_retrieval",
      "question": "What are the OWASP Top 10 SQL injection prevention techniques used in the quantitative RAG pipeline?",
      "expected_answer": "Forbidden pattern detection (DELETE, UPDATE, INSERT, DROP, TRUNCATE, ALTER, CREATE, GRANT, REVOKE, EXEC), mandatory SELECT prefix, LIMIT enforcement (max 100), mandatory tenant_id in WHERE clause with comparison operator, SQL comment blocking (--), UNION SELECT blocking, xp_ and sp_ prefix blocking.",
      "difficulty": "hard",
      "tests_feature": "Security doc retrieval",
      "actual_answer": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "std-eval-12",
      "rag_target": "standard",
      "category": "process_retrieval",
      "question": "How does the adaptive topK mechanism work in the standard RAG pipeline?",
      "expected_answer": "The Init & ACL Pre-Filter analyzes query complexity and adjusts the number of retrieved results (topK) accordingly: simple queries use 8-10 results, moderate queries use 12-15, complex queries use 15-20, and multi-hop queries use 20-25 results.",
      "difficulty": "medium",
      "tests_feature": "Implementation detail retrieval",
      "actual_answer": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "std-eval-13",
      "rag_target": "standard",
      "category": "factual_retrieval",
      "question": "What is the Chain-of-Thought (CoT) prompting technique used in SQL generation?",
      "expected_answer": "CoT prompting structures the SQL generation in 4 explicit steps: 1) Understand the question (entities, metrics, filters, time period), 2) Map to schema (find tables, exact columns, data types, JOINs), 3) Build the query (SELECT, FROM, JOIN, WHERE, GROUP BY, ORDER BY, LIMIT), 4) Verify (syntax, correctness, column existence). This structured reasoning improves SQL accuracy.",
      "difficulty": "medium",
      "tests_feature": "Technique description retrieval",
      "actual_answer": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "std-eval-14",
      "rag_target": "standard",
      "category": "architecture_retrieval",
      "question": "What are the three types of memory layers used in the orchestrator?",
      "expected_answer": "L1: Redis (real-time session memory via Upstash), L2: PostgreSQL conversation_context table (entity tracking, intent history), L3: Neo4j knowledge graph (long-term entity relationships).",
      "difficulty": "medium",
      "tests_feature": "Architecture retrieval",
      "actual_answer": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "std-eval-15",
      "rag_target": "standard",
      "category": "error_handling",
      "question": "What are the PostgreSQL error categories in the Diagnostic Error Handler?",
      "expected_answer": "7 categories: SYNTAX_ERROR (fix syntax), COLUMN_NOT_FOUND (verify schema), TABLE_NOT_FOUND (map alternative table), TYPE_MISMATCH (add cast), PERMISSION_DENIED (stop immediately), TIMEOUT (simplify query), AMBIGUOUS_COLUMN (qualify columns).",
      "difficulty": "hard",
      "tests_feature": "Error categorization retrieval",
      "actual_answer": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "std-eval-16",
      "rag_target": "standard",
      "category": "benchmark_retrieval",
      "question": "What evaluation metrics are used to measure RAG pipeline performance?",
      "expected_answer": "Retrieval: recall@5, recall@10, MRR@10, NDCG@10. Generation: Exact Match (EM), F1 score (token-level), Faithfulness, ROUGE-L, Noise Robustness, Negative Rejection. E2E: Accuracy, F1, EM, ROUGE-L, Retrieval Precision, Faithfulness. Robustness: Hallucination rate, Abstention rate, Counterfactual robustness.",
      "difficulty": "hard",
      "tests_feature": "Metrics enumeration retrieval",
      "actual_answer": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "std-eval-17",
      "rag_target": "standard",
      "category": "technical_retrieval",
      "question": "What is the self-healing SQL repair mechanism and how does it work?",
      "expected_answer": "The self-healing mechanism catches SQL execution errors, categorizes them using the Diagnostic Error Handler, and retries up to 3 times. Each retry sends the failed SQL, error message, schema context, and original question to a repair LLM that generates a corrected query. The repaired SQL goes through validation again before execution.",
      "difficulty": "medium",
      "tests_feature": "Process flow retrieval",
      "actual_answer": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "std-eval-18",
      "rag_target": "standard",
      "category": "factual_simple",
      "question": "What graph database is used for multi-hop reasoning?",
      "expected_answer": "Neo4j",
      "difficulty": "easy",
      "tests_feature": "Simple fact retrieval",
      "actual_answer": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "std-eval-19",
      "rag_target": "standard",
      "category": "technical_retrieval",
      "question": "What is PII masking and where is it applied in the pipeline?",
      "expected_answer": "PII (Personally Identifiable Information) masking detects and redacts sensitive information like names, email addresses, and Social Security Numbers during document ingestion, before the content is chunked and embedded. This prevents PII from being stored in the vector database.",
      "difficulty": "medium",
      "tests_feature": "Security feature retrieval",
      "actual_answer": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "std-eval-20",
      "rag_target": "standard",
      "category": "architecture_retrieval",
      "question": "How many n8n workflow nodes does the quantitative RAG pipeline contain?",
      "expected_answer": "24 nodes (21 active)",
      "difficulty": "easy",
      "tests_feature": "Specific fact retrieval",
      "actual_answer": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "std-eval-21",
      "rag_target": "standard",
      "category": "comparison_retrieval",
      "question": "What is the difference between the standard RAG and graph RAG approaches for answering questions?",
      "expected_answer": "Standard RAG uses vector similarity search in Pinecone to retrieve relevant document chunks and generate answers from them. Graph RAG uses Neo4j to traverse entity relationships across multiple documents, supporting multi-hop reasoning where the answer requires connecting information from different sources. Standard RAG is faster but limited to single-hop retrieval; Graph RAG handles complex relationship queries but is slower.",
      "difficulty": "hard",
      "tests_feature": "Comparative analysis retrieval",
      "actual_answer": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "std-eval-22",
      "rag_target": "standard",
      "category": "technical_retrieval",
      "question": "What reranking approach is used in the standard RAG pipeline and what upgrade is planned?",
      "expected_answer": "Currently uses Cohere rerank-v3 for result reranking after Pinecone retrieval. Planned upgrade to Qwen3-Reranker-8B self-hosted model, or ColBERT for late interaction reranking.",
      "difficulty": "medium",
      "tests_feature": "Current + planned feature retrieval",
      "actual_answer": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "std-eval-23",
      "rag_target": "standard",
      "category": "factual_retrieval",
      "question": "What financial tables are available in the benchmark database?",
      "expected_answer": "5 tables: financials (income statements), balance_sheet (balance sheet snapshots), sales_data (transaction-level sales), employees (50 per company), products (6 per company). Data covers 3 companies: TechVision Inc, GreenEnergy Corp, HealthPlus Labs.",
      "difficulty": "medium",
      "tests_feature": "Schema knowledge retrieval",
      "actual_answer": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "std-eval-24",
      "rag_target": "standard",
      "category": "performance_retrieval",
      "question": "What is the estimated accuracy improvement from adding few-shot SQL examples to the quantitative pipeline?",
      "expected_answer": "+13% BIRD-SQL accuracy based on DIN-SQL research (2023, validated 2026)",
      "difficulty": "easy",
      "tests_feature": "Quantitative improvement metric retrieval",
      "actual_answer": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "std-eval-25",
      "rag_target": "standard",
      "category": "architecture_retrieval",
      "question": "What are the five specialized agents in the multi-agent orchestration system?",
      "expected_answer": "1. Workflow Analyzer (Opus 4.5) - analyzes workflow JSON, 2. DB Reader (Opus 4.5) - extracts data from DBs (Pinecone, Neo4j, Supabase), 3. Patch Writer (Opus 4.5) - generates RFC 6902 patches, 4. Patch Applier (Haiku) - applies patches via Python, 5. N8N Tester (Opus 4.5) - tests and validates on n8n cloud. Orchestrator uses Haiku for coordination.",
      "difficulty": "medium",
      "tests_feature": "System architecture retrieval",
      "actual_answer": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "orch-eval-01",
      "rag_target": "orchestrator",
      "category": "intent_routing_standard",
      "question": "What is semantic chunking?",
      "expected_routing": "standard",
      "expected_answer": "Semantic chunking splits documents at natural topic boundaries using NLP/embedding similarity to maintain coherent meaning within each chunk.",
      "difficulty": "easy",
      "tests_feature": "Intent classification - should route to standard RAG (factual/definitional query)",
      "actual_answer": null,
      "actual_routing": null,
      "routing_correct": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "orch-eval-02",
      "rag_target": "orchestrator",
      "category": "intent_routing_quantitative",
      "question": "What is the total revenue of TechVision for FY 2023?",
      "expected_routing": "quantitative",
      "expected_answer": "$6,745,000,000",
      "difficulty": "easy",
      "tests_feature": "Intent classification - should route to quantitative (SQL query on financials table)",
      "actual_answer": null,
      "actual_routing": null,
      "routing_correct": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "orch-eval-03",
      "rag_target": "orchestrator",
      "category": "intent_routing_graph",
      "question": "Which employees at TechVision work in the same department as the highest-paid person at GreenEnergy?",
      "expected_routing": "graph",
      "expected_answer": "Depends on seed data - requires multi-hop: GreenEnergy -> max salary employee -> department -> TechVision employees in same department",
      "difficulty": "hard",
      "tests_feature": "Intent classification - should route to graph RAG (multi-hop entity relationship)",
      "actual_answer": null,
      "actual_routing": null,
      "routing_correct": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "orch-eval-04",
      "rag_target": "orchestrator",
      "category": "intent_routing_ambiguous",
      "question": "How does TechVision compare to GreenEnergy in terms of financial health?",
      "expected_routing": "quantitative+graph",
      "expected_answer": "TechVision: Revenue $6.7B, Net Income $1.6B, Total Assets $7.9B, D/E 0.29. GreenEnergy: Revenue $3.65B, Net Income $664M, Total Assets $4.46B, D/E 0.36. TechVision is larger and more profitable with lower leverage.",
      "difficulty": "hard",
      "tests_feature": "Ambiguous intent - could need both quantitative (financials) and graph (entity comparison). Tests confidence-based routing.",
      "actual_answer": null,
      "actual_routing": null,
      "routing_correct": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "orch-eval-05",
      "rag_target": "orchestrator",
      "category": "intent_routing_quantitative",
      "question": "Calculate the operating margin trend for all three benchmark companies from 2020 to 2023.",
      "expected_routing": "quantitative",
      "expected_answer": "TechVision: 25.0%(2020)->28.0%(2021)->29.5%(2022)->30.0%(2023). GreenEnergy: 14.0%(2020)->17.0%(2021)->20.0%(2022)->23.0%(2023). HealthPlus: 5.0%(2020)->12.0%(2021)->15.0%(2022)->18.5%(2023).",
      "difficulty": "hard",
      "tests_feature": "Complex quantitative routing with multi-year, multi-company aggregation",
      "actual_answer": null,
      "actual_routing": null,
      "routing_correct": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "orch-eval-06",
      "rag_target": "orchestrator",
      "category": "intent_routing_standard",
      "question": "What security measures are implemented to prevent SQL injection in the system?",
      "expected_routing": "standard",
      "expected_answer": "Forbidden pattern detection, mandatory SELECT prefix, LIMIT enforcement, tenant_id validation in WHERE clause, SQL comment blocking, UNION SELECT prevention.",
      "difficulty": "medium",
      "tests_feature": "Conceptual question - should route to standard RAG (documentation retrieval)",
      "actual_answer": null,
      "actual_routing": null,
      "routing_correct": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "orch-eval-07",
      "rag_target": "orchestrator",
      "category": "intent_routing_graph",
      "question": "What products does the company with the highest net income sell, and in which regions?",
      "expected_routing": "graph",
      "expected_answer": "TechVision Inc (highest net income at $1.6B) sells: VisionAI Platform, VisionAI Edge, CloudSync Pro, CloudSync Enterprise, CyberShield, DataVault across North America, Europe, Asia Pacific, and Middle East.",
      "difficulty": "hard",
      "tests_feature": "Multi-hop: identify company with max metric -> traverse to products -> traverse to sales regions",
      "actual_answer": null,
      "actual_routing": null,
      "routing_correct": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "orch-eval-08",
      "rag_target": "orchestrator",
      "category": "intent_routing_quantitative",
      "question": "What is the debt-to-equity ratio for each company at end of FY 2023?",
      "expected_routing": "quantitative",
      "expected_answer": "TechVision: 0.29 (1775M/6149M), GreenEnergy: 0.36 (1184M/3276M), HealthPlus: 0.40 (320M/795M)",
      "difficulty": "medium",
      "tests_feature": "Financial ratio - quantitative routing with balance_sheet table",
      "actual_answer": null,
      "actual_routing": null,
      "routing_correct": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "orch-eval-09",
      "rag_target": "orchestrator",
      "category": "intent_routing_ambiguous",
      "question": "Tell me everything about HealthPlus Labs.",
      "expected_routing": "quantitative+graph+standard",
      "expected_answer": "HealthPlus Labs is a healthcare company. Revenue: $1.15B (FY2023), Net Income: $174M, Total Assets: $1.1B. Products: BioAssay Pro, GenomeScan 2.0, ImmunoTherapy X, CellGuard, PatientHub, PharmaCare. 50 employees. Revenue grew 260% from 2020 to 2023.",
      "difficulty": "hard",
      "tests_feature": "Open-ended query - should trigger multiple pipelines and synthesize",
      "actual_answer": null,
      "actual_routing": null,
      "routing_correct": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "orch-eval-10",
      "rag_target": "orchestrator",
      "category": "intent_routing_standard",
      "question": "How does the OTEL tracing work in the RAG pipelines?",
      "expected_routing": "standard",
      "expected_answer": "OTEL (OpenTelemetry) exports trace data via HTTP POST to an OTEL collector endpoint. Each trace includes traceId, spanName, status, and attributes like result_count, sql_length, sql_query_preview, engine type, validation_status, query_length, and has_results.",
      "difficulty": "medium",
      "tests_feature": "Technical documentation retrieval via standard RAG",
      "actual_answer": null,
      "actual_routing": null,
      "routing_correct": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "orch-eval-11",
      "rag_target": "orchestrator",
      "category": "intent_routing_quantitative",
      "question": "Which quarter of 2023 had the best net income for GreenEnergy Corp?",
      "expected_routing": "quantitative",
      "expected_answer": "Q4 2023 with the highest net income (due to sequential quarterly growth pattern in the data)",
      "difficulty": "medium",
      "tests_feature": "Quarterly aggregation + MAX routing",
      "actual_answer": null,
      "actual_routing": null,
      "routing_correct": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "orch-eval-12",
      "rag_target": "orchestrator",
      "category": "intent_routing_graph",
      "question": "What is the relationship between TechVision's product lineup and their employee department structure?",
      "expected_routing": "graph",
      "expected_answer": "TechVision has products in AI/ML (VisionAI), Cloud (CloudSync), Security (CyberShield), Data (DataVault) categories, aligned with Engineering, Product, Sales departments. AI/ML products likely developed by Engineering dept (~15 employees).",
      "difficulty": "hard",
      "tests_feature": "Entity relationship reasoning across products and employees tables",
      "actual_answer": null,
      "actual_routing": null,
      "routing_correct": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "orch-eval-13",
      "rag_target": "orchestrator",
      "category": "synthesis_multi_pipeline",
      "question": "Is HealthPlus Labs a good investment? Analyze their financial growth, product portfolio, and market position.",
      "expected_routing": "quantitative+graph+standard",
      "expected_answer": "Growth: Revenue CAGR 53.3% (2020-2023), Net Income grew from $4.3M to $174M. Products: 6 products across Diagnostics, Therapeutics, Digital Health. Balance Sheet: Total Assets $1.1B, low leverage (D/E 0.40). Market: Smallest of 3 benchmark companies but fastest growing. Strong trajectory but smallest scale.",
      "difficulty": "hard",
      "tests_feature": "Full synthesis across all 3 pipelines - financial data + product graph + documentation context",
      "actual_answer": null,
      "actual_routing": null,
      "routing_correct": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "orch-eval-14",
      "rag_target": "orchestrator",
      "category": "synthesis_multi_pipeline",
      "question": "Compare the R&D investment strategy of all three companies. Who invests the most relative to revenue and what products result from it?",
      "expected_routing": "quantitative+graph",
      "expected_answer": "TechVision: $1.35B R&D (20% of revenue) -> AI/ML and Cloud products. GreenEnergy: $365M R&D (10% of revenue) -> Solar and Battery products. HealthPlus: $155M R&D (13.5% of revenue) -> Diagnostics and Therapeutics. TechVision invests most both absolutely and relatively.",
      "difficulty": "hard",
      "tests_feature": "Cross-pipeline synthesis: quantitative (R&D figures) + graph (product mapping)",
      "actual_answer": null,
      "actual_routing": null,
      "routing_correct": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "orch-eval-15",
      "rag_target": "orchestrator",
      "category": "synthesis_multi_pipeline",
      "question": "Which company would benefit most from expanding into new geographic markets based on their current sales distribution and financial capacity?",
      "expected_routing": "quantitative+graph",
      "expected_answer": "HealthPlus Labs would benefit most - highest growth rate (53% CAGR), likely concentrated in fewer regions, and has cash reserves ($320M) for expansion. GreenEnergy has the strongest geographic diversification already. TechVision is well-established globally.",
      "difficulty": "hard",
      "tests_feature": "Complex synthesis requiring financial analysis + geographic sales data + strategic reasoning",
      "actual_answer": null,
      "actual_routing": null,
      "routing_correct": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "orch-eval-16",
      "rag_target": "orchestrator",
      "category": "synthesis_multi_pipeline",
      "question": "Create a competitive analysis summary for GreenEnergy Corp including financial metrics, product strengths, and workforce capabilities.",
      "expected_routing": "quantitative+graph+standard",
      "expected_answer": "Financials: Revenue $3.65B, 30% YoY growth, Operating Margin 23%, Net Income $664M. Products: 6 products in Solar and Battery Storage categories, highest-priced product ($9,999.99). Workforce: 50 employees across Engineering, Sales, Marketing, etc. Strong in renewable energy with rapidly growing revenue and improving margins.",
      "difficulty": "hard",
      "tests_feature": "Full competitive analysis synthesis",
      "actual_answer": null,
      "actual_routing": null,
      "routing_correct": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "orch-eval-17",
      "rag_target": "orchestrator",
      "category": "synthesis_multi_pipeline",
      "question": "What are the key risks facing each company based on their financial data and market position?",
      "expected_routing": "quantitative+standard",
      "expected_answer": "TechVision: Concentration risk (58% of combined revenue), high R&D burn ($1.35B), potential market saturation. GreenEnergy: Long-term debt ($300M), moderate margins. HealthPlus: Smallest scale ($1.15B revenue), low cash reserves relative to growth needs, highest leverage ratio.",
      "difficulty": "hard",
      "tests_feature": "Risk analysis synthesis from financial + contextual data",
      "actual_answer": null,
      "actual_routing": null,
      "routing_correct": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "orch-eval-18",
      "rag_target": "orchestrator",
      "category": "synthesis_multi_pipeline",
      "question": "Rank the three companies by overall performance in 2023 considering revenue, profitability, and growth rate.",
      "expected_routing": "quantitative",
      "expected_answer": "1. HealthPlus Labs: Fastest growth (50% revenue YoY, 97% net income YoY), improving margins. 2. GreenEnergy Corp: Strong growth (30% revenue YoY, 52% net income YoY), good margins. 3. TechVision Inc: Steady growth (15% revenue YoY, 21% net income YoY), highest absolute numbers but slower percentage growth.",
      "difficulty": "hard",
      "tests_feature": "Multi-metric ranking synthesis",
      "actual_answer": null,
      "actual_routing": null,
      "routing_correct": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "orch-eval-19",
      "rag_target": "orchestrator",
      "category": "synthesis_multi_pipeline",
      "question": "What product diversification strategies should TechVision consider based on their current portfolio and market trends?",
      "expected_routing": "graph+standard",
      "expected_answer": "Current portfolio: AI/ML (VisionAI), Cloud (CloudSync), Security (CyberShield), Data (DataVault). Gaps: No IoT/Edge, no industry-specific solutions. Recommendations: Expand VisionAI Edge for edge computing, develop vertical solutions for healthcare/energy using existing AI capabilities, partner with GreenEnergy for smart grid solutions.",
      "difficulty": "hard",
      "tests_feature": "Strategic synthesis from product graph + market context",
      "actual_answer": null,
      "actual_routing": null,
      "routing_correct": null,
      "f1_score": null,
      "status": "not_tested"
    },
    {
      "id": "orch-eval-20",
      "rag_target": "orchestrator",
      "category": "synthesis_multi_pipeline",
      "question": "If the three companies merged, what would the combined entity look like financially?",
      "expected_routing": "quantitative",
      "expected_answer": "Combined Revenue: $11.55B, Combined Net Income: $2.46B, Combined Assets: $13.5B, Combined Equity: $10.22B, Combined Employees: ~150, Combined Products: 18 across tech/energy/healthcare. Overall D/E: 0.32. Diversified across technology, renewable energy, and healthcare.",
      "difficulty": "hard",
      "tests_feature": "Aggregation synthesis requiring sum across all 3 companies",
      "actual_answer": null,
      "actual_routing": null,
      "routing_correct": null,
      "f1_score": null,
      "status": "not_tested"
    }
  ],
  "evaluation_criteria": {
    "standard_rag": {
      "f1_threshold_pass": 0.5,
      "f1_threshold_good": 0.7,
      "f1_threshold_excellent": 0.9,
      "latency_threshold_ms": 10000,
      "hyde_quality_check": true,
      "retrieval_relevance_check": true
    },
    "orchestrator": {
      "routing_accuracy_threshold": 0.8,
      "synthesis_f1_threshold": 0.5,
      "multi_pipeline_latency_ms": 15000,
      "fallback_handling_check": true
    }
  },
  "known_issues": {
    "WF5_fetch_error": "fetch is not defined error blocks most standard RAG tests - needs httpRequest conversion",
    "WF2_graph_raw_summaries": "Graph RAG returns raw Neo4j community summaries instead of LLM-synthesized answers",
    "V10_confidence_routing": "Orchestrator has basic intent classification but lacks confidence-based fallback",
    "V10_parallel_execution": "3-pipeline parallel execution not yet validated at scale"
  }
}
